{
  "best_global_step": 27300,
  "best_metric": 0.0792868509888649,
  "best_model_checkpoint": "trainer_output/checkpoint-27000",
  "epoch": 0.06,
  "eval_steps": 100,
  "global_step": 27600,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0005,
      "grad_norm": 1.1461460590362549,
      "learning_rate": 6.000000000000001e-07,
      "loss": 1.2274,
      "step": 10
    },
    {
      "epoch": 0.001,
      "grad_norm": 1.2312934398651123,
      "learning_rate": 1.2000000000000002e-06,
      "loss": 1.2129,
      "step": 20
    },
    {
      "epoch": 0.0015,
      "grad_norm": 1.1702306270599365,
      "learning_rate": 1.8e-06,
      "loss": 1.2326,
      "step": 30
    },
    {
      "epoch": 0.002,
      "grad_norm": 1.258779764175415,
      "learning_rate": 2.4000000000000003e-06,
      "loss": 1.2205,
      "step": 40
    },
    {
      "step": 50,
      "wer/bud500": 0.20254626246089982
    },
    {
      "step": 50,
      "wer/private": 0.3755656108597285
    },
    {
      "epoch": 0.0025,
      "grad_norm": 1.221843957901001,
      "learning_rate": 3e-06,
      "loss": 1.2079,
      "step": 50
    },
    {
      "epoch": 0.003,
      "grad_norm": 1.214572548866272,
      "learning_rate": 3.6e-06,
      "loss": 1.1877,
      "step": 60
    },
    {
      "epoch": 0.0035,
      "grad_norm": 1.2984619140625,
      "learning_rate": 4.2000000000000004e-06,
      "loss": 1.1901,
      "step": 70
    },
    {
      "epoch": 0.004,
      "grad_norm": 1.2008044719696045,
      "learning_rate": 4.800000000000001e-06,
      "loss": 1.1659,
      "step": 80
    },
    {
      "epoch": 0.0045,
      "grad_norm": 1.3067033290863037,
      "learning_rate": 5.4e-06,
      "loss": 1.1926,
      "step": 90
    },
    {
      "step": 100,
      "wer/bud500": 0.20606893325927442
    },
    {
      "step": 100,
      "wer/private": 0.3755656108597285
    },
    {
      "epoch": 0.005,
      "grad_norm": 1.3145649433135986,
      "learning_rate": 6e-06,
      "loss": 1.1637,
      "step": 100
    },
    {
      "epoch": 0.005,
      "eval_loss": 1.0916683673858643,
      "eval_runtime": 225.4242,
      "eval_samples_per_second": 33.271,
      "eval_steps_per_second": 0.523,
      "step": 100
    },
    {
      "epoch": 0.0055,
      "grad_norm": 1.3691405057907104,
      "learning_rate": 6.6e-06,
      "loss": 1.1723,
      "step": 110
    },
    {
      "epoch": 0.006,
      "grad_norm": 1.3739697933197021,
      "learning_rate": 7.2e-06,
      "loss": 1.1271,
      "step": 120
    },
    {
      "epoch": 0.0065,
      "grad_norm": 1.3754749298095703,
      "learning_rate": 7.8e-06,
      "loss": 1.1439,
      "step": 130
    },
    {
      "epoch": 0.007,
      "grad_norm": 1.4429779052734375,
      "learning_rate": 8.400000000000001e-06,
      "loss": 1.1023,
      "step": 140
    },
    {
      "step": 150,
      "wer/bud500": 0.21060016955593885
    },
    {
      "step": 150,
      "wer/private": 0.37104072398190047
    },
    {
      "epoch": 0.0075,
      "grad_norm": 1.4255735874176025,
      "learning_rate": 9e-06,
      "loss": 1.0506,
      "step": 150
    },
    {
      "epoch": 0.008,
      "grad_norm": 1.5713790655136108,
      "learning_rate": 9.600000000000001e-06,
      "loss": 1.0619,
      "step": 160
    },
    {
      "epoch": 0.0085,
      "grad_norm": 1.5211505889892578,
      "learning_rate": 1.02e-05,
      "loss": 1.0184,
      "step": 170
    },
    {
      "epoch": 0.009,
      "grad_norm": 1.6800501346588135,
      "learning_rate": 1.08e-05,
      "loss": 0.9974,
      "step": 180
    },
    {
      "epoch": 0.0095,
      "grad_norm": 1.706877589225769,
      "learning_rate": 1.1400000000000001e-05,
      "loss": 0.9556,
      "step": 190
    },
    {
      "step": 200,
      "wer/bud500": 0.21299733972578713
    },
    {
      "step": 200,
      "wer/private": 0.3755656108597285
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.723962426185608,
      "learning_rate": 1.2e-05,
      "loss": 0.8982,
      "step": 200
    },
    {
      "epoch": 0.01,
      "eval_loss": 0.8103893995285034,
      "eval_runtime": 218.0578,
      "eval_samples_per_second": 34.395,
      "eval_steps_per_second": 0.541,
      "step": 200
    },
    {
      "epoch": 0.0105,
      "grad_norm": 1.780524492263794,
      "learning_rate": 1.26e-05,
      "loss": 0.8777,
      "step": 210
    },
    {
      "epoch": 0.011,
      "grad_norm": 1.9197006225585938,
      "learning_rate": 1.32e-05,
      "loss": 0.7887,
      "step": 220
    },
    {
      "epoch": 0.0115,
      "grad_norm": 1.8761988878250122,
      "learning_rate": 1.3800000000000002e-05,
      "loss": 0.7509,
      "step": 230
    },
    {
      "epoch": 0.012,
      "grad_norm": 1.9830141067504883,
      "learning_rate": 1.44e-05,
      "loss": 0.6586,
      "step": 240
    },
    {
      "step": 250,
      "wer/bud500": 0.2469962288420499
    },
    {
      "step": 250,
      "wer/private": 0.36877828054298645
    },
    {
      "epoch": 0.0125,
      "grad_norm": 2.165679693222046,
      "learning_rate": 1.5e-05,
      "loss": 0.602,
      "step": 250
    },
    {
      "epoch": 0.013,
      "grad_norm": 2.32978892326355,
      "learning_rate": 1.56e-05,
      "loss": 0.5317,
      "step": 260
    },
    {
      "epoch": 0.0135,
      "grad_norm": 2.090322732925415,
      "learning_rate": 1.62e-05,
      "loss": 0.418,
      "step": 270
    },
    {
      "epoch": 0.014,
      "grad_norm": 1.4393947124481201,
      "learning_rate": 1.6800000000000002e-05,
      "loss": 0.3135,
      "step": 280
    },
    {
      "epoch": 0.0145,
      "grad_norm": 1.0231808423995972,
      "learning_rate": 1.74e-05,
      "loss": 0.2607,
      "step": 290
    },
    {
      "step": 300,
      "wer/bud500": 0.11252082907007338
    },
    {
      "step": 300,
      "wer/private": 0.25452488687782804
    },
    {
      "epoch": 0.015,
      "grad_norm": 0.7373087406158447,
      "learning_rate": 1.8e-05,
      "loss": 0.2413,
      "step": 300
    },
    {
      "epoch": 0.015,
      "eval_loss": 0.15074338018894196,
      "eval_runtime": 219.1816,
      "eval_samples_per_second": 34.218,
      "eval_steps_per_second": 0.538,
      "step": 300
    },
    {
      "epoch": 0.0155,
      "grad_norm": 0.6370435357093811,
      "learning_rate": 1.86e-05,
      "loss": 0.2137,
      "step": 310
    },
    {
      "epoch": 0.016,
      "grad_norm": 0.6107124090194702,
      "learning_rate": 1.9200000000000003e-05,
      "loss": 0.2131,
      "step": 320
    },
    {
      "epoch": 0.0165,
      "grad_norm": 0.5037177801132202,
      "learning_rate": 1.98e-05,
      "loss": 0.2008,
      "step": 330
    },
    {
      "epoch": 0.017,
      "grad_norm": 0.5559792518615723,
      "learning_rate": 2.04e-05,
      "loss": 0.2071,
      "step": 340
    },
    {
      "step": 350,
      "wer/bud500": 0.09623761218464057
    },
    {
      "step": 350,
      "wer/private": 0.25339366515837103
    },
    {
      "epoch": 0.0175,
      "grad_norm": 0.5556575655937195,
      "learning_rate": 2.1e-05,
      "loss": 0.2099,
      "step": 350
    },
    {
      "epoch": 0.018,
      "grad_norm": 0.4563068449497223,
      "learning_rate": 2.16e-05,
      "loss": 0.2043,
      "step": 360
    },
    {
      "epoch": 0.0185,
      "grad_norm": 0.6103417873382568,
      "learning_rate": 2.22e-05,
      "loss": 0.1953,
      "step": 370
    },
    {
      "epoch": 0.019,
      "grad_norm": 0.5520091652870178,
      "learning_rate": 2.2800000000000002e-05,
      "loss": 0.1906,
      "step": 380
    },
    {
      "epoch": 0.0195,
      "grad_norm": 0.5308763980865479,
      "learning_rate": 2.3400000000000003e-05,
      "loss": 0.1901,
      "step": 390
    },
    {
      "step": 400,
      "wer/bud500": 0.0922325839740404
    },
    {
      "step": 400,
      "wer/private": 0.252262443438914
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4286426603794098,
      "learning_rate": 2.4e-05,
      "loss": 0.1836,
      "step": 400
    },
    {
      "epoch": 0.02,
      "eval_loss": 0.1255994737148285,
      "eval_runtime": 222.1002,
      "eval_samples_per_second": 33.769,
      "eval_steps_per_second": 0.531,
      "step": 400
    },
    {
      "epoch": 0.0205,
      "grad_norm": 0.7278167605400085,
      "learning_rate": 2.4599999999999998e-05,
      "loss": 0.1782,
      "step": 410
    },
    {
      "epoch": 0.021,
      "grad_norm": 0.5049126148223877,
      "learning_rate": 2.52e-05,
      "loss": 0.189,
      "step": 420
    },
    {
      "epoch": 0.0215,
      "grad_norm": 0.687451183795929,
      "learning_rate": 2.58e-05,
      "loss": 0.2074,
      "step": 430
    },
    {
      "epoch": 0.022,
      "grad_norm": 0.46270883083343506,
      "learning_rate": 2.64e-05,
      "loss": 0.1988,
      "step": 440
    },
    {
      "step": 450,
      "wer/bud500": 0.08309702692431374
    },
    {
      "step": 450,
      "wer/private": 0.25
    },
    {
      "epoch": 0.0225,
      "grad_norm": 0.5178572535514832,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 0.2012,
      "step": 450
    },
    {
      "epoch": 0.023,
      "grad_norm": 0.39762794971466064,
      "learning_rate": 2.7600000000000003e-05,
      "loss": 0.1782,
      "step": 460
    },
    {
      "epoch": 0.0235,
      "grad_norm": 0.4396381676197052,
      "learning_rate": 2.8199999999999998e-05,
      "loss": 0.1886,
      "step": 470
    },
    {
      "epoch": 0.024,
      "grad_norm": 0.48219719529151917,
      "learning_rate": 2.88e-05,
      "loss": 0.1907,
      "step": 480
    },
    {
      "epoch": 0.0245,
      "grad_norm": 0.41088953614234924,
      "learning_rate": 2.94e-05,
      "loss": 0.1794,
      "step": 490
    },
    {
      "step": 500,
      "wer/bud500": 0.08075832431958371
    },
    {
      "step": 500,
      "wer/private": 0.2579185520361991
    },
    {
      "epoch": 0.025,
      "grad_norm": 0.3903321623802185,
      "learning_rate": 3e-05,
      "loss": 0.1842,
      "step": 500
    },
    {
      "epoch": 0.025,
      "eval_loss": 0.11750764399766922,
      "eval_runtime": 219.8161,
      "eval_samples_per_second": 34.119,
      "eval_steps_per_second": 0.537,
      "step": 500
    },
    {
      "epoch": 0.0255,
      "grad_norm": 0.483424574136734,
      "learning_rate": 2.9999980533328867e-05,
      "loss": 0.1821,
      "step": 510
    },
    {
      "epoch": 0.026,
      "grad_norm": 0.42637336254119873,
      "learning_rate": 2.999992213336598e-05,
      "loss": 0.1871,
      "step": 520
    },
    {
      "epoch": 0.0265,
      "grad_norm": 0.4728187322616577,
      "learning_rate": 2.9999824800262928e-05,
      "loss": 0.1954,
      "step": 530
    },
    {
      "epoch": 0.027,
      "grad_norm": 0.5088319778442383,
      "learning_rate": 2.9999688534272348e-05,
      "loss": 0.1917,
      "step": 540
    },
    {
      "step": 550,
      "wer/bud500": 0.07974975882129388
    },
    {
      "step": 550,
      "wer/private": 0.2737556561085973
    },
    {
      "epoch": 0.0275,
      "grad_norm": 0.40615400671958923,
      "learning_rate": 2.999951333574792e-05,
      "loss": 0.1874,
      "step": 550
    },
    {
      "epoch": 0.028,
      "grad_norm": 0.43472328782081604,
      "learning_rate": 2.9999299205144383e-05,
      "loss": 0.188,
      "step": 560
    },
    {
      "epoch": 0.0285,
      "grad_norm": 0.471576452255249,
      "learning_rate": 2.999904614301752e-05,
      "loss": 0.1853,
      "step": 570
    },
    {
      "epoch": 0.029,
      "grad_norm": 0.5839901566505432,
      "learning_rate": 2.9998754150024177e-05,
      "loss": 0.1759,
      "step": 580
    },
    {
      "epoch": 0.0295,
      "grad_norm": 0.5199564695358276,
      "learning_rate": 2.9998423226922234e-05,
      "loss": 0.1756,
      "step": 590
    },
    {
      "step": 600,
      "wer/bud500": 0.078375771041015
    },
    {
      "step": 600,
      "wer/private": 0.26131221719457015
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.42772698402404785,
      "learning_rate": 2.9998053374570622e-05,
      "loss": 0.1743,
      "step": 600
    },
    {
      "epoch": 0.03,
      "eval_loss": 0.11265940219163895,
      "eval_runtime": 220.3129,
      "eval_samples_per_second": 34.042,
      "eval_steps_per_second": 0.536,
      "step": 600
    },
    {
      "epoch": 0.0305,
      "grad_norm": 0.4817982316017151,
      "learning_rate": 2.9997644593929307e-05,
      "loss": 0.1744,
      "step": 610
    },
    {
      "epoch": 0.031,
      "grad_norm": 0.41380006074905396,
      "learning_rate": 2.9997196886059313e-05,
      "loss": 0.1672,
      "step": 620
    },
    {
      "epoch": 0.0315,
      "grad_norm": 0.4351097047328949,
      "learning_rate": 2.9996710252122685e-05,
      "loss": 0.1768,
      "step": 630
    },
    {
      "epoch": 0.032,
      "grad_norm": 0.3854909837245941,
      "learning_rate": 2.99961846933825e-05,
      "loss": 0.1591,
      "step": 640
    },
    {
      "step": 650,
      "wer/bud500": 0.07790803052006899
    },
    {
      "step": 650,
      "wer/private": 0.27262443438914025
    },
    {
      "epoch": 0.0325,
      "grad_norm": 0.4742094576358795,
      "learning_rate": 2.9995620211202898e-05,
      "loss": 0.1845,
      "step": 650
    },
    {
      "epoch": 0.033,
      "grad_norm": 0.42761924862861633,
      "learning_rate": 2.9995016807049e-05,
      "loss": 0.1798,
      "step": 660
    },
    {
      "epoch": 0.0335,
      "grad_norm": 0.37104305624961853,
      "learning_rate": 2.999437448248699e-05,
      "loss": 0.1745,
      "step": 670
    },
    {
      "epoch": 0.034,
      "grad_norm": 0.3709103465080261,
      "learning_rate": 2.9993693239184054e-05,
      "loss": 0.1744,
      "step": 680
    },
    {
      "epoch": 0.0345,
      "grad_norm": 0.39557966589927673,
      "learning_rate": 2.9992973078908392e-05,
      "loss": 0.1885,
      "step": 690
    },
    {
      "step": 700,
      "wer/bud500": 0.07701640015201566
    },
    {
      "step": 700,
      "wer/private": 0.25904977375565613
    },
    {
      "epoch": 0.035,
      "grad_norm": 0.3610558807849884,
      "learning_rate": 2.9992214003529226e-05,
      "loss": 0.1698,
      "step": 700
    },
    {
      "epoch": 0.035,
      "eval_loss": 0.10914572328329086,
      "eval_runtime": 218.8067,
      "eval_samples_per_second": 34.277,
      "eval_steps_per_second": 0.27,
      "step": 700
    },
    {
      "epoch": 0.0355,
      "grad_norm": 0.3939100205898285,
      "learning_rate": 2.999141601501678e-05,
      "loss": 0.1666,
      "step": 710
    },
    {
      "epoch": 0.036,
      "grad_norm": 0.36111918091773987,
      "learning_rate": 2.999057911544227e-05,
      "loss": 0.165,
      "step": 720
    },
    {
      "epoch": 0.0365,
      "grad_norm": 0.39429447054862976,
      "learning_rate": 2.9989703306977923e-05,
      "loss": 0.1923,
      "step": 730
    },
    {
      "epoch": 0.037,
      "grad_norm": 0.33373406529426575,
      "learning_rate": 2.998878859189695e-05,
      "loss": 0.1715,
      "step": 740
    },
    {
      "step": 750,
      "wer/bud500": 0.07691408191305873
    },
    {
      "step": 750,
      "wer/private": 0.2703619909502262
    },
    {
      "epoch": 0.0375,
      "grad_norm": 0.44275274872779846,
      "learning_rate": 2.9987834972573544e-05,
      "loss": 0.1597,
      "step": 750
    },
    {
      "epoch": 0.038,
      "grad_norm": 0.39002329111099243,
      "learning_rate": 2.9986842451482876e-05,
      "loss": 0.1725,
      "step": 760
    },
    {
      "epoch": 0.0385,
      "grad_norm": 0.5008683800697327,
      "learning_rate": 2.9985811031201086e-05,
      "loss": 0.1727,
      "step": 770
    },
    {
      "epoch": 0.039,
      "grad_norm": 0.35061824321746826,
      "learning_rate": 2.9984740714405295e-05,
      "loss": 0.1769,
      "step": 780
    },
    {
      "epoch": 0.0395,
      "grad_norm": 0.3933698236942291,
      "learning_rate": 2.9983631503873558e-05,
      "loss": 0.1837,
      "step": 790
    },
    {
      "step": 800,
      "wer/bud500": 0.07597860087116672
    },
    {
      "step": 800,
      "wer/private": 0.48981900452488686
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4157435894012451,
      "learning_rate": 2.99824834024849e-05,
      "loss": 0.167,
      "step": 800
    },
    {
      "epoch": 0.04,
      "eval_loss": 0.10811491310596466,
      "eval_runtime": 217.303,
      "eval_samples_per_second": 34.514,
      "eval_steps_per_second": 0.272,
      "step": 800
    },
    {
      "epoch": 0.0405,
      "grad_norm": 0.3385310173034668,
      "learning_rate": 2.998129641321928e-05,
      "loss": 0.1808,
      "step": 810
    },
    {
      "epoch": 0.041,
      "grad_norm": 0.4489861726760864,
      "learning_rate": 2.99800705391576e-05,
      "loss": 0.1563,
      "step": 820
    },
    {
      "epoch": 0.0415,
      "grad_norm": 0.4283549189567566,
      "learning_rate": 2.9978805783481677e-05,
      "loss": 0.1669,
      "step": 830
    },
    {
      "epoch": 0.042,
      "grad_norm": 0.41893163323402405,
      "learning_rate": 2.997750214947426e-05,
      "loss": 0.1745,
      "step": 840
    },
    {
      "step": 850,
      "wer/bud500": 0.0753646914374251
    },
    {
      "step": 850,
      "wer/private": 0.2703619909502262
    },
    {
      "epoch": 0.0425,
      "grad_norm": 0.33199480175971985,
      "learning_rate": 2.9976159640519e-05,
      "loss": 0.1549,
      "step": 850
    },
    {
      "epoch": 0.043,
      "grad_norm": 0.40314123034477234,
      "learning_rate": 2.9974778260100463e-05,
      "loss": 0.18,
      "step": 860
    },
    {
      "epoch": 0.0435,
      "grad_norm": 0.3368396759033203,
      "learning_rate": 2.9973358011804094e-05,
      "loss": 0.1623,
      "step": 870
    },
    {
      "epoch": 0.044,
      "grad_norm": 0.42882585525512695,
      "learning_rate": 2.997189889931623e-05,
      "loss": 0.1762,
      "step": 880
    },
    {
      "epoch": 0.0445,
      "grad_norm": 0.35238251090049744,
      "learning_rate": 2.9970400926424075e-05,
      "loss": 0.1672,
      "step": 890
    },
    {
      "step": 900,
      "wer/bud500": 0.07510158739439296
    },
    {
      "step": 900,
      "wer/private": 0.27149321266968324
    },
    {
      "epoch": 0.045,
      "grad_norm": 0.39133670926094055,
      "learning_rate": 2.9968864097015703e-05,
      "loss": 0.1674,
      "step": 900
    },
    {
      "epoch": 0.045,
      "eval_loss": 0.10579393059015274,
      "eval_runtime": 217.9139,
      "eval_samples_per_second": 34.417,
      "eval_steps_per_second": 0.271,
      "step": 900
    },
    {
      "epoch": 0.0455,
      "grad_norm": 0.37634050846099854,
      "learning_rate": 2.9967288415080043e-05,
      "loss": 0.149,
      "step": 910
    },
    {
      "epoch": 0.046,
      "grad_norm": 0.41613835096359253,
      "learning_rate": 2.9965673884706868e-05,
      "loss": 0.1805,
      "step": 920
    },
    {
      "epoch": 0.0465,
      "grad_norm": 0.3455665707588196,
      "learning_rate": 2.9964020510086772e-05,
      "loss": 0.1811,
      "step": 930
    },
    {
      "epoch": 0.047,
      "grad_norm": 0.3507576286792755,
      "learning_rate": 2.9962328295511194e-05,
      "loss": 0.1774,
      "step": 940
    },
    {
      "step": 950,
      "wer/bud500": 0.07447306106937177
    },
    {
      "step": 950,
      "wer/private": 0.26131221719457015
    },
    {
      "epoch": 0.0475,
      "grad_norm": 0.40092918276786804,
      "learning_rate": 2.996059724537237e-05,
      "loss": 0.1695,
      "step": 950
    },
    {
      "epoch": 0.048,
      "grad_norm": 0.38651707768440247,
      "learning_rate": 2.9958827364163326e-05,
      "loss": 0.1774,
      "step": 960
    },
    {
      "epoch": 0.0485,
      "grad_norm": 0.4066857397556305,
      "learning_rate": 2.99570186564779e-05,
      "loss": 0.1686,
      "step": 970
    },
    {
      "epoch": 0.049,
      "grad_norm": 0.3658124804496765,
      "learning_rate": 2.9955171127010695e-05,
      "loss": 0.1538,
      "step": 980
    },
    {
      "epoch": 0.0495,
      "grad_norm": 0.5064461827278137,
      "learning_rate": 2.9953284780557073e-05,
      "loss": 0.1618,
      "step": 990
    },
    {
      "step": 1000,
      "wer/bud500": 0.07366913204899582
    },
    {
      "step": 1000,
      "wer/private": 0.26244343891402716
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3277958631515503,
      "learning_rate": 2.995135962201315e-05,
      "loss": 0.1593,
      "step": 1000
    },
    {
      "epoch": 0.05,
      "eval_loss": 0.10411778837442398,
      "eval_runtime": 217.8195,
      "eval_samples_per_second": 34.432,
      "eval_steps_per_second": 0.271,
      "step": 1000
    },
    {
      "epoch": 0.0505,
      "grad_norm": 0.4059562385082245,
      "learning_rate": 2.994939565637579e-05,
      "loss": 0.1724,
      "step": 1010
    },
    {
      "epoch": 0.051,
      "grad_norm": 0.40819162130355835,
      "learning_rate": 2.9947392888742566e-05,
      "loss": 0.1764,
      "step": 1020
    },
    {
      "epoch": 0.0515,
      "grad_norm": 0.3684094250202179,
      "learning_rate": 2.9945351324311784e-05,
      "loss": 0.1711,
      "step": 1030
    },
    {
      "epoch": 0.052,
      "grad_norm": 0.35685914754867554,
      "learning_rate": 2.994327096838243e-05,
      "loss": 0.1651,
      "step": 1040
    },
    {
      "step": 1050,
      "wer/bud500": 0.0738737685269097
    },
    {
      "step": 1050,
      "wer/private": 0.4468325791855204
    },
    {
      "epoch": 0.0525,
      "grad_norm": 0.3516932427883148,
      "learning_rate": 2.9941151826354196e-05,
      "loss": 0.1776,
      "step": 1050
    },
    {
      "epoch": 0.053,
      "grad_norm": 0.38624680042266846,
      "learning_rate": 2.993899390372742e-05,
      "loss": 0.1721,
      "step": 1060
    },
    {
      "epoch": 0.0535,
      "grad_norm": 0.3687388300895691,
      "learning_rate": 2.9936797206103126e-05,
      "loss": 0.1788,
      "step": 1070
    },
    {
      "epoch": 0.054,
      "grad_norm": 0.4099695384502411,
      "learning_rate": 2.993456173918296e-05,
      "loss": 0.1602,
      "step": 1080
    },
    {
      "epoch": 0.0545,
      "grad_norm": 0.40674903988838196,
      "learning_rate": 2.9932287508769194e-05,
      "loss": 0.1643,
      "step": 1090
    },
    {
      "step": 1100,
      "wer/bud500": 0.07510158739439296
    },
    {
      "step": 1100,
      "wer/private": 0.26131221719457015
    },
    {
      "epoch": 0.055,
      "grad_norm": 0.3523021936416626,
      "learning_rate": 2.992997452076473e-05,
      "loss": 0.1551,
      "step": 1100
    },
    {
      "epoch": 0.055,
      "eval_loss": 0.10281307250261307,
      "eval_runtime": 217.8592,
      "eval_samples_per_second": 34.426,
      "eval_steps_per_second": 0.271,
      "step": 1100
    },
    {
      "epoch": 0.0555,
      "grad_norm": 0.43583953380584717,
      "learning_rate": 2.9927622781173057e-05,
      "loss": 0.159,
      "step": 1110
    },
    {
      "epoch": 0.056,
      "grad_norm": 0.36748942732810974,
      "learning_rate": 2.9925232296098246e-05,
      "loss": 0.163,
      "step": 1120
    },
    {
      "epoch": 0.0565,
      "grad_norm": 0.4003927707672119,
      "learning_rate": 2.9922803071744933e-05,
      "loss": 0.1849,
      "step": 1130
    },
    {
      "epoch": 0.057,
      "grad_norm": 0.35056042671203613,
      "learning_rate": 2.9920335114418313e-05,
      "loss": 0.1596,
      "step": 1140
    },
    {
      "step": 1150,
      "wer/bud500": 0.07444382728681265
    },
    {
      "step": 1150,
      "wer/private": 0.2658371040723982
    },
    {
      "epoch": 0.0575,
      "grad_norm": 0.4216572344303131,
      "learning_rate": 2.99178284305241e-05,
      "loss": 0.1696,
      "step": 1150
    },
    {
      "epoch": 0.058,
      "grad_norm": 0.31442832946777344,
      "learning_rate": 2.991528302656854e-05,
      "loss": 0.1438,
      "step": 1160
    },
    {
      "epoch": 0.0585,
      "grad_norm": 0.28466105461120605,
      "learning_rate": 2.9912698909158366e-05,
      "loss": 0.1483,
      "step": 1170
    },
    {
      "epoch": 0.059,
      "grad_norm": 0.4735057055950165,
      "learning_rate": 2.9910076085000798e-05,
      "loss": 0.1629,
      "step": 1180
    },
    {
      "epoch": 0.0595,
      "grad_norm": 0.3883199989795685,
      "learning_rate": 2.990741456090353e-05,
      "loss": 0.1655,
      "step": 1190
    },
    {
      "step": 1200,
      "wer/bud500": 0.07400532054842576
    },
    {
      "step": 1200,
      "wer/private": 0.2669683257918552
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3926047086715698,
      "learning_rate": 2.9904714343774698e-05,
      "loss": 0.1657,
      "step": 1200
    },
    {
      "epoch": 0.06,
      "eval_loss": 0.10170678049325943,
      "eval_runtime": 216.7274,
      "eval_samples_per_second": 34.606,
      "eval_steps_per_second": 0.272,
      "step": 1200
    },
    {
      "epoch": 0.0605,
      "grad_norm": 0.3787575364112854,
      "learning_rate": 2.990197544062286e-05,
      "loss": 0.1672,
      "step": 1210
    },
    {
      "epoch": 0.061,
      "grad_norm": 0.44946929812431335,
      "learning_rate": 2.9899197858557e-05,
      "loss": 0.1668,
      "step": 1220
    },
    {
      "epoch": 0.0615,
      "grad_norm": 0.485760897397995,
      "learning_rate": 2.9896381604786476e-05,
      "loss": 0.1547,
      "step": 1230
    },
    {
      "epoch": 0.062,
      "grad_norm": 0.40915146470069885,
      "learning_rate": 2.989352668662105e-05,
      "loss": 0.1625,
      "step": 1240
    },
    {
      "step": 1250,
      "wer/bud500": 0.0737568333966732
    },
    {
      "step": 1250,
      "wer/private": 0.2669683257918552
    },
    {
      "epoch": 0.0625,
      "grad_norm": 0.42740368843078613,
      "learning_rate": 2.9890633111470808e-05,
      "loss": 0.1664,
      "step": 1250
    },
    {
      "epoch": 0.063,
      "grad_norm": 0.42419669032096863,
      "learning_rate": 2.98877008868462e-05,
      "loss": 0.1537,
      "step": 1260
    },
    {
      "epoch": 0.0635,
      "grad_norm": 0.3692646026611328,
      "learning_rate": 2.9884730020357967e-05,
      "loss": 0.1544,
      "step": 1270
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.3984656035900116,
      "learning_rate": 2.988172051971717e-05,
      "loss": 0.1714,
      "step": 1280
    },
    {
      "epoch": 0.0645,
      "grad_norm": 0.4577641785144806,
      "learning_rate": 2.987867239273513e-05,
      "loss": 0.1803,
      "step": 1290
    },
    {
      "step": 1300,
      "wer/bud500": 0.07396146987458707
    },
    {
      "step": 1300,
      "wer/private": 0.4321266968325792
    },
    {
      "epoch": 0.065,
      "grad_norm": 0.3843790292739868,
      "learning_rate": 2.987558564732343e-05,
      "loss": 0.1736,
      "step": 1300
    },
    {
      "epoch": 0.065,
      "eval_loss": 0.101052425801754,
      "eval_runtime": 214.8518,
      "eval_samples_per_second": 34.908,
      "eval_steps_per_second": 0.275,
      "step": 1300
    },
    {
      "epoch": 0.0655,
      "grad_norm": 0.39868777990341187,
      "learning_rate": 2.98724602914939e-05,
      "loss": 0.1707,
      "step": 1310
    },
    {
      "epoch": 0.066,
      "grad_norm": 0.4412910044193268,
      "learning_rate": 2.9869296333358566e-05,
      "loss": 0.1635,
      "step": 1320
    },
    {
      "epoch": 0.0665,
      "grad_norm": 0.4258248805999756,
      "learning_rate": 2.986609378112967e-05,
      "loss": 0.1513,
      "step": 1330
    },
    {
      "epoch": 0.067,
      "grad_norm": 0.3957265615463257,
      "learning_rate": 2.986285264311961e-05,
      "loss": 0.162,
      "step": 1340
    },
    {
      "step": 1350,
      "wer/bud500": 0.07344987867980238
    },
    {
      "step": 1350,
      "wer/private": 0.4423076923076923
    },
    {
      "epoch": 0.0675,
      "grad_norm": 0.39959508180618286,
      "learning_rate": 2.9859572927740938e-05,
      "loss": 0.16,
      "step": 1350
    },
    {
      "epoch": 0.068,
      "grad_norm": 0.46719351410865784,
      "learning_rate": 2.985625464350635e-05,
      "loss": 0.1731,
      "step": 1360
    },
    {
      "epoch": 0.0685,
      "grad_norm": 0.38802024722099304,
      "learning_rate": 2.985289779902863e-05,
      "loss": 0.1718,
      "step": 1370
    },
    {
      "epoch": 0.069,
      "grad_norm": 0.342489093542099,
      "learning_rate": 2.9849502403020656e-05,
      "loss": 0.1616,
      "step": 1380
    },
    {
      "epoch": 0.0695,
      "grad_norm": 0.36017581820487976,
      "learning_rate": 2.984606846429538e-05,
      "loss": 0.1568,
      "step": 1390
    },
    {
      "step": 1400,
      "wer/bud500": 0.07660712719618791
    },
    {
      "step": 1400,
      "wer/private": 0.4762443438914027
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.39407217502593994,
      "learning_rate": 2.9842595991765766e-05,
      "loss": 0.1774,
      "step": 1400
    },
    {
      "epoch": 0.07,
      "eval_loss": 0.10048815608024597,
      "eval_runtime": 207.7277,
      "eval_samples_per_second": 36.105,
      "eval_steps_per_second": 0.284,
      "step": 1400
    },
    {
      "epoch": 0.0705,
      "grad_norm": 0.4881211221218109,
      "learning_rate": 2.983908499444483e-05,
      "loss": 0.1836,
      "step": 1410
    },
    {
      "epoch": 0.071,
      "grad_norm": 0.35913634300231934,
      "learning_rate": 2.9835535481445543e-05,
      "loss": 0.1674,
      "step": 1420
    },
    {
      "epoch": 0.0715,
      "grad_norm": 0.41914960741996765,
      "learning_rate": 2.9831947461980877e-05,
      "loss": 0.1549,
      "step": 1430
    },
    {
      "epoch": 0.072,
      "grad_norm": 0.35237282514572144,
      "learning_rate": 2.982832094536374e-05,
      "loss": 0.1517,
      "step": 1440
    },
    {
      "step": 1450,
      "wer/bud500": 0.07586166574093021
    },
    {
      "step": 1450,
      "wer/private": 0.43778280542986425
    },
    {
      "epoch": 0.0725,
      "grad_norm": 0.4207838177680969,
      "learning_rate": 2.9824655941006956e-05,
      "loss": 0.1704,
      "step": 1450
    },
    {
      "epoch": 0.073,
      "grad_norm": 0.427310973405838,
      "learning_rate": 2.9820952458423247e-05,
      "loss": 0.1642,
      "step": 1460
    },
    {
      "epoch": 0.0735,
      "grad_norm": 0.42406579852104187,
      "learning_rate": 2.9817210507225217e-05,
      "loss": 0.1703,
      "step": 1470
    },
    {
      "epoch": 0.074,
      "grad_norm": 0.367951363325119,
      "learning_rate": 2.9813430097125304e-05,
      "loss": 0.1516,
      "step": 1480
    },
    {
      "epoch": 0.0745,
      "grad_norm": 0.3771679401397705,
      "learning_rate": 2.9809611237935773e-05,
      "loss": 0.1677,
      "step": 1490
    },
    {
      "step": 1500,
      "wer/bud500": 0.07596398397988716
    },
    {
      "step": 1500,
      "wer/private": 0.47398190045248867
    },
    {
      "epoch": 0.075,
      "grad_norm": 0.4265687167644501,
      "learning_rate": 2.980575393956869e-05,
      "loss": 0.1736,
      "step": 1500
    },
    {
      "epoch": 0.075,
      "eval_loss": 0.09943569451570511,
      "eval_runtime": 207.9073,
      "eval_samples_per_second": 36.074,
      "eval_steps_per_second": 0.284,
      "step": 1500
    },
    {
      "epoch": 0.0755,
      "grad_norm": 0.3403170704841614,
      "learning_rate": 2.98018582120359e-05,
      "loss": 0.1617,
      "step": 1510
    },
    {
      "epoch": 0.076,
      "grad_norm": 0.6724584102630615,
      "learning_rate": 2.9797924065448962e-05,
      "loss": 0.1572,
      "step": 1520
    },
    {
      "epoch": 0.0765,
      "grad_norm": 0.3594100773334503,
      "learning_rate": 2.9793951510019194e-05,
      "loss": 0.1624,
      "step": 1530
    },
    {
      "epoch": 0.077,
      "grad_norm": 0.3883090317249298,
      "learning_rate": 2.9789940556057574e-05,
      "loss": 0.1615,
      "step": 1540
    },
    {
      "step": 1550,
      "wer/bud500": 0.07540854211126377
    },
    {
      "step": 1550,
      "wer/private": 0.4502262443438914
    },
    {
      "epoch": 0.0775,
      "grad_norm": 0.38159218430519104,
      "learning_rate": 2.9785891213974764e-05,
      "loss": 0.1628,
      "step": 1550
    },
    {
      "epoch": 0.078,
      "grad_norm": 0.41644537448883057,
      "learning_rate": 2.9781803494281053e-05,
      "loss": 0.1644,
      "step": 1560
    },
    {
      "epoch": 0.0785,
      "grad_norm": 0.41115549206733704,
      "learning_rate": 2.9777677407586357e-05,
      "loss": 0.1688,
      "step": 1570
    },
    {
      "epoch": 0.079,
      "grad_norm": 0.3615078330039978,
      "learning_rate": 2.977351296460016e-05,
      "loss": 0.1771,
      "step": 1580
    },
    {
      "epoch": 0.0795,
      "grad_norm": 0.46315184235572815,
      "learning_rate": 2.9769310176131506e-05,
      "loss": 0.1651,
      "step": 1590
    },
    {
      "step": 1600,
      "wer/bud500": 0.07182740374777093
    },
    {
      "step": 1600,
      "wer/private": 0.43552036199095023
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4597415626049042,
      "learning_rate": 2.9765069053088968e-05,
      "loss": 0.1664,
      "step": 1600
    },
    {
      "epoch": 0.08,
      "eval_loss": 0.09874502569437027,
      "eval_runtime": 216.7666,
      "eval_samples_per_second": 34.599,
      "eval_steps_per_second": 0.272,
      "step": 1600
    },
    {
      "epoch": 0.0805,
      "grad_norm": 0.4211621880531311,
      "learning_rate": 2.976078960648062e-05,
      "loss": 0.1706,
      "step": 1610
    },
    {
      "epoch": 0.081,
      "grad_norm": 0.38252291083335876,
      "learning_rate": 2.975647184741401e-05,
      "loss": 0.1671,
      "step": 1620
    },
    {
      "epoch": 0.0815,
      "grad_norm": 0.2990364730358124,
      "learning_rate": 2.975211578709612e-05,
      "loss": 0.1483,
      "step": 1630
    },
    {
      "epoch": 0.082,
      "grad_norm": 0.47737357020378113,
      "learning_rate": 2.9747721436833347e-05,
      "loss": 0.1614,
      "step": 1640
    },
    {
      "step": 1650,
      "wer/bud500": 0.07187125442160962
    },
    {
      "step": 1650,
      "wer/private": 0.4309954751131222
    },
    {
      "epoch": 0.0825,
      "grad_norm": 0.37987953424453735,
      "learning_rate": 2.9743288808031485e-05,
      "loss": 0.1734,
      "step": 1650
    },
    {
      "epoch": 0.083,
      "grad_norm": 0.4991976320743561,
      "learning_rate": 2.9738817912195657e-05,
      "loss": 0.1658,
      "step": 1660
    },
    {
      "epoch": 0.0835,
      "grad_norm": 0.6050231456756592,
      "learning_rate": 2.9734308760930333e-05,
      "loss": 0.1511,
      "step": 1670
    },
    {
      "epoch": 0.084,
      "grad_norm": 0.3731662631034851,
      "learning_rate": 2.972976136593926e-05,
      "loss": 0.1642,
      "step": 1680
    },
    {
      "epoch": 0.0845,
      "grad_norm": 0.41426458954811096,
      "learning_rate": 2.972517573902547e-05,
      "loss": 0.1713,
      "step": 1690
    },
    {
      "step": 1700,
      "wer/bud500": 0.0699564416639869
    },
    {
      "step": 1700,
      "wer/private": 0.2828054298642534
    },
    {
      "epoch": 0.085,
      "grad_norm": 0.5003159046173096,
      "learning_rate": 2.97205518920912e-05,
      "loss": 0.1577,
      "step": 1700
    },
    {
      "epoch": 0.085,
      "eval_loss": 0.09808729588985443,
      "eval_runtime": 218.9709,
      "eval_samples_per_second": 34.251,
      "eval_steps_per_second": 0.269,
      "step": 1700
    },
    {
      "epoch": 0.0855,
      "grad_norm": 0.3940739035606384,
      "learning_rate": 2.971588983713792e-05,
      "loss": 0.1646,
      "step": 1710
    },
    {
      "epoch": 0.086,
      "grad_norm": 0.39536288380622864,
      "learning_rate": 2.9711189586266242e-05,
      "loss": 0.1571,
      "step": 1720
    },
    {
      "epoch": 0.0865,
      "grad_norm": 0.5463908314704895,
      "learning_rate": 2.9706451151675937e-05,
      "loss": 0.1602,
      "step": 1730
    },
    {
      "epoch": 0.087,
      "grad_norm": 0.36205440759658813,
      "learning_rate": 2.9701674545665878e-05,
      "loss": 0.1588,
      "step": 1740
    },
    {
      "step": 1750,
      "wer/bud500": 0.07182740374777093
    },
    {
      "step": 1750,
      "wer/private": 0.43552036199095023
    },
    {
      "epoch": 0.0875,
      "grad_norm": 0.5184884667396545,
      "learning_rate": 2.9696859780634016e-05,
      "loss": 0.16,
      "step": 1750
    },
    {
      "epoch": 0.088,
      "grad_norm": 0.3651185631752014,
      "learning_rate": 2.969200686907734e-05,
      "loss": 0.1628,
      "step": 1760
    },
    {
      "epoch": 0.0885,
      "grad_norm": 0.43046796321868896,
      "learning_rate": 2.9687115823591856e-05,
      "loss": 0.1614,
      "step": 1770
    },
    {
      "epoch": 0.089,
      "grad_norm": 0.3891826570034027,
      "learning_rate": 2.9682186656872546e-05,
      "loss": 0.1544,
      "step": 1780
    },
    {
      "epoch": 0.0895,
      "grad_norm": 0.3397029936313629,
      "learning_rate": 2.9677219381713344e-05,
      "loss": 0.1441,
      "step": 1790
    },
    {
      "step": 1800,
      "wer/bud500": 0.07125734498786798
    },
    {
      "step": 1800,
      "wer/private": 0.4321266968325792
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3702440559864044,
      "learning_rate": 2.9672214011007087e-05,
      "loss": 0.1539,
      "step": 1800
    },
    {
      "epoch": 0.09,
      "eval_loss": 0.09735630452632904,
      "eval_runtime": 216.6746,
      "eval_samples_per_second": 34.614,
      "eval_steps_per_second": 0.272,
      "step": 1800
    },
    {
      "epoch": 0.0905,
      "grad_norm": 0.3480922281742096,
      "learning_rate": 2.9667170557745494e-05,
      "loss": 0.153,
      "step": 1810
    },
    {
      "epoch": 0.091,
      "grad_norm": 0.34608811140060425,
      "learning_rate": 2.9662089035019136e-05,
      "loss": 0.1625,
      "step": 1820
    },
    {
      "epoch": 0.0915,
      "grad_norm": 0.46481800079345703,
      "learning_rate": 2.9656969456017385e-05,
      "loss": 0.179,
      "step": 1830
    },
    {
      "epoch": 0.092,
      "grad_norm": 0.3806397020816803,
      "learning_rate": 2.9651811834028403e-05,
      "loss": 0.1563,
      "step": 1840
    },
    {
      "step": 1850,
      "wer/bud500": 0.06910866196977226
    },
    {
      "step": 1850,
      "wer/private": 0.44004524886877827
    },
    {
      "epoch": 0.0925,
      "grad_norm": 0.43863680958747864,
      "learning_rate": 2.964661618243908e-05,
      "loss": 0.1605,
      "step": 1850
    },
    {
      "epoch": 0.093,
      "grad_norm": 0.3960687816143036,
      "learning_rate": 2.964138251473503e-05,
      "loss": 0.161,
      "step": 1860
    },
    {
      "epoch": 0.0935,
      "grad_norm": 0.43284711241722107,
      "learning_rate": 2.9636110844500522e-05,
      "loss": 0.1658,
      "step": 1870
    },
    {
      "epoch": 0.094,
      "grad_norm": 0.4069449007511139,
      "learning_rate": 2.9630801185418477e-05,
      "loss": 0.1603,
      "step": 1880
    },
    {
      "epoch": 0.0945,
      "grad_norm": 0.36916980147361755,
      "learning_rate": 2.9625453551270415e-05,
      "loss": 0.1567,
      "step": 1890
    },
    {
      "step": 1900,
      "wer/bud500": 0.06906481129593359
    },
    {
      "step": 1900,
      "wer/private": 0.48642533936651583
    },
    {
      "epoch": 0.095,
      "grad_norm": 0.3891218304634094,
      "learning_rate": 2.962006795593642e-05,
      "loss": 0.1514,
      "step": 1900
    },
    {
      "epoch": 0.095,
      "eval_loss": 0.0968514159321785,
      "eval_runtime": 216.9761,
      "eval_samples_per_second": 34.566,
      "eval_steps_per_second": 0.272,
      "step": 1900
    },
    {
      "epoch": 0.0955,
      "grad_norm": 0.46836283802986145,
      "learning_rate": 2.9614644413395104e-05,
      "loss": 0.1607,
      "step": 1910
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.4268668591976166,
      "learning_rate": 2.9609182937723574e-05,
      "loss": 0.1558,
      "step": 1920
    },
    {
      "epoch": 0.0965,
      "grad_norm": 0.3648179769515991,
      "learning_rate": 2.9603683543097406e-05,
      "loss": 0.1624,
      "step": 1930
    },
    {
      "epoch": 0.097,
      "grad_norm": 0.4564841687679291,
      "learning_rate": 2.959814624379058e-05,
      "loss": 0.1684,
      "step": 1940
    },
    {
      "step": 1950,
      "wer/bud500": 0.06856783699242845
    },
    {
      "step": 1950,
      "wer/private": 0.4287330316742081
    },
    {
      "epoch": 0.0975,
      "grad_norm": 0.3630802035331726,
      "learning_rate": 2.9592571054175464e-05,
      "loss": 0.1509,
      "step": 1950
    },
    {
      "epoch": 0.098,
      "grad_norm": 0.49361222982406616,
      "learning_rate": 2.9586957988722788e-05,
      "loss": 0.172,
      "step": 1960
    },
    {
      "epoch": 0.0985,
      "grad_norm": 0.3392590582370758,
      "learning_rate": 2.958130706200157e-05,
      "loss": 0.1724,
      "step": 1970
    },
    {
      "epoch": 0.099,
      "grad_norm": 0.360135942697525,
      "learning_rate": 2.9575618288679113e-05,
      "loss": 0.163,
      "step": 1980
    },
    {
      "epoch": 0.0995,
      "grad_norm": 0.42814671993255615,
      "learning_rate": 2.9569891683520943e-05,
      "loss": 0.1601,
      "step": 1990
    },
    {
      "step": 2000,
      "wer/bud500": 0.07363989826643669
    },
    {
      "step": 2000,
      "wer/private": 0.4457013574660634
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.43529558181762695,
      "learning_rate": 2.956412726139078e-05,
      "loss": 0.1655,
      "step": 2000
    },
    {
      "epoch": 0.1,
      "eval_loss": 0.09642715752124786,
      "eval_runtime": 217.0664,
      "eval_samples_per_second": 34.552,
      "eval_steps_per_second": 0.272,
      "step": 2000
    },
    {
      "epoch": 0.1005,
      "grad_norm": 0.3816349506378174,
      "learning_rate": 2.9558325037250516e-05,
      "loss": 0.167,
      "step": 2010
    },
    {
      "epoch": 0.101,
      "grad_norm": 0.40493258833885193,
      "learning_rate": 2.9552485026160146e-05,
      "loss": 0.1515,
      "step": 2020
    },
    {
      "epoch": 0.1015,
      "grad_norm": 0.408777117729187,
      "learning_rate": 2.954660724327774e-05,
      "loss": 0.1522,
      "step": 2030
    },
    {
      "epoch": 0.102,
      "grad_norm": 0.42793112993240356,
      "learning_rate": 2.9540691703859428e-05,
      "loss": 0.172,
      "step": 2040
    },
    {
      "step": 2050,
      "wer/bud500": 0.07026339638085773
    },
    {
      "step": 2050,
      "wer/private": 0.48642533936651583
    },
    {
      "epoch": 0.1025,
      "grad_norm": 0.3447553813457489,
      "learning_rate": 2.9534738423259312e-05,
      "loss": 0.1488,
      "step": 2050
    },
    {
      "epoch": 0.103,
      "grad_norm": 0.3557588458061218,
      "learning_rate": 2.9528747416929467e-05,
      "loss": 0.1564,
      "step": 2060
    },
    {
      "epoch": 0.1035,
      "grad_norm": 0.49346572160720825,
      "learning_rate": 2.952271870041989e-05,
      "loss": 0.1763,
      "step": 2070
    },
    {
      "epoch": 0.104,
      "grad_norm": 0.5262685418128967,
      "learning_rate": 2.951665228937846e-05,
      "loss": 0.1659,
      "step": 2080
    },
    {
      "epoch": 0.1045,
      "grad_norm": 0.3701123297214508,
      "learning_rate": 2.9510548199550872e-05,
      "loss": 0.1667,
      "step": 2090
    },
    {
      "step": 2100,
      "wer/bud500": 0.06970795451223434
    },
    {
      "step": 2100,
      "wer/private": 0.4411764705882353
    },
    {
      "epoch": 0.105,
      "grad_norm": 0.3832330107688904,
      "learning_rate": 2.9504406446780648e-05,
      "loss": 0.176,
      "step": 2100
    },
    {
      "epoch": 0.105,
      "eval_loss": 0.09579432755708694,
      "eval_runtime": 216.7289,
      "eval_samples_per_second": 34.605,
      "eval_steps_per_second": 0.272,
      "step": 2100
    },
    {
      "epoch": 0.1055,
      "grad_norm": 0.37811988592147827,
      "learning_rate": 2.949822704700904e-05,
      "loss": 0.1566,
      "step": 2110
    },
    {
      "epoch": 0.106,
      "grad_norm": 0.3719038963317871,
      "learning_rate": 2.9492010016275036e-05,
      "loss": 0.1548,
      "step": 2120
    },
    {
      "epoch": 0.1065,
      "grad_norm": 0.34969189763069153,
      "learning_rate": 2.9485755370715287e-05,
      "loss": 0.1713,
      "step": 2130
    },
    {
      "epoch": 0.107,
      "grad_norm": 0.4091186821460724,
      "learning_rate": 2.9479463126564076e-05,
      "loss": 0.1578,
      "step": 2140
    },
    {
      "step": 2150,
      "wer/bud500": 0.06982488964247084
    },
    {
      "step": 2150,
      "wer/private": 0.2816742081447964
    },
    {
      "epoch": 0.1075,
      "grad_norm": 0.38846567273139954,
      "learning_rate": 2.9473133300153275e-05,
      "loss": 0.1594,
      "step": 2150
    },
    {
      "epoch": 0.108,
      "grad_norm": 0.3827771246433258,
      "learning_rate": 2.9466765907912303e-05,
      "loss": 0.1775,
      "step": 2160
    },
    {
      "epoch": 0.1085,
      "grad_norm": 0.3565116226673126,
      "learning_rate": 2.9460360966368083e-05,
      "loss": 0.1541,
      "step": 2170
    },
    {
      "epoch": 0.109,
      "grad_norm": 0.46095800399780273,
      "learning_rate": 2.945391849214501e-05,
      "loss": 0.1531,
      "step": 2180
    },
    {
      "epoch": 0.1095,
      "grad_norm": 0.42145004868507385,
      "learning_rate": 2.9447438501964873e-05,
      "loss": 0.1441,
      "step": 2190
    },
    {
      "step": 2200,
      "wer/bud500": 0.06928406466512702
    },
    {
      "step": 2200,
      "wer/private": 0.3031674208144796
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.4847191870212555,
      "learning_rate": 2.944092101264686e-05,
      "loss": 0.1577,
      "step": 2200
    },
    {
      "epoch": 0.11,
      "eval_loss": 0.09510084241628647,
      "eval_runtime": 217.7721,
      "eval_samples_per_second": 34.44,
      "eval_steps_per_second": 0.271,
      "step": 2200
    },
    {
      "epoch": 0.1105,
      "grad_norm": 0.41560640931129456,
      "learning_rate": 2.9434366041107482e-05,
      "loss": 0.1581,
      "step": 2210
    },
    {
      "epoch": 0.111,
      "grad_norm": 0.4173029065132141,
      "learning_rate": 2.9427773604360528e-05,
      "loss": 0.1662,
      "step": 2220
    },
    {
      "epoch": 0.1115,
      "grad_norm": 0.349006712436676,
      "learning_rate": 2.9421143719517046e-05,
      "loss": 0.1509,
      "step": 2230
    },
    {
      "epoch": 0.112,
      "grad_norm": 0.46947216987609863,
      "learning_rate": 2.9414476403785267e-05,
      "loss": 0.166,
      "step": 2240
    },
    {
      "step": 2250,
      "wer/bud500": 0.0691378957523314
    },
    {
      "step": 2250,
      "wer/private": 0.29524886877828055
    },
    {
      "epoch": 0.1125,
      "grad_norm": 0.34842169284820557,
      "learning_rate": 2.9407771674470585e-05,
      "loss": 0.1391,
      "step": 2250
    },
    {
      "epoch": 0.113,
      "grad_norm": 0.38098323345184326,
      "learning_rate": 2.9401029548975505e-05,
      "loss": 0.1581,
      "step": 2260
    },
    {
      "epoch": 0.1135,
      "grad_norm": 0.4500442445278168,
      "learning_rate": 2.939425004479959e-05,
      "loss": 0.1537,
      "step": 2270
    },
    {
      "epoch": 0.114,
      "grad_norm": 0.30902862548828125,
      "learning_rate": 2.9387433179539427e-05,
      "loss": 0.1491,
      "step": 2280
    },
    {
      "epoch": 0.1145,
      "grad_norm": 0.4261999726295471,
      "learning_rate": 2.9380578970888566e-05,
      "loss": 0.1579,
      "step": 2290
    },
    {
      "step": 2300,
      "wer/bud500": 0.06967872072967521
    },
    {
      "step": 2300,
      "wer/private": 0.28054298642533937
    },
    {
      "epoch": 0.115,
      "grad_norm": 0.4563828408718109,
      "learning_rate": 2.9373687436637492e-05,
      "loss": 0.1705,
      "step": 2300
    },
    {
      "epoch": 0.115,
      "eval_loss": 0.09544337540864944,
      "eval_runtime": 217.4546,
      "eval_samples_per_second": 34.49,
      "eval_steps_per_second": 0.271,
      "step": 2300
    },
    {
      "epoch": 0.1155,
      "grad_norm": 0.38655591011047363,
      "learning_rate": 2.9366758594673575e-05,
      "loss": 0.1525,
      "step": 2310
    },
    {
      "epoch": 0.116,
      "grad_norm": 0.3251557946205139,
      "learning_rate": 2.9359792462981007e-05,
      "loss": 0.1397,
      "step": 2320
    },
    {
      "epoch": 0.1165,
      "grad_norm": 0.4220753610134125,
      "learning_rate": 2.935278905964078e-05,
      "loss": 0.1538,
      "step": 2330
    },
    {
      "epoch": 0.117,
      "grad_norm": 0.3575384318828583,
      "learning_rate": 2.9345748402830615e-05,
      "loss": 0.1547,
      "step": 2340
    },
    {
      "step": 2350,
      "wer/bud500": 0.07223667670359868
    },
    {
      "step": 2350,
      "wer/private": 0.29524886877828055
    },
    {
      "epoch": 0.1175,
      "grad_norm": 0.46610674262046814,
      "learning_rate": 2.9338670510824936e-05,
      "loss": 0.1497,
      "step": 2350
    },
    {
      "epoch": 0.118,
      "grad_norm": 0.3699004650115967,
      "learning_rate": 2.9331555401994805e-05,
      "loss": 0.1559,
      "step": 2360
    },
    {
      "epoch": 0.1185,
      "grad_norm": 0.44412487745285034,
      "learning_rate": 2.9324403094807888e-05,
      "loss": 0.1627,
      "step": 2370
    },
    {
      "epoch": 0.119,
      "grad_norm": 0.3369634449481964,
      "learning_rate": 2.9317213607828404e-05,
      "loss": 0.1406,
      "step": 2380
    },
    {
      "epoch": 0.1195,
      "grad_norm": 0.4605892300605774,
      "learning_rate": 2.9309986959717068e-05,
      "loss": 0.1532,
      "step": 2390
    },
    {
      "step": 2400,
      "wer/bud500": 0.07277750168094249
    },
    {
      "step": 2400,
      "wer/private": 0.4479638009049774
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.521461546421051,
      "learning_rate": 2.9302723169231046e-05,
      "loss": 0.15,
      "step": 2400
    },
    {
      "epoch": 0.12,
      "eval_loss": 0.09432690590620041,
      "eval_runtime": 217.0357,
      "eval_samples_per_second": 34.557,
      "eval_steps_per_second": 0.272,
      "step": 2400
    },
    {
      "epoch": 0.1205,
      "grad_norm": 0.31621310114860535,
      "learning_rate": 2.929542225522392e-05,
      "loss": 0.1439,
      "step": 2410
    },
    {
      "epoch": 0.121,
      "grad_norm": 0.40454545617103577,
      "learning_rate": 2.9288084236645618e-05,
      "loss": 0.1632,
      "step": 2420
    },
    {
      "epoch": 0.1215,
      "grad_norm": 0.5376265048980713,
      "learning_rate": 2.9280709132542384e-05,
      "loss": 0.1426,
      "step": 2430
    },
    {
      "epoch": 0.122,
      "grad_norm": 0.3453879654407501,
      "learning_rate": 2.9273296962056713e-05,
      "loss": 0.1529,
      "step": 2440
    },
    {
      "step": 2450,
      "wer/bud500": 0.07200280644312568
    },
    {
      "step": 2450,
      "wer/private": 0.4513574660633484
    },
    {
      "epoch": 0.1225,
      "grad_norm": 0.3849230408668518,
      "learning_rate": 2.9265847744427305e-05,
      "loss": 0.1501,
      "step": 2450
    },
    {
      "epoch": 0.123,
      "grad_norm": 0.43972864747047424,
      "learning_rate": 2.9258361498989024e-05,
      "loss": 0.1733,
      "step": 2460
    },
    {
      "epoch": 0.1235,
      "grad_norm": 0.39727455377578735,
      "learning_rate": 2.925083824517285e-05,
      "loss": 0.1743,
      "step": 2470
    },
    {
      "epoch": 0.124,
      "grad_norm": 0.3600325882434845,
      "learning_rate": 2.9243278002505803e-05,
      "loss": 0.1544,
      "step": 2480
    },
    {
      "epoch": 0.1245,
      "grad_norm": 0.3934098780155182,
      "learning_rate": 2.9235680790610918e-05,
      "loss": 0.1574,
      "step": 2490
    },
    {
      "step": 2500,
      "wer/bud500": 0.07222205981231912
    },
    {
      "step": 2500,
      "wer/private": 0.2816742081447964
    },
    {
      "epoch": 0.125,
      "grad_norm": 0.33641523122787476,
      "learning_rate": 2.922804662920718e-05,
      "loss": 0.169,
      "step": 2500
    },
    {
      "epoch": 0.125,
      "eval_loss": 0.09425953030586243,
      "eval_runtime": 217.3744,
      "eval_samples_per_second": 34.503,
      "eval_steps_per_second": 0.271,
      "step": 2500
    },
    {
      "epoch": 0.1255,
      "grad_norm": 0.33696144819259644,
      "learning_rate": 2.9220375538109495e-05,
      "loss": 0.1674,
      "step": 2510
    },
    {
      "epoch": 0.126,
      "grad_norm": 0.412698894739151,
      "learning_rate": 2.9212667537228606e-05,
      "loss": 0.1676,
      "step": 2520
    },
    {
      "epoch": 0.1265,
      "grad_norm": 0.3494870066642761,
      "learning_rate": 2.9204922646571053e-05,
      "loss": 0.1611,
      "step": 2530
    },
    {
      "epoch": 0.127,
      "grad_norm": 0.36059457063674927,
      "learning_rate": 2.9197140886239146e-05,
      "loss": 0.141,
      "step": 2540
    },
    {
      "step": 2550,
      "wer/bud500": 0.07230976115999649
    },
    {
      "step": 2550,
      "wer/private": 0.2816742081447964
    },
    {
      "epoch": 0.1275,
      "grad_norm": 0.3856450617313385,
      "learning_rate": 2.9189322276430878e-05,
      "loss": 0.1485,
      "step": 2550
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.33333733677864075,
      "learning_rate": 2.918146683743989e-05,
      "loss": 0.1394,
      "step": 2560
    },
    {
      "epoch": 0.1285,
      "grad_norm": 0.33029794692993164,
      "learning_rate": 2.917357458965541e-05,
      "loss": 0.15,
      "step": 2570
    },
    {
      "epoch": 0.129,
      "grad_norm": 0.3570452034473419,
      "learning_rate": 2.9165645553562215e-05,
      "loss": 0.1597,
      "step": 2580
    },
    {
      "epoch": 0.1295,
      "grad_norm": 0.38974910974502563,
      "learning_rate": 2.9157679749740564e-05,
      "loss": 0.1513,
      "step": 2590
    },
    {
      "step": 2600,
      "wer/bud500": 0.0701172274680621
    },
    {
      "step": 2600,
      "wer/private": 0.4660633484162896
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.45014163851737976,
      "learning_rate": 2.9149677198866145e-05,
      "loss": 0.1665,
      "step": 2600
    },
    {
      "epoch": 0.13,
      "eval_loss": 0.09379015862941742,
      "eval_runtime": 216.668,
      "eval_samples_per_second": 34.615,
      "eval_steps_per_second": 0.272,
      "step": 2600
    },
    {
      "epoch": 0.1305,
      "grad_norm": 0.37591075897216797,
      "learning_rate": 2.9141637921710032e-05,
      "loss": 0.1348,
      "step": 2610
    },
    {
      "epoch": 0.131,
      "grad_norm": 0.40645894408226013,
      "learning_rate": 2.9133561939138617e-05,
      "loss": 0.1443,
      "step": 2620
    },
    {
      "epoch": 0.1315,
      "grad_norm": 0.37026041746139526,
      "learning_rate": 2.9125449272113567e-05,
      "loss": 0.1579,
      "step": 2630
    },
    {
      "epoch": 0.132,
      "grad_norm": 0.4095124304294586,
      "learning_rate": 2.911729994169177e-05,
      "loss": 0.149,
      "step": 2640
    },
    {
      "step": 2650,
      "wer/bud500": 0.07192972198672787
    },
    {
      "step": 2650,
      "wer/private": 0.27941176470588236
    },
    {
      "epoch": 0.1325,
      "grad_norm": 0.29811835289001465,
      "learning_rate": 2.910911396902526e-05,
      "loss": 0.1515,
      "step": 2650
    },
    {
      "epoch": 0.133,
      "grad_norm": 0.47944316267967224,
      "learning_rate": 2.9100891375361197e-05,
      "loss": 0.148,
      "step": 2660
    },
    {
      "epoch": 0.1335,
      "grad_norm": 0.36971622705459595,
      "learning_rate": 2.909263218204178e-05,
      "loss": 0.1599,
      "step": 2670
    },
    {
      "epoch": 0.134,
      "grad_norm": 0.41705822944641113,
      "learning_rate": 2.908433641050421e-05,
      "loss": 0.1412,
      "step": 2680
    },
    {
      "epoch": 0.1345,
      "grad_norm": 0.3536868989467621,
      "learning_rate": 2.9076004082280633e-05,
      "loss": 0.1619,
      "step": 2690
    },
    {
      "step": 2700,
      "wer/bud500": 0.06981027275119128
    },
    {
      "step": 2700,
      "wer/private": 0.2839366515837104
    },
    {
      "epoch": 0.135,
      "grad_norm": 0.41927406191825867,
      "learning_rate": 2.906763521899807e-05,
      "loss": 0.1522,
      "step": 2700
    },
    {
      "epoch": 0.135,
      "eval_loss": 0.0934944823384285,
      "eval_runtime": 216.3224,
      "eval_samples_per_second": 34.67,
      "eval_steps_per_second": 0.273,
      "step": 2700
    },
    {
      "epoch": 0.1355,
      "grad_norm": 0.3923531174659729,
      "learning_rate": 2.9059229842378373e-05,
      "loss": 0.1593,
      "step": 2710
    },
    {
      "epoch": 0.136,
      "grad_norm": 0.28665807843208313,
      "learning_rate": 2.9050787974238174e-05,
      "loss": 0.1523,
      "step": 2720
    },
    {
      "epoch": 0.1365,
      "grad_norm": 0.4056365489959717,
      "learning_rate": 2.9042309636488816e-05,
      "loss": 0.1727,
      "step": 2730
    },
    {
      "epoch": 0.137,
      "grad_norm": 0.3616449534893036,
      "learning_rate": 2.9033794851136297e-05,
      "loss": 0.1622,
      "step": 2740
    },
    {
      "step": 2750,
      "wer/bud500": 0.06973718829479346
    },
    {
      "step": 2750,
      "wer/private": 0.6153846153846154
    },
    {
      "epoch": 0.1375,
      "grad_norm": 0.42290985584259033,
      "learning_rate": 2.9025243640281226e-05,
      "loss": 0.1573,
      "step": 2750
    },
    {
      "epoch": 0.138,
      "grad_norm": 0.36759859323501587,
      "learning_rate": 2.901665602611874e-05,
      "loss": 0.1561,
      "step": 2760
    },
    {
      "epoch": 0.1385,
      "grad_norm": 0.44516444206237793,
      "learning_rate": 2.9008032030938487e-05,
      "loss": 0.1407,
      "step": 2770
    },
    {
      "epoch": 0.139,
      "grad_norm": 0.4023911952972412,
      "learning_rate": 2.899937167712452e-05,
      "loss": 0.152,
      "step": 2780
    },
    {
      "epoch": 0.1395,
      "grad_norm": 0.3316797614097595,
      "learning_rate": 2.8990674987155286e-05,
      "loss": 0.1409,
      "step": 2790
    },
    {
      "step": 2800,
      "wer/bud500": 0.06982488964247084
    },
    {
      "step": 2800,
      "wer/private": 0.3608597285067873
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3581060469150543,
      "learning_rate": 2.898194198360352e-05,
      "loss": 0.1603,
      "step": 2800
    },
    {
      "epoch": 0.14,
      "eval_loss": 0.09303198009729385,
      "eval_runtime": 216.8458,
      "eval_samples_per_second": 34.587,
      "eval_steps_per_second": 0.272,
      "step": 2800
    },
    {
      "epoch": 0.1405,
      "grad_norm": 0.3467108905315399,
      "learning_rate": 2.8973172689136223e-05,
      "loss": 0.1452,
      "step": 2810
    },
    {
      "epoch": 0.141,
      "grad_norm": 0.3676672577857971,
      "learning_rate": 2.8964367126514603e-05,
      "loss": 0.1534,
      "step": 2820
    },
    {
      "epoch": 0.1415,
      "grad_norm": 0.4247666597366333,
      "learning_rate": 2.895552531859398e-05,
      "loss": 0.1594,
      "step": 2830
    },
    {
      "epoch": 0.142,
      "grad_norm": 0.31106364727020264,
      "learning_rate": 2.894664728832377e-05,
      "loss": 0.1525,
      "step": 2840
    },
    {
      "step": 2850,
      "wer/bud500": 0.06665302423480574
    },
    {
      "step": 2850,
      "wer/private": 0.31221719457013575
    },
    {
      "epoch": 0.1425,
      "grad_norm": 0.3402095437049866,
      "learning_rate": 2.89377330587474e-05,
      "loss": 0.1603,
      "step": 2850
    },
    {
      "epoch": 0.143,
      "grad_norm": 0.3334801495075226,
      "learning_rate": 2.8928782653002247e-05,
      "loss": 0.1588,
      "step": 2860
    },
    {
      "epoch": 0.1435,
      "grad_norm": 0.4454815685749054,
      "learning_rate": 2.8919796094319595e-05,
      "loss": 0.1534,
      "step": 2870
    },
    {
      "epoch": 0.144,
      "grad_norm": 0.4015057682991028,
      "learning_rate": 2.8910773406024563e-05,
      "loss": 0.1603,
      "step": 2880
    },
    {
      "epoch": 0.1445,
      "grad_norm": 0.3352779448032379,
      "learning_rate": 2.8901714611536043e-05,
      "loss": 0.1569,
      "step": 2890
    },
    {
      "step": 2900,
      "wer/bud500": 0.06900634373081534
    },
    {
      "step": 2900,
      "wer/private": 0.3382352941176471
    },
    {
      "epoch": 0.145,
      "grad_norm": 0.41396182775497437,
      "learning_rate": 2.889261973436665e-05,
      "loss": 0.1648,
      "step": 2900
    },
    {
      "epoch": 0.145,
      "eval_loss": 0.09302740544080734,
      "eval_runtime": 205.8764,
      "eval_samples_per_second": 36.43,
      "eval_steps_per_second": 0.287,
      "step": 2900
    },
    {
      "epoch": 0.1455,
      "grad_norm": 0.35625940561294556,
      "learning_rate": 2.8883488798122642e-05,
      "loss": 0.1652,
      "step": 2910
    },
    {
      "epoch": 0.146,
      "grad_norm": 0.3681049346923828,
      "learning_rate": 2.8874321826503874e-05,
      "loss": 0.1704,
      "step": 2920
    },
    {
      "epoch": 0.1465,
      "grad_norm": 0.3859536945819855,
      "learning_rate": 2.8865118843303744e-05,
      "loss": 0.1514,
      "step": 2930
    },
    {
      "epoch": 0.147,
      "grad_norm": 0.5238553285598755,
      "learning_rate": 2.8855879872409108e-05,
      "loss": 0.1546,
      "step": 2940
    },
    {
      "step": 2950,
      "wer/bud500": 0.06571754319291373
    },
    {
      "step": 2950,
      "wer/private": 0.2828054298642534
    },
    {
      "epoch": 0.1475,
      "grad_norm": 0.3985445201396942,
      "learning_rate": 2.8846604937800232e-05,
      "loss": 0.1557,
      "step": 2950
    },
    {
      "epoch": 0.148,
      "grad_norm": 0.43681564927101135,
      "learning_rate": 2.8837294063550737e-05,
      "loss": 0.1527,
      "step": 2960
    },
    {
      "epoch": 0.1485,
      "grad_norm": 0.5854392051696777,
      "learning_rate": 2.8827947273827508e-05,
      "loss": 0.1599,
      "step": 2970
    },
    {
      "epoch": 0.149,
      "grad_norm": 0.3311116695404053,
      "learning_rate": 2.881856459289067e-05,
      "loss": 0.1592,
      "step": 2980
    },
    {
      "epoch": 0.1495,
      "grad_norm": 0.5200266242027283,
      "learning_rate": 2.88091460450935e-05,
      "loss": 0.1263,
      "step": 2990
    },
    {
      "step": 3000,
      "wer/bud500": 0.06574677697547286
    },
    {
      "step": 3000,
      "wer/private": 0.33710407239819007
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.37048569321632385,
      "learning_rate": 2.8799691654882365e-05,
      "loss": 0.1541,
      "step": 3000
    },
    {
      "epoch": 0.15,
      "eval_loss": 0.09176785498857498,
      "eval_runtime": 203.4083,
      "eval_samples_per_second": 36.872,
      "eval_steps_per_second": 0.29,
      "step": 3000
    },
    {
      "epoch": 0.1505,
      "grad_norm": 0.37839147448539734,
      "learning_rate": 2.8790201446796663e-05,
      "loss": 0.1452,
      "step": 3010
    },
    {
      "epoch": 0.151,
      "grad_norm": 0.3179261088371277,
      "learning_rate": 2.8780675445468764e-05,
      "loss": 0.1576,
      "step": 3020
    },
    {
      "epoch": 0.1515,
      "grad_norm": 0.3312012851238251,
      "learning_rate": 2.8771113675623943e-05,
      "loss": 0.1498,
      "step": 3030
    },
    {
      "epoch": 0.152,
      "grad_norm": 0.4545843005180359,
      "learning_rate": 2.8761516162080306e-05,
      "loss": 0.1457,
      "step": 3040
    },
    {
      "step": 3050,
      "wer/bud500": 0.06805624579764376
    },
    {
      "step": 3050,
      "wer/private": 0.3382352941176471
    },
    {
      "epoch": 0.1525,
      "grad_norm": 0.36568349599838257,
      "learning_rate": 2.875188292974874e-05,
      "loss": 0.1546,
      "step": 3050
    },
    {
      "epoch": 0.153,
      "grad_norm": 0.3740970492362976,
      "learning_rate": 2.8742214003632835e-05,
      "loss": 0.1546,
      "step": 3060
    },
    {
      "epoch": 0.1535,
      "grad_norm": 0.38688722252845764,
      "learning_rate": 2.873250940882884e-05,
      "loss": 0.1448,
      "step": 3070
    },
    {
      "epoch": 0.154,
      "grad_norm": 0.4384341537952423,
      "learning_rate": 2.8722769170525575e-05,
      "loss": 0.1646,
      "step": 3080
    },
    {
      "epoch": 0.1545,
      "grad_norm": 0.44411295652389526,
      "learning_rate": 2.8712993314004372e-05,
      "loss": 0.1633,
      "step": 3090
    },
    {
      "step": 3100,
      "wer/bud500": 0.06773467418949337
    },
    {
      "step": 3100,
      "wer/private": 0.3947963800904977
    },
    {
      "epoch": 0.155,
      "grad_norm": 0.3497009575366974,
      "learning_rate": 2.8703181864639013e-05,
      "loss": 0.1412,
      "step": 3100
    },
    {
      "epoch": 0.155,
      "eval_loss": 0.09213121235370636,
      "eval_runtime": 202.8636,
      "eval_samples_per_second": 36.971,
      "eval_steps_per_second": 0.291,
      "step": 3100
    },
    {
      "epoch": 0.1555,
      "grad_norm": 0.3916892409324646,
      "learning_rate": 2.8693334847895672e-05,
      "loss": 0.1443,
      "step": 3110
    },
    {
      "epoch": 0.156,
      "grad_norm": 0.4001889228820801,
      "learning_rate": 2.868345228933283e-05,
      "loss": 0.1765,
      "step": 3120
    },
    {
      "epoch": 0.1565,
      "grad_norm": 0.36608654260635376,
      "learning_rate": 2.8673534214601227e-05,
      "loss": 0.1545,
      "step": 3130
    },
    {
      "epoch": 0.157,
      "grad_norm": 0.33671191334724426,
      "learning_rate": 2.8663580649443776e-05,
      "loss": 0.1394,
      "step": 3140
    },
    {
      "step": 3150,
      "wer/bud500": 0.06814394714532113
    },
    {
      "step": 3150,
      "wer/private": 0.43778280542986425
    },
    {
      "epoch": 0.1575,
      "grad_norm": 0.3417310416698456,
      "learning_rate": 2.865359161969552e-05,
      "loss": 0.141,
      "step": 3150
    },
    {
      "epoch": 0.158,
      "grad_norm": 0.33376723527908325,
      "learning_rate": 2.8643567151283545e-05,
      "loss": 0.1407,
      "step": 3160
    },
    {
      "epoch": 0.1585,
      "grad_norm": 0.4599853754043579,
      "learning_rate": 2.8633507270226917e-05,
      "loss": 0.1444,
      "step": 3170
    },
    {
      "epoch": 0.159,
      "grad_norm": 0.35156795382499695,
      "learning_rate": 2.8623412002636635e-05,
      "loss": 0.1497,
      "step": 3180
    },
    {
      "epoch": 0.1595,
      "grad_norm": 0.434049516916275,
      "learning_rate": 2.8613281374715515e-05,
      "loss": 0.1547,
      "step": 3190
    },
    {
      "step": 3200,
      "wer/bud500": 0.0715204490309001
    },
    {
      "step": 3200,
      "wer/private": 0.43665158371040724
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4927881956100464,
      "learning_rate": 2.860311541275818e-05,
      "loss": 0.1464,
      "step": 3200
    },
    {
      "epoch": 0.16,
      "eval_loss": 0.09156033396720886,
      "eval_runtime": 202.0145,
      "eval_samples_per_second": 37.126,
      "eval_steps_per_second": 0.292,
      "step": 3200
    },
    {
      "epoch": 0.1605,
      "grad_norm": 0.5105076432228088,
      "learning_rate": 2.859291414315096e-05,
      "loss": 0.1505,
      "step": 3210
    },
    {
      "epoch": 0.161,
      "grad_norm": 0.46039077639579773,
      "learning_rate": 2.8582677592371814e-05,
      "loss": 0.158,
      "step": 3220
    },
    {
      "epoch": 0.1615,
      "grad_norm": 0.42676490545272827,
      "learning_rate": 2.8572405786990293e-05,
      "loss": 0.1535,
      "step": 3230
    },
    {
      "epoch": 0.162,
      "grad_norm": 0.41670092940330505,
      "learning_rate": 2.8562098753667436e-05,
      "loss": 0.1575,
      "step": 3240
    },
    {
      "step": 3250,
      "wer/bud500": 0.06812933025404157
    },
    {
      "step": 3250,
      "wer/private": 0.2850678733031674
    },
    {
      "epoch": 0.1625,
      "grad_norm": 0.3315413296222687,
      "learning_rate": 2.8551756519155732e-05,
      "loss": 0.1496,
      "step": 3250
    },
    {
      "epoch": 0.163,
      "grad_norm": 0.32240328192710876,
      "learning_rate": 2.8541379110299035e-05,
      "loss": 0.1489,
      "step": 3260
    },
    {
      "epoch": 0.1635,
      "grad_norm": 0.44024020433425903,
      "learning_rate": 2.853096655403248e-05,
      "loss": 0.1316,
      "step": 3270
    },
    {
      "epoch": 0.164,
      "grad_norm": 0.3623012602329254,
      "learning_rate": 2.8520518877382455e-05,
      "loss": 0.1472,
      "step": 3280
    },
    {
      "epoch": 0.1645,
      "grad_norm": 0.38793420791625977,
      "learning_rate": 2.851003610746648e-05,
      "loss": 0.1637,
      "step": 3290
    },
    {
      "step": 3300,
      "wer/bud500": 0.06786622621100945
    },
    {
      "step": 3300,
      "wer/private": 0.43778280542986425
    },
    {
      "epoch": 0.165,
      "grad_norm": 0.3913612365722656,
      "learning_rate": 2.8499518271493182e-05,
      "loss": 0.1649,
      "step": 3300
    },
    {
      "epoch": 0.165,
      "eval_loss": 0.09131202846765518,
      "eval_runtime": 202.7763,
      "eval_samples_per_second": 36.987,
      "eval_steps_per_second": 0.291,
      "step": 3300
    },
    {
      "epoch": 0.1655,
      "grad_norm": 0.3901159167289734,
      "learning_rate": 2.848896539676219e-05,
      "loss": 0.138,
      "step": 3310
    },
    {
      "epoch": 0.166,
      "grad_norm": 0.33886080980300903,
      "learning_rate": 2.8478377510664084e-05,
      "loss": 0.1508,
      "step": 3320
    },
    {
      "epoch": 0.1665,
      "grad_norm": 0.376377671957016,
      "learning_rate": 2.8467754640680322e-05,
      "loss": 0.1526,
      "step": 3330
    },
    {
      "epoch": 0.167,
      "grad_norm": 0.38111528754234314,
      "learning_rate": 2.845709681438315e-05,
      "loss": 0.144,
      "step": 3340
    },
    {
      "step": 3350,
      "wer/bud500": 0.06820241471043938
    },
    {
      "step": 3350,
      "wer/private": 0.4423076923076923
    },
    {
      "epoch": 0.1675,
      "grad_norm": 0.3839367628097534,
      "learning_rate": 2.8446404059435557e-05,
      "loss": 0.1527,
      "step": 3350
    },
    {
      "epoch": 0.168,
      "grad_norm": 0.3896180987358093,
      "learning_rate": 2.8435676403591193e-05,
      "loss": 0.1516,
      "step": 3360
    },
    {
      "epoch": 0.1685,
      "grad_norm": 0.3406886160373688,
      "learning_rate": 2.842491387469429e-05,
      "loss": 0.1513,
      "step": 3370
    },
    {
      "epoch": 0.169,
      "grad_norm": 0.4787174165248871,
      "learning_rate": 2.8414116500679596e-05,
      "loss": 0.1561,
      "step": 3380
    },
    {
      "epoch": 0.1695,
      "grad_norm": 0.3274567127227783,
      "learning_rate": 2.84032843095723e-05,
      "loss": 0.1497,
      "step": 3390
    },
    {
      "step": 3400,
      "wer/bud500": 0.06497208173765603
    },
    {
      "step": 3400,
      "wer/private": 0.5180995475113123
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4564756751060486,
      "learning_rate": 2.8392417329487962e-05,
      "loss": 0.1564,
      "step": 3400
    },
    {
      "epoch": 0.17,
      "eval_loss": 0.09127875417470932,
      "eval_runtime": 202.8387,
      "eval_samples_per_second": 36.975,
      "eval_steps_per_second": 0.291,
      "step": 3400
    },
    {
      "epoch": 0.1705,
      "grad_norm": 0.34288328886032104,
      "learning_rate": 2.838151558863244e-05,
      "loss": 0.1456,
      "step": 3410
    },
    {
      "epoch": 0.171,
      "grad_norm": 0.30576175451278687,
      "learning_rate": 2.8370579115301816e-05,
      "loss": 0.1571,
      "step": 3420
    },
    {
      "epoch": 0.1715,
      "grad_norm": 0.37313389778137207,
      "learning_rate": 2.835960793788232e-05,
      "loss": 0.1492,
      "step": 3430
    },
    {
      "epoch": 0.172,
      "grad_norm": 0.5129957795143127,
      "learning_rate": 2.834860208485026e-05,
      "loss": 0.1577,
      "step": 3440
    },
    {
      "step": 3450,
      "wer/bud500": 0.06773467418949337
    },
    {
      "step": 3450,
      "wer/private": 0.4490950226244344
    },
    {
      "epoch": 0.1725,
      "grad_norm": 0.4315994083881378,
      "learning_rate": 2.833756158477194e-05,
      "loss": 0.1599,
      "step": 3450
    },
    {
      "epoch": 0.173,
      "grad_norm": 0.37317365407943726,
      "learning_rate": 2.8326486466303603e-05,
      "loss": 0.1635,
      "step": 3460
    },
    {
      "epoch": 0.1735,
      "grad_norm": 0.40253254771232605,
      "learning_rate": 2.831537675819134e-05,
      "loss": 0.158,
      "step": 3470
    },
    {
      "epoch": 0.174,
      "grad_norm": 0.38664281368255615,
      "learning_rate": 2.8304232489271018e-05,
      "loss": 0.1429,
      "step": 3480
    },
    {
      "epoch": 0.1745,
      "grad_norm": 0.40746065974235535,
      "learning_rate": 2.829305368846822e-05,
      "loss": 0.1638,
      "step": 3490
    },
    {
      "step": 3500,
      "wer/bud500": 0.06755927149413862
    },
    {
      "step": 3500,
      "wer/private": 0.3891402714932127
    },
    {
      "epoch": 0.175,
      "grad_norm": 0.383927583694458,
      "learning_rate": 2.8281840384798147e-05,
      "loss": 0.1636,
      "step": 3500
    },
    {
      "epoch": 0.175,
      "eval_loss": 0.09091805666685104,
      "eval_runtime": 203.0461,
      "eval_samples_per_second": 36.937,
      "eval_steps_per_second": 0.291,
      "step": 3500
    },
    {
      "epoch": 0.1755,
      "grad_norm": 0.41120678186416626,
      "learning_rate": 2.8270592607365562e-05,
      "loss": 0.156,
      "step": 3510
    },
    {
      "epoch": 0.176,
      "grad_norm": 0.3444964587688446,
      "learning_rate": 2.8259310385364696e-05,
      "loss": 0.1495,
      "step": 3520
    },
    {
      "epoch": 0.1765,
      "grad_norm": 0.365213006734848,
      "learning_rate": 2.82479937480792e-05,
      "loss": 0.1517,
      "step": 3530
    },
    {
      "epoch": 0.177,
      "grad_norm": 0.39645668864250183,
      "learning_rate": 2.823664272488203e-05,
      "loss": 0.1545,
      "step": 3540
    },
    {
      "step": 3550,
      "wer/bud500": 0.06429970473879615
    },
    {
      "step": 3550,
      "wer/private": 0.4411764705882353
    },
    {
      "epoch": 0.1775,
      "grad_norm": 0.3702143728733063,
      "learning_rate": 2.822525734523541e-05,
      "loss": 0.1504,
      "step": 3550
    },
    {
      "epoch": 0.178,
      "grad_norm": 0.4381445348262787,
      "learning_rate": 2.8213837638690732e-05,
      "loss": 0.1523,
      "step": 3560
    },
    {
      "epoch": 0.1785,
      "grad_norm": 0.3873670995235443,
      "learning_rate": 2.8202383634888483e-05,
      "loss": 0.1773,
      "step": 3570
    },
    {
      "epoch": 0.179,
      "grad_norm": 0.42671921849250793,
      "learning_rate": 2.8190895363558177e-05,
      "loss": 0.1427,
      "step": 3580
    },
    {
      "epoch": 0.1795,
      "grad_norm": 0.5127463936805725,
      "learning_rate": 2.817937285451827e-05,
      "loss": 0.1605,
      "step": 3590
    },
    {
      "step": 3600,
      "wer/bud500": 0.06507439997661298
    },
    {
      "step": 3600,
      "wer/private": 0.4411764705882353
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.33156895637512207,
      "learning_rate": 2.816781613767607e-05,
      "loss": 0.1476,
      "step": 3600
    },
    {
      "epoch": 0.18,
      "eval_loss": 0.0906645730137825,
      "eval_runtime": 204.4888,
      "eval_samples_per_second": 36.677,
      "eval_steps_per_second": 0.289,
      "step": 3600
    },
    {
      "epoch": 0.1805,
      "grad_norm": 0.3862057328224182,
      "learning_rate": 2.8156225243027693e-05,
      "loss": 0.1418,
      "step": 3610
    },
    {
      "epoch": 0.181,
      "grad_norm": 0.4554252326488495,
      "learning_rate": 2.8144600200657953e-05,
      "loss": 0.1493,
      "step": 3620
    },
    {
      "epoch": 0.1815,
      "grad_norm": 0.34925055503845215,
      "learning_rate": 2.8132941040740305e-05,
      "loss": 0.1537,
      "step": 3630
    },
    {
      "epoch": 0.182,
      "grad_norm": 0.3907034993171692,
      "learning_rate": 2.812124779353675e-05,
      "loss": 0.1499,
      "step": 3640
    },
    {
      "step": 3650,
      "wer/bud500": 0.06469436080334434
    },
    {
      "step": 3650,
      "wer/private": 0.6323529411764706
    },
    {
      "epoch": 0.1825,
      "grad_norm": 0.481738805770874,
      "learning_rate": 2.8109520489397772e-05,
      "loss": 0.1548,
      "step": 3650
    },
    {
      "epoch": 0.183,
      "grad_norm": 0.42007333040237427,
      "learning_rate": 2.8097759158762236e-05,
      "loss": 0.1391,
      "step": 3660
    },
    {
      "epoch": 0.1835,
      "grad_norm": 0.4248800575733185,
      "learning_rate": 2.8085963832157352e-05,
      "loss": 0.1507,
      "step": 3670
    },
    {
      "epoch": 0.184,
      "grad_norm": 0.4260796308517456,
      "learning_rate": 2.807413454019854e-05,
      "loss": 0.1623,
      "step": 3680
    },
    {
      "epoch": 0.1845,
      "grad_norm": 0.3743146061897278,
      "learning_rate": 2.8062271313589396e-05,
      "loss": 0.1478,
      "step": 3690
    },
    {
      "step": 3700,
      "wer/bud500": 0.06751542082029993
    },
    {
      "step": 3700,
      "wer/private": 0.5079185520361991
    },
    {
      "epoch": 0.185,
      "grad_norm": 0.4015466570854187,
      "learning_rate": 2.8050374183121588e-05,
      "loss": 0.1534,
      "step": 3700
    },
    {
      "epoch": 0.185,
      "eval_loss": 0.09010088443756104,
      "eval_runtime": 203.1232,
      "eval_samples_per_second": 36.923,
      "eval_steps_per_second": 0.29,
      "step": 3700
    },
    {
      "epoch": 0.1855,
      "grad_norm": 0.3679267168045044,
      "learning_rate": 2.8038443179674794e-05,
      "loss": 0.13,
      "step": 3710
    },
    {
      "epoch": 0.186,
      "grad_norm": 0.3475238084793091,
      "learning_rate": 2.8026478334216595e-05,
      "loss": 0.1523,
      "step": 3720
    },
    {
      "epoch": 0.1865,
      "grad_norm": 0.3657262623310089,
      "learning_rate": 2.8014479677802422e-05,
      "loss": 0.1504,
      "step": 3730
    },
    {
      "epoch": 0.187,
      "grad_norm": 0.34162119030952454,
      "learning_rate": 2.800244724157546e-05,
      "loss": 0.1543,
      "step": 3740
    },
    {
      "step": 3750,
      "wer/bud500": 0.0670622971906335
    },
    {
      "step": 3750,
      "wer/private": 0.6029411764705882
    },
    {
      "epoch": 0.1875,
      "grad_norm": 0.37733370065689087,
      "learning_rate": 2.7990381056766583e-05,
      "loss": 0.1584,
      "step": 3750
    },
    {
      "epoch": 0.188,
      "grad_norm": 0.37399154901504517,
      "learning_rate": 2.7978281154694238e-05,
      "loss": 0.1547,
      "step": 3760
    },
    {
      "epoch": 0.1885,
      "grad_norm": 0.45685920119285583,
      "learning_rate": 2.79661475667644e-05,
      "loss": 0.1567,
      "step": 3770
    },
    {
      "epoch": 0.189,
      "grad_norm": 0.4025920629501343,
      "learning_rate": 2.7953980324470488e-05,
      "loss": 0.153,
      "step": 3780
    },
    {
      "epoch": 0.1895,
      "grad_norm": 0.4601735770702362,
      "learning_rate": 2.794177945939326e-05,
      "loss": 0.1565,
      "step": 3790
    },
    {
      "step": 3800,
      "wer/bud500": 0.06393428245680709
    },
    {
      "step": 3800,
      "wer/private": 0.5339366515837104
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.399392694234848,
      "learning_rate": 2.7929545003200738e-05,
      "loss": 0.1625,
      "step": 3800
    },
    {
      "epoch": 0.19,
      "eval_loss": 0.09045889973640442,
      "eval_runtime": 204.7744,
      "eval_samples_per_second": 36.626,
      "eval_steps_per_second": 0.288,
      "step": 3800
    },
    {
      "epoch": 0.1905,
      "grad_norm": 0.42041656374931335,
      "learning_rate": 2.7917276987648147e-05,
      "loss": 0.1463,
      "step": 3810
    },
    {
      "epoch": 0.191,
      "grad_norm": 0.36123165488243103,
      "learning_rate": 2.7904975444577815e-05,
      "loss": 0.1588,
      "step": 3820
    },
    {
      "epoch": 0.1915,
      "grad_norm": 0.3366515338420868,
      "learning_rate": 2.7892640405919077e-05,
      "loss": 0.1526,
      "step": 3830
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.3960387110710144,
      "learning_rate": 2.7880271903688225e-05,
      "loss": 0.1477,
      "step": 3840
    },
    {
      "step": 3850,
      "wer/bud500": 0.06717923232087
    },
    {
      "step": 3850,
      "wer/private": 0.332579185520362
    },
    {
      "epoch": 0.1925,
      "grad_norm": 0.5145470499992371,
      "learning_rate": 2.78678699699884e-05,
      "loss": 0.1515,
      "step": 3850
    },
    {
      "epoch": 0.193,
      "grad_norm": 0.4028758406639099,
      "learning_rate": 2.7855434637009516e-05,
      "loss": 0.1511,
      "step": 3860
    },
    {
      "epoch": 0.1935,
      "grad_norm": 0.3875168263912201,
      "learning_rate": 2.7842965937028177e-05,
      "loss": 0.1553,
      "step": 3870
    },
    {
      "epoch": 0.194,
      "grad_norm": 0.40349605679512024,
      "learning_rate": 2.78304639024076e-05,
      "loss": 0.1595,
      "step": 3880
    },
    {
      "epoch": 0.1945,
      "grad_norm": 0.4268958270549774,
      "learning_rate": 2.7817928565597513e-05,
      "loss": 0.1517,
      "step": 3890
    },
    {
      "step": 3900,
      "wer/bud500": 0.067646972841816
    },
    {
      "step": 3900,
      "wer/private": 0.7092760180995475
    },
    {
      "epoch": 0.195,
      "grad_norm": 0.4151865839958191,
      "learning_rate": 2.7805359959134086e-05,
      "loss": 0.1488,
      "step": 3900
    },
    {
      "epoch": 0.195,
      "eval_loss": 0.09081705659627914,
      "eval_runtime": 203.994,
      "eval_samples_per_second": 36.766,
      "eval_steps_per_second": 0.289,
      "step": 3900
    },
    {
      "epoch": 0.1955,
      "grad_norm": 0.316823273897171,
      "learning_rate": 2.7792758115639843e-05,
      "loss": 0.1412,
      "step": 3910
    },
    {
      "epoch": 0.196,
      "grad_norm": 0.403129905462265,
      "learning_rate": 2.7780123067823576e-05,
      "loss": 0.1431,
      "step": 3920
    },
    {
      "epoch": 0.1965,
      "grad_norm": 0.45884236693382263,
      "learning_rate": 2.7767454848480268e-05,
      "loss": 0.1423,
      "step": 3930
    },
    {
      "epoch": 0.197,
      "grad_norm": 0.47492989897727966,
      "learning_rate": 2.775475349049098e-05,
      "loss": 0.1454,
      "step": 3940
    },
    {
      "step": 3950,
      "wer/bud500": 0.06725231677726781
    },
    {
      "step": 3950,
      "wer/private": 0.45248868778280543
    },
    {
      "epoch": 0.1975,
      "grad_norm": 0.4106771647930145,
      "learning_rate": 2.7742019026822818e-05,
      "loss": 0.1508,
      "step": 3950
    },
    {
      "epoch": 0.198,
      "grad_norm": 0.6517415046691895,
      "learning_rate": 2.772925149052878e-05,
      "loss": 0.1345,
      "step": 3960
    },
    {
      "epoch": 0.1985,
      "grad_norm": 0.5398030877113342,
      "learning_rate": 2.7716450914747734e-05,
      "loss": 0.1678,
      "step": 3970
    },
    {
      "epoch": 0.199,
      "grad_norm": 0.409618616104126,
      "learning_rate": 2.770361733270429e-05,
      "loss": 0.158,
      "step": 3980
    },
    {
      "epoch": 0.1995,
      "grad_norm": 0.33659958839416504,
      "learning_rate": 2.769075077770873e-05,
      "loss": 0.138,
      "step": 3990
    },
    {
      "step": 4000,
      "wer/bud500": 0.06416815271728009
    },
    {
      "step": 4000,
      "wer/private": 0.41402714932126694
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.3366456925868988,
      "learning_rate": 2.767785128315692e-05,
      "loss": 0.1346,
      "step": 4000
    },
    {
      "epoch": 0.2,
      "eval_loss": 0.08951994776725769,
      "eval_runtime": 207.8683,
      "eval_samples_per_second": 36.081,
      "eval_steps_per_second": 0.284,
      "step": 4000
    },
    {
      "epoch": 0.2005,
      "grad_norm": 0.4301726222038269,
      "learning_rate": 2.7664918882530227e-05,
      "loss": 0.1497,
      "step": 4010
    },
    {
      "epoch": 0.201,
      "grad_norm": 0.35906684398651123,
      "learning_rate": 2.7651953609395415e-05,
      "loss": 0.1453,
      "step": 4020
    },
    {
      "epoch": 0.2015,
      "grad_norm": 0.42508047819137573,
      "learning_rate": 2.7638955497404585e-05,
      "loss": 0.1574,
      "step": 4030
    },
    {
      "epoch": 0.202,
      "grad_norm": 0.35423678159713745,
      "learning_rate": 2.7625924580295067e-05,
      "loss": 0.1408,
      "step": 4040
    },
    {
      "step": 4050,
      "wer/bud500": 0.06731078434238606
    },
    {
      "step": 4050,
      "wer/private": 0.5531674208144797
    },
    {
      "epoch": 0.2025,
      "grad_norm": 0.34523651003837585,
      "learning_rate": 2.7612860891889334e-05,
      "loss": 0.1383,
      "step": 4050
    },
    {
      "epoch": 0.203,
      "grad_norm": 0.47505679726600647,
      "learning_rate": 2.7599764466094924e-05,
      "loss": 0.1571,
      "step": 4060
    },
    {
      "epoch": 0.2035,
      "grad_norm": 0.3706081807613373,
      "learning_rate": 2.758663533690434e-05,
      "loss": 0.1494,
      "step": 4070
    },
    {
      "epoch": 0.204,
      "grad_norm": 0.34210553765296936,
      "learning_rate": 2.7573473538394984e-05,
      "loss": 0.1491,
      "step": 4080
    },
    {
      "epoch": 0.2045,
      "grad_norm": 0.46445563435554504,
      "learning_rate": 2.7560279104729044e-05,
      "loss": 0.1466,
      "step": 4090
    },
    {
      "step": 4100,
      "wer/bud500": 0.06669687490864443
    },
    {
      "step": 4100,
      "wer/private": 0.39819004524886875
    },
    {
      "epoch": 0.205,
      "grad_norm": 0.3992688059806824,
      "learning_rate": 2.75470520701534e-05,
      "loss": 0.1439,
      "step": 4100
    },
    {
      "epoch": 0.205,
      "eval_loss": 0.08927598595619202,
      "eval_runtime": 204.5399,
      "eval_samples_per_second": 36.668,
      "eval_steps_per_second": 0.288,
      "step": 4100
    },
    {
      "epoch": 0.2055,
      "grad_norm": 0.3952115774154663,
      "learning_rate": 2.7533792468999577e-05,
      "loss": 0.1595,
      "step": 4110
    },
    {
      "epoch": 0.206,
      "grad_norm": 0.3564830720424652,
      "learning_rate": 2.7520500335683604e-05,
      "loss": 0.166,
      "step": 4120
    },
    {
      "epoch": 0.2065,
      "grad_norm": 0.3589063882827759,
      "learning_rate": 2.750717570470597e-05,
      "loss": 0.1453,
      "step": 4130
    },
    {
      "epoch": 0.207,
      "grad_norm": 0.34533777832984924,
      "learning_rate": 2.7493818610651493e-05,
      "loss": 0.1375,
      "step": 4140
    },
    {
      "step": 4150,
      "wer/bud500": 0.06387581489168884
    },
    {
      "step": 4150,
      "wer/private": 0.3721719457013575
    },
    {
      "epoch": 0.2075,
      "grad_norm": 0.38086479902267456,
      "learning_rate": 2.7480429088189264e-05,
      "loss": 0.1263,
      "step": 4150
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.3717815577983856,
      "learning_rate": 2.7467007172072543e-05,
      "loss": 0.1493,
      "step": 4160
    },
    {
      "epoch": 0.2085,
      "grad_norm": 0.4293343722820282,
      "learning_rate": 2.7453552897138662e-05,
      "loss": 0.1613,
      "step": 4170
    },
    {
      "epoch": 0.209,
      "grad_norm": 0.5535411834716797,
      "learning_rate": 2.7440066298308953e-05,
      "loss": 0.1446,
      "step": 4180
    },
    {
      "epoch": 0.2095,
      "grad_norm": 0.3470442593097687,
      "learning_rate": 2.7426547410588638e-05,
      "loss": 0.1455,
      "step": 4190
    },
    {
      "step": 4200,
      "wer/bud500": 0.0643581723039144
    },
    {
      "step": 4200,
      "wer/private": 0.41402714932126694
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4310291111469269,
      "learning_rate": 2.741299626906675e-05,
      "loss": 0.1456,
      "step": 4200
    },
    {
      "epoch": 0.21,
      "eval_loss": 0.08964040875434875,
      "eval_runtime": 202.9871,
      "eval_samples_per_second": 36.948,
      "eval_steps_per_second": 0.291,
      "step": 4200
    },
    {
      "epoch": 0.2105,
      "grad_norm": 0.41270148754119873,
      "learning_rate": 2.7399412908916033e-05,
      "loss": 0.1503,
      "step": 4210
    },
    {
      "epoch": 0.211,
      "grad_norm": 0.3923755884170532,
      "learning_rate": 2.7385797365392862e-05,
      "loss": 0.1563,
      "step": 4220
    },
    {
      "epoch": 0.2115,
      "grad_norm": 0.35003262758255005,
      "learning_rate": 2.737214967383715e-05,
      "loss": 0.1549,
      "step": 4230
    },
    {
      "epoch": 0.212,
      "grad_norm": 0.3428395092487335,
      "learning_rate": 2.7358469869672245e-05,
      "loss": 0.1277,
      "step": 4240
    },
    {
      "step": 4250,
      "wer/bud500": 0.06399275002192534
    },
    {
      "step": 4250,
      "wer/private": 0.6538461538461539
    },
    {
      "epoch": 0.2125,
      "grad_norm": 0.47082728147506714,
      "learning_rate": 2.7344757988404845e-05,
      "loss": 0.1557,
      "step": 4250
    },
    {
      "epoch": 0.213,
      "grad_norm": 0.37447357177734375,
      "learning_rate": 2.733101406562491e-05,
      "loss": 0.1461,
      "step": 4260
    },
    {
      "epoch": 0.2135,
      "grad_norm": 0.35833102464675903,
      "learning_rate": 2.731723813700556e-05,
      "loss": 0.1457,
      "step": 4270
    },
    {
      "epoch": 0.214,
      "grad_norm": 0.3814404010772705,
      "learning_rate": 2.7303430238302995e-05,
      "loss": 0.1466,
      "step": 4280
    },
    {
      "epoch": 0.2145,
      "grad_norm": 0.35203826427459717,
      "learning_rate": 2.7289590405356392e-05,
      "loss": 0.1464,
      "step": 4290
    },
    {
      "step": 4300,
      "wer/bud500": 0.06719384921214956
    },
    {
      "step": 4300,
      "wer/private": 0.4117647058823529
    },
    {
      "epoch": 0.215,
      "grad_norm": 0.3130713701248169,
      "learning_rate": 2.7275718674087806e-05,
      "loss": 0.1452,
      "step": 4300
    },
    {
      "epoch": 0.215,
      "eval_loss": 0.08921150863170624,
      "eval_runtime": 202.4873,
      "eval_samples_per_second": 37.039,
      "eval_steps_per_second": 0.291,
      "step": 4300
    },
    {
      "epoch": 0.2155,
      "grad_norm": 0.42689427733421326,
      "learning_rate": 2.72618150805021e-05,
      "loss": 0.1505,
      "step": 4310
    },
    {
      "epoch": 0.216,
      "grad_norm": 0.32473206520080566,
      "learning_rate": 2.724787966068684e-05,
      "loss": 0.1516,
      "step": 4320
    },
    {
      "epoch": 0.2165,
      "grad_norm": 0.42734968662261963,
      "learning_rate": 2.7233912450812178e-05,
      "loss": 0.143,
      "step": 4330
    },
    {
      "epoch": 0.217,
      "grad_norm": 0.41330885887145996,
      "learning_rate": 2.72199134871308e-05,
      "loss": 0.1584,
      "step": 4340
    },
    {
      "step": 4350,
      "wer/bud500": 0.06367117841377495
    },
    {
      "step": 4350,
      "wer/private": 0.3891402714932127
    },
    {
      "epoch": 0.2175,
      "grad_norm": 0.3791261315345764,
      "learning_rate": 2.7205882805977796e-05,
      "loss": 0.1401,
      "step": 4350
    },
    {
      "epoch": 0.218,
      "grad_norm": 0.3638223707675934,
      "learning_rate": 2.7191820443770584e-05,
      "loss": 0.158,
      "step": 4360
    },
    {
      "epoch": 0.2185,
      "grad_norm": 0.423723042011261,
      "learning_rate": 2.7177726437008828e-05,
      "loss": 0.1449,
      "step": 4370
    },
    {
      "epoch": 0.219,
      "grad_norm": 0.48569396138191223,
      "learning_rate": 2.7163600822274305e-05,
      "loss": 0.1446,
      "step": 4380
    },
    {
      "epoch": 0.2195,
      "grad_norm": 0.43526574969291687,
      "learning_rate": 2.7149443636230844e-05,
      "loss": 0.1503,
      "step": 4390
    },
    {
      "step": 4400,
      "wer/bud500": 0.06644838775689187
    },
    {
      "step": 4400,
      "wer/private": 0.4638009049773756
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.4082828164100647,
      "learning_rate": 2.7135254915624213e-05,
      "loss": 0.1516,
      "step": 4400
    },
    {
      "epoch": 0.22,
      "eval_loss": 0.08880925923585892,
      "eval_runtime": 202.8371,
      "eval_samples_per_second": 36.975,
      "eval_steps_per_second": 0.291,
      "step": 4400
    },
    {
      "epoch": 0.2205,
      "grad_norm": 0.38179776072502136,
      "learning_rate": 2.712103469728203e-05,
      "loss": 0.1433,
      "step": 4410
    },
    {
      "epoch": 0.221,
      "grad_norm": 0.33503204584121704,
      "learning_rate": 2.7106783018113684e-05,
      "loss": 0.1356,
      "step": 4420
    },
    {
      "epoch": 0.2215,
      "grad_norm": 0.4706730246543884,
      "learning_rate": 2.7092499915110197e-05,
      "loss": 0.1443,
      "step": 4430
    },
    {
      "epoch": 0.222,
      "grad_norm": 0.4032551050186157,
      "learning_rate": 2.7078185425344164e-05,
      "loss": 0.1387,
      "step": 4440
    },
    {
      "step": 4450,
      "wer/bud500": 0.06656532288712837
    },
    {
      "step": 4450,
      "wer/private": 0.32805429864253394
    },
    {
      "epoch": 0.2225,
      "grad_norm": 0.472036749124527,
      "learning_rate": 2.706383958596965e-05,
      "loss": 0.1417,
      "step": 4450
    },
    {
      "epoch": 0.223,
      "grad_norm": 0.4313633143901825,
      "learning_rate": 2.7049462434222094e-05,
      "loss": 0.1398,
      "step": 4460
    },
    {
      "epoch": 0.2235,
      "grad_norm": 0.41301295161247253,
      "learning_rate": 2.703505400741819e-05,
      "loss": 0.1442,
      "step": 4470
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.3939623236656189,
      "learning_rate": 2.7020614342955822e-05,
      "loss": 0.1493,
      "step": 4480
    },
    {
      "epoch": 0.2245,
      "grad_norm": 0.4435727894306183,
      "learning_rate": 2.7006143478313955e-05,
      "loss": 0.1444,
      "step": 4490
    },
    {
      "step": 4500,
      "wer/bud500": 0.06628760195281667
    },
    {
      "step": 4500,
      "wer/private": 0.416289592760181
    },
    {
      "epoch": 0.225,
      "grad_norm": 0.3557220995426178,
      "learning_rate": 2.699164145105252e-05,
      "loss": 0.1276,
      "step": 4500
    },
    {
      "epoch": 0.225,
      "eval_loss": 0.08857834339141846,
      "eval_runtime": 203.3904,
      "eval_samples_per_second": 36.875,
      "eval_steps_per_second": 0.29,
      "step": 4500
    },
    {
      "epoch": 0.2255,
      "grad_norm": 0.35990482568740845,
      "learning_rate": 2.697710829881235e-05,
      "loss": 0.1469,
      "step": 4510
    },
    {
      "epoch": 0.226,
      "grad_norm": 0.3377377688884735,
      "learning_rate": 2.696254405931506e-05,
      "loss": 0.1381,
      "step": 4520
    },
    {
      "epoch": 0.2265,
      "grad_norm": 0.3982039988040924,
      "learning_rate": 2.6947948770362945e-05,
      "loss": 0.1571,
      "step": 4530
    },
    {
      "epoch": 0.227,
      "grad_norm": 0.3449791967868805,
      "learning_rate": 2.6933322469838905e-05,
      "loss": 0.1367,
      "step": 4540
    },
    {
      "step": 4550,
      "wer/bud500": 0.06640453708305318
    },
    {
      "step": 4550,
      "wer/private": 0.5294117647058824
    },
    {
      "epoch": 0.2275,
      "grad_norm": 0.4095562994480133,
      "learning_rate": 2.6918665195706313e-05,
      "loss": 0.1465,
      "step": 4550
    },
    {
      "epoch": 0.228,
      "grad_norm": 0.39140161871910095,
      "learning_rate": 2.6903976986008963e-05,
      "loss": 0.1578,
      "step": 4560
    },
    {
      "epoch": 0.2285,
      "grad_norm": 0.34760722517967224,
      "learning_rate": 2.6889257878870913e-05,
      "loss": 0.1659,
      "step": 4570
    },
    {
      "epoch": 0.229,
      "grad_norm": 0.3519386649131775,
      "learning_rate": 2.6874507912496438e-05,
      "loss": 0.1395,
      "step": 4580
    },
    {
      "epoch": 0.2295,
      "grad_norm": 0.34045517444610596,
      "learning_rate": 2.68597271251699e-05,
      "loss": 0.1531,
      "step": 4590
    },
    {
      "step": 4600,
      "wer/bud500": 0.06672610869120356
    },
    {
      "step": 4600,
      "wer/private": 0.3042986425339366
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.4935430884361267,
      "learning_rate": 2.6844915555255676e-05,
      "loss": 0.1556,
      "step": 4600
    },
    {
      "epoch": 0.23,
      "eval_loss": 0.08801914751529694,
      "eval_runtime": 202.9878,
      "eval_samples_per_second": 36.948,
      "eval_steps_per_second": 0.291,
      "step": 4600
    },
    {
      "epoch": 0.2305,
      "grad_norm": 0.3404054641723633,
      "learning_rate": 2.683007324119801e-05,
      "loss": 0.1266,
      "step": 4610
    },
    {
      "epoch": 0.231,
      "grad_norm": 0.3905138671398163,
      "learning_rate": 2.6815200221520976e-05,
      "loss": 0.1571,
      "step": 4620
    },
    {
      "epoch": 0.2315,
      "grad_norm": 0.37797531485557556,
      "learning_rate": 2.680029653482832e-05,
      "loss": 0.1473,
      "step": 4630
    },
    {
      "epoch": 0.232,
      "grad_norm": 0.38479888439178467,
      "learning_rate": 2.6785362219803402e-05,
      "loss": 0.1459,
      "step": 4640
    },
    {
      "step": 4650,
      "wer/bud500": 0.06698921273423568
    },
    {
      "step": 4650,
      "wer/private": 0.36425339366515835
    },
    {
      "epoch": 0.2325,
      "grad_norm": 0.39727434515953064,
      "learning_rate": 2.677039731520908e-05,
      "loss": 0.1495,
      "step": 4650
    },
    {
      "epoch": 0.233,
      "grad_norm": 0.3673616051673889,
      "learning_rate": 2.6755401859887598e-05,
      "loss": 0.1439,
      "step": 4660
    },
    {
      "epoch": 0.2335,
      "grad_norm": 0.4479774832725525,
      "learning_rate": 2.6740375892760506e-05,
      "loss": 0.1361,
      "step": 4670
    },
    {
      "epoch": 0.234,
      "grad_norm": 0.47807177901268005,
      "learning_rate": 2.6725319452828542e-05,
      "loss": 0.148,
      "step": 4680
    },
    {
      "epoch": 0.2345,
      "grad_norm": 0.39767953753471375,
      "learning_rate": 2.6710232579171542e-05,
      "loss": 0.1547,
      "step": 4690
    },
    {
      "step": 4700,
      "wer/bud500": 0.06660917356096706
    },
    {
      "step": 4700,
      "wer/private": 0.38461538461538464
    },
    {
      "epoch": 0.235,
      "grad_norm": 0.40082648396492004,
      "learning_rate": 2.6695115310948335e-05,
      "loss": 0.158,
      "step": 4700
    },
    {
      "epoch": 0.235,
      "eval_loss": 0.08857845515012741,
      "eval_runtime": 203.7272,
      "eval_samples_per_second": 36.814,
      "eval_steps_per_second": 0.29,
      "step": 4700
    },
    {
      "epoch": 0.2355,
      "grad_norm": 0.4328409433364868,
      "learning_rate": 2.667996768739664e-05,
      "loss": 0.1484,
      "step": 4710
    },
    {
      "epoch": 0.236,
      "grad_norm": 0.37127962708473206,
      "learning_rate": 2.6664789747832967e-05,
      "loss": 0.1651,
      "step": 4720
    },
    {
      "epoch": 0.2365,
      "grad_norm": 0.47794461250305176,
      "learning_rate": 2.6649581531652506e-05,
      "loss": 0.1422,
      "step": 4730
    },
    {
      "epoch": 0.237,
      "grad_norm": 0.3897325396537781,
      "learning_rate": 2.6634343078329037e-05,
      "loss": 0.1512,
      "step": 4740
    },
    {
      "step": 4750,
      "wer/bud500": 0.06674072558248312
    },
    {
      "step": 4750,
      "wer/private": 0.4287330316742081
    },
    {
      "epoch": 0.2375,
      "grad_norm": 0.4181426763534546,
      "learning_rate": 2.6619074427414817e-05,
      "loss": 0.1525,
      "step": 4750
    },
    {
      "epoch": 0.238,
      "grad_norm": 0.3500045835971832,
      "learning_rate": 2.6603775618540496e-05,
      "loss": 0.1399,
      "step": 4760
    },
    {
      "epoch": 0.2385,
      "grad_norm": 0.3965122401714325,
      "learning_rate": 2.6588446691414987e-05,
      "loss": 0.1562,
      "step": 4770
    },
    {
      "epoch": 0.239,
      "grad_norm": 0.40768685936927795,
      "learning_rate": 2.657308768582538e-05,
      "loss": 0.1415,
      "step": 4780
    },
    {
      "epoch": 0.2395,
      "grad_norm": 0.4166901409626007,
      "learning_rate": 2.655769864163684e-05,
      "loss": 0.1481,
      "step": 4790
    },
    {
      "step": 4800,
      "wer/bud500": 0.06329113924050633
    },
    {
      "step": 4800,
      "wer/private": 0.3427601809954751
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.3084164559841156,
      "learning_rate": 2.654227959879249e-05,
      "loss": 0.1469,
      "step": 4800
    },
    {
      "epoch": 0.24,
      "eval_loss": 0.08799999207258224,
      "eval_runtime": 204.9116,
      "eval_samples_per_second": 36.601,
      "eval_steps_per_second": 0.288,
      "step": 4800
    },
    {
      "epoch": 0.2405,
      "grad_norm": 0.3917747437953949,
      "learning_rate": 2.6526830597313327e-05,
      "loss": 0.1459,
      "step": 4810
    },
    {
      "epoch": 0.241,
      "grad_norm": 0.46107232570648193,
      "learning_rate": 2.6511351677298096e-05,
      "loss": 0.1306,
      "step": 4820
    },
    {
      "epoch": 0.2415,
      "grad_norm": 0.3788140118122101,
      "learning_rate": 2.6495842878923205e-05,
      "loss": 0.1331,
      "step": 4830
    },
    {
      "epoch": 0.242,
      "grad_norm": 0.39804792404174805,
      "learning_rate": 2.6480304242442614e-05,
      "loss": 0.1566,
      "step": 4840
    },
    {
      "step": 4850,
      "wer/bud500": 0.06367117841377495
    },
    {
      "step": 4850,
      "wer/private": 0.5192307692307693
    },
    {
      "epoch": 0.2425,
      "grad_norm": 0.3770979046821594,
      "learning_rate": 2.6464735808187725e-05,
      "loss": 0.155,
      "step": 4850
    },
    {
      "epoch": 0.243,
      "grad_norm": 0.3862577974796295,
      "learning_rate": 2.6449137616567285e-05,
      "loss": 0.1425,
      "step": 4860
    },
    {
      "epoch": 0.2435,
      "grad_norm": 0.3915022909641266,
      "learning_rate": 2.643350970806727e-05,
      "loss": 0.1478,
      "step": 4870
    },
    {
      "epoch": 0.244,
      "grad_norm": 0.3745473027229309,
      "learning_rate": 2.6417852123250804e-05,
      "loss": 0.1444,
      "step": 4880
    },
    {
      "epoch": 0.2445,
      "grad_norm": 0.3634171187877655,
      "learning_rate": 2.6402164902758013e-05,
      "loss": 0.1509,
      "step": 4890
    },
    {
      "step": 4900,
      "wer/bud500": 0.06348115882714064
    },
    {
      "step": 4900,
      "wer/private": 0.38574660633484165
    },
    {
      "epoch": 0.245,
      "grad_norm": 0.36453017592430115,
      "learning_rate": 2.6386448087305973e-05,
      "loss": 0.135,
      "step": 4900
    },
    {
      "epoch": 0.245,
      "eval_loss": 0.08864014595746994,
      "eval_runtime": 202.6471,
      "eval_samples_per_second": 37.01,
      "eval_steps_per_second": 0.291,
      "step": 4900
    },
    {
      "epoch": 0.2455,
      "grad_norm": 0.38019323348999023,
      "learning_rate": 2.6370701717688557e-05,
      "loss": 0.1554,
      "step": 4910
    },
    {
      "epoch": 0.246,
      "grad_norm": 0.40877825021743774,
      "learning_rate": 2.6354925834776346e-05,
      "loss": 0.154,
      "step": 4920
    },
    {
      "epoch": 0.2465,
      "grad_norm": 0.3968696892261505,
      "learning_rate": 2.6339120479516537e-05,
      "loss": 0.1447,
      "step": 4930
    },
    {
      "epoch": 0.247,
      "grad_norm": 0.4403553605079651,
      "learning_rate": 2.6323285692932814e-05,
      "loss": 0.1449,
      "step": 4940
    },
    {
      "step": 4950,
      "wer/bud500": 0.06324728856666764
    },
    {
      "step": 4950,
      "wer/private": 0.49547511312217196
    },
    {
      "epoch": 0.2475,
      "grad_norm": 0.4332907199859619,
      "learning_rate": 2.630742151612525e-05,
      "loss": 0.1415,
      "step": 4950
    },
    {
      "epoch": 0.248,
      "grad_norm": 0.44003987312316895,
      "learning_rate": 2.629152799027022e-05,
      "loss": 0.1489,
      "step": 4960
    },
    {
      "epoch": 0.2485,
      "grad_norm": 0.35283565521240234,
      "learning_rate": 2.6275605156620248e-05,
      "loss": 0.1313,
      "step": 4970
    },
    {
      "epoch": 0.249,
      "grad_norm": 0.4749104678630829,
      "learning_rate": 2.6259653056503952e-05,
      "loss": 0.1491,
      "step": 4980
    },
    {
      "epoch": 0.2495,
      "grad_norm": 0.3668012320995331,
      "learning_rate": 2.6243671731325897e-05,
      "loss": 0.135,
      "step": 4990
    },
    {
      "step": 5000,
      "wer/bud500": 0.06324728856666764
    },
    {
      "step": 5000,
      "wer/private": 0.4004524886877828
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.334672749042511,
      "learning_rate": 2.6227661222566516e-05,
      "loss": 0.1444,
      "step": 5000
    },
    {
      "epoch": 0.25,
      "eval_loss": 0.08789835125207901,
      "eval_runtime": 203.4332,
      "eval_samples_per_second": 36.867,
      "eval_steps_per_second": 0.29,
      "step": 5000
    },
    {
      "epoch": 0.2505,
      "grad_norm": 0.3289942741394043,
      "learning_rate": 2.6211621571781984e-05,
      "loss": 0.14,
      "step": 5010
    },
    {
      "epoch": 0.251,
      "grad_norm": 0.3645295202732086,
      "learning_rate": 2.619555282060411e-05,
      "loss": 0.145,
      "step": 5020
    },
    {
      "epoch": 0.2515,
      "grad_norm": 0.5274813771247864,
      "learning_rate": 2.617945501074024e-05,
      "loss": 0.1407,
      "step": 5030
    },
    {
      "epoch": 0.252,
      "grad_norm": 0.4045041501522064,
      "learning_rate": 2.6163328183973148e-05,
      "loss": 0.1441,
      "step": 5040
    },
    {
      "step": 5050,
      "wer/bud500": 0.06612681614874148
    },
    {
      "step": 5050,
      "wer/private": 0.3574660633484163
    },
    {
      "epoch": 0.2525,
      "grad_norm": NaN,
      "learning_rate": 2.614878926502466e-05,
      "loss": 0.1596,
      "step": 5050
    },
    {
      "epoch": 0.253,
      "grad_norm": 0.5048208236694336,
      "learning_rate": 2.613260742152262e-05,
      "loss": 0.1474,
      "step": 5060
    },
    {
      "epoch": 0.2535,
      "grad_norm": 0.3943721652030945,
      "learning_rate": 2.6116396682712915e-05,
      "loss": 0.1403,
      "step": 5070
    },
    {
      "epoch": 0.254,
      "grad_norm": 0.36991724371910095,
      "learning_rate": 2.6100157090671408e-05,
      "loss": 0.1513,
      "step": 5080
    },
    {
      "epoch": 0.2545,
      "grad_norm": 0.4476788640022278,
      "learning_rate": 2.608388868754888e-05,
      "loss": 0.1408,
      "step": 5090
    },
    {
      "step": 5100,
      "wer/bud500": 0.0631449703277107
    },
    {
      "step": 5100,
      "wer/private": 0.37895927601809953
    },
    {
      "epoch": 0.255,
      "grad_norm": 0.4236178696155548,
      "learning_rate": 2.6067591515570892e-05,
      "loss": 0.1587,
      "step": 5100
    },
    {
      "epoch": 0.255,
      "eval_loss": 0.08781912922859192,
      "eval_runtime": 210.9804,
      "eval_samples_per_second": 35.548,
      "eval_steps_per_second": 0.28,
      "step": 5100
    },
    {
      "epoch": 0.2555,
      "grad_norm": 0.4054704010486603,
      "learning_rate": 2.605126561703766e-05,
      "loss": 0.1525,
      "step": 5110
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.4952196478843689,
      "learning_rate": 2.603491103432397e-05,
      "loss": 0.1638,
      "step": 5120
    },
    {
      "epoch": 0.2565,
      "grad_norm": 0.42185530066490173,
      "learning_rate": 2.6018527809879066e-05,
      "loss": 0.1509,
      "step": 5130
    },
    {
      "epoch": 0.257,
      "grad_norm": 0.3991692066192627,
      "learning_rate": 2.6002115986226526e-05,
      "loss": 0.1365,
      "step": 5140
    },
    {
      "step": 5150,
      "wer/bud500": 0.06304265208875376
    },
    {
      "step": 5150,
      "wer/private": 0.4920814479638009
    },
    {
      "epoch": 0.2575,
      "grad_norm": 0.3364346921443939,
      "learning_rate": 2.5985675605964154e-05,
      "loss": 0.1308,
      "step": 5150
    },
    {
      "epoch": 0.258,
      "grad_norm": 0.49199944734573364,
      "learning_rate": 2.5969206711763885e-05,
      "loss": 0.1389,
      "step": 5160
    },
    {
      "epoch": 0.2585,
      "grad_norm": 0.3387148976325989,
      "learning_rate": 2.5952709346371655e-05,
      "loss": 0.1553,
      "step": 5170
    },
    {
      "epoch": 0.259,
      "grad_norm": 0.36509180068969727,
      "learning_rate": 2.5936183552607308e-05,
      "loss": 0.1393,
      "step": 5180
    },
    {
      "epoch": 0.2595,
      "grad_norm": 0.39108216762542725,
      "learning_rate": 2.5919629373364467e-05,
      "loss": 0.1549,
      "step": 5190
    },
    {
      "step": 5200,
      "wer/bud500": 0.06292571695851726
    },
    {
      "step": 5200,
      "wer/private": 0.3552036199095023
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.3417099416255951,
      "learning_rate": 2.590304685161043e-05,
      "loss": 0.1326,
      "step": 5200
    },
    {
      "epoch": 0.26,
      "eval_loss": 0.08760885894298553,
      "eval_runtime": 201.9036,
      "eval_samples_per_second": 37.146,
      "eval_steps_per_second": 0.292,
      "step": 5200
    },
    {
      "epoch": 0.2605,
      "grad_norm": 0.5145155787467957,
      "learning_rate": 2.5886436030386072e-05,
      "loss": 0.146,
      "step": 5210
    },
    {
      "epoch": 0.261,
      "grad_norm": 0.46270453929901123,
      "learning_rate": 2.5869796952805702e-05,
      "loss": 0.1573,
      "step": 5220
    },
    {
      "epoch": 0.2615,
      "grad_norm": 0.40558359026908875,
      "learning_rate": 2.5853129662056982e-05,
      "loss": 0.1352,
      "step": 5230
    },
    {
      "epoch": 0.262,
      "grad_norm": 0.39431795477867126,
      "learning_rate": 2.583643420140081e-05,
      "loss": 0.1434,
      "step": 5240
    },
    {
      "step": 5250,
      "wer/bud500": 0.06270646358932382
    },
    {
      "step": 5250,
      "wer/private": 0.35180995475113125
    },
    {
      "epoch": 0.2625,
      "grad_norm": 0.3851265013217926,
      "learning_rate": 2.5819710614171183e-05,
      "loss": 0.1661,
      "step": 5250
    },
    {
      "epoch": 0.263,
      "grad_norm": 0.4557041823863983,
      "learning_rate": 2.5802958943775113e-05,
      "loss": 0.1511,
      "step": 5260
    },
    {
      "epoch": 0.2635,
      "grad_norm": 0.41401728987693787,
      "learning_rate": 2.5786179233692504e-05,
      "loss": 0.1476,
      "step": 5270
    },
    {
      "epoch": 0.264,
      "grad_norm": 0.4026346504688263,
      "learning_rate": 2.576937152747603e-05,
      "loss": 0.1445,
      "step": 5280
    },
    {
      "epoch": 0.2645,
      "grad_norm": 0.4457188844680786,
      "learning_rate": 2.575253586875104e-05,
      "loss": 0.16,
      "step": 5290
    },
    {
      "step": 5300,
      "wer/bud500": 0.06283801561083989
    },
    {
      "step": 5300,
      "wer/private": 0.36538461538461536
    },
    {
      "epoch": 0.265,
      "grad_norm": 0.3722172975540161,
      "learning_rate": 2.5735672301215428e-05,
      "loss": 0.1526,
      "step": 5300
    },
    {
      "epoch": 0.265,
      "eval_loss": 0.08757122606039047,
      "eval_runtime": 201.9105,
      "eval_samples_per_second": 37.145,
      "eval_steps_per_second": 0.292,
      "step": 5300
    },
    {
      "epoch": 0.2655,
      "grad_norm": 0.394572913646698,
      "learning_rate": 2.571878086863954e-05,
      "loss": 0.1441,
      "step": 5310
    },
    {
      "epoch": 0.266,
      "grad_norm": 0.37274792790412903,
      "learning_rate": 2.570186161486603e-05,
      "loss": 0.1498,
      "step": 5320
    },
    {
      "epoch": 0.2665,
      "grad_norm": 0.44916239380836487,
      "learning_rate": 2.5684914583809768e-05,
      "loss": 0.1363,
      "step": 5330
    },
    {
      "epoch": 0.267,
      "grad_norm": 0.39774319529533386,
      "learning_rate": 2.566793981945773e-05,
      "loss": 0.1437,
      "step": 5340
    },
    {
      "step": 5350,
      "wer/bud500": 0.06590756277954804
    },
    {
      "step": 5350,
      "wer/private": 0.3778280542986425
    },
    {
      "epoch": 0.2675,
      "grad_norm": 0.441558837890625,
      "learning_rate": 2.565093736586887e-05,
      "loss": 0.1583,
      "step": 5350
    },
    {
      "epoch": 0.268,
      "grad_norm": 0.371954083442688,
      "learning_rate": 2.563390726717401e-05,
      "loss": 0.1426,
      "step": 5360
    },
    {
      "epoch": 0.2685,
      "grad_norm": 0.42257022857666016,
      "learning_rate": 2.5616849567575727e-05,
      "loss": 0.1458,
      "step": 5370
    },
    {
      "epoch": 0.269,
      "grad_norm": 0.390560120344162,
      "learning_rate": 2.559976431134824e-05,
      "loss": 0.1402,
      "step": 5380
    },
    {
      "epoch": 0.2695,
      "grad_norm": 0.3523325026035309,
      "learning_rate": 2.558265154283729e-05,
      "loss": 0.1528,
      "step": 5390
    },
    {
      "step": 5400,
      "wer/bud500": 0.06795392755868682
    },
    {
      "step": 5400,
      "wer/private": 0.43891402714932126
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.4690817892551422,
      "learning_rate": 2.5565511306460028e-05,
      "loss": 0.1312,
      "step": 5400
    },
    {
      "epoch": 0.27,
      "eval_loss": 0.08742844313383102,
      "eval_runtime": 203.7707,
      "eval_samples_per_second": 36.806,
      "eval_steps_per_second": 0.29,
      "step": 5400
    },
    {
      "epoch": 0.2705,
      "grad_norm": 0.536827564239502,
      "learning_rate": 2.5548343646704897e-05,
      "loss": 0.1551,
      "step": 5410
    },
    {
      "epoch": 0.271,
      "grad_norm": 0.5507076978683472,
      "learning_rate": 2.5531148608131528e-05,
      "loss": 0.1443,
      "step": 5420
    },
    {
      "epoch": 0.2715,
      "grad_norm": 0.39366060495376587,
      "learning_rate": 2.5513926235370603e-05,
      "loss": 0.1523,
      "step": 5430
    },
    {
      "epoch": 0.272,
      "grad_norm": 0.3827265799045563,
      "learning_rate": 2.5496676573123763e-05,
      "loss": 0.146,
      "step": 5440
    },
    {
      "step": 5450,
      "wer/bud500": 0.06538135469348379
    },
    {
      "step": 5450,
      "wer/private": 0.4423076923076923
    },
    {
      "epoch": 0.2725,
      "grad_norm": 0.3601716458797455,
      "learning_rate": 2.5479399666163474e-05,
      "loss": 0.1377,
      "step": 5450
    },
    {
      "epoch": 0.273,
      "grad_norm": 0.4321986436843872,
      "learning_rate": 2.5462095559332916e-05,
      "loss": 0.1522,
      "step": 5460
    },
    {
      "epoch": 0.2735,
      "grad_norm": 0.4492523968219757,
      "learning_rate": 2.5444764297545868e-05,
      "loss": 0.1497,
      "step": 5470
    },
    {
      "epoch": 0.274,
      "grad_norm": 0.48640698194503784,
      "learning_rate": 2.5427405925786598e-05,
      "loss": 0.1436,
      "step": 5480
    },
    {
      "epoch": 0.2745,
      "grad_norm": 0.34576618671417236,
      "learning_rate": 2.5410020489109736e-05,
      "loss": 0.1491,
      "step": 5490
    },
    {
      "step": 5500,
      "wer/bud500": 0.0682754991668372
    },
    {
      "step": 5500,
      "wer/private": 0.334841628959276
    },
    {
      "epoch": 0.275,
      "grad_norm": 0.41365325450897217,
      "learning_rate": 2.539260803264015e-05,
      "loss": 0.1446,
      "step": 5500
    },
    {
      "epoch": 0.275,
      "eval_loss": 0.08710262179374695,
      "eval_runtime": 201.9721,
      "eval_samples_per_second": 37.134,
      "eval_steps_per_second": 0.292,
      "step": 5500
    },
    {
      "epoch": 0.2755,
      "grad_norm": 0.3835722506046295,
      "learning_rate": 2.5375168601572855e-05,
      "loss": 0.1458,
      "step": 5510
    },
    {
      "epoch": 0.276,
      "grad_norm": 0.36020320653915405,
      "learning_rate": 2.535770224117287e-05,
      "loss": 0.1569,
      "step": 5520
    },
    {
      "epoch": 0.2765,
      "grad_norm": 0.45551201701164246,
      "learning_rate": 2.534020899677512e-05,
      "loss": 0.1316,
      "step": 5530
    },
    {
      "epoch": 0.277,
      "grad_norm": 0.42926138639450073,
      "learning_rate": 2.53226889137843e-05,
      "loss": 0.1434,
      "step": 5540
    },
    {
      "step": 5550,
      "wer/bud500": 0.06546905604116117
    },
    {
      "step": 5550,
      "wer/private": 0.3936651583710407
    },
    {
      "epoch": 0.2775,
      "grad_norm": 0.3556232452392578,
      "learning_rate": 2.5305142037674773e-05,
      "loss": 0.1372,
      "step": 5550
    },
    {
      "epoch": 0.278,
      "grad_norm": 0.40248602628707886,
      "learning_rate": 2.5287568413990434e-05,
      "loss": 0.1303,
      "step": 5560
    },
    {
      "epoch": 0.2785,
      "grad_norm": 0.39864581823349,
      "learning_rate": 2.5269968088344614e-05,
      "loss": 0.1247,
      "step": 5570
    },
    {
      "epoch": 0.279,
      "grad_norm": 0.4096044600009918,
      "learning_rate": 2.5252341106419943e-05,
      "loss": 0.1552,
      "step": 5580
    },
    {
      "epoch": 0.2795,
      "grad_norm": 0.3933582901954651,
      "learning_rate": 2.5234687513968247e-05,
      "loss": 0.1471,
      "step": 5590
    },
    {
      "step": 5600,
      "wer/bud500": 0.06565907562779548
    },
    {
      "step": 5600,
      "wer/private": 0.40158371040723984
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.46432065963745117,
      "learning_rate": 2.5217007356810415e-05,
      "loss": 0.157,
      "step": 5600
    },
    {
      "epoch": 0.28,
      "eval_loss": 0.08696747571229935,
      "eval_runtime": 202.2578,
      "eval_samples_per_second": 37.081,
      "eval_steps_per_second": 0.292,
      "step": 5600
    },
    {
      "epoch": 0.2805,
      "grad_norm": 0.5149034261703491,
      "learning_rate": 2.519930068083629e-05,
      "loss": 0.1682,
      "step": 5610
    },
    {
      "epoch": 0.281,
      "grad_norm": 0.4764137268066406,
      "learning_rate": 2.5181567532004538e-05,
      "loss": 0.1611,
      "step": 5620
    },
    {
      "epoch": 0.2815,
      "grad_norm": 0.3716464042663574,
      "learning_rate": 2.5163807956342543e-05,
      "loss": 0.1402,
      "step": 5630
    },
    {
      "epoch": 0.282,
      "grad_norm": 0.42635712027549744,
      "learning_rate": 2.514602199994629e-05,
      "loss": 0.1393,
      "step": 5640
    },
    {
      "step": 5650,
      "wer/bud500": 0.06811471336276201
    },
    {
      "step": 5650,
      "wer/private": 0.38122171945701355
    },
    {
      "epoch": 0.2825,
      "grad_norm": 0.40217891335487366,
      "learning_rate": 2.512820970898022e-05,
      "loss": 0.1464,
      "step": 5650
    },
    {
      "epoch": 0.283,
      "grad_norm": 0.3739386200904846,
      "learning_rate": 2.511037112967713e-05,
      "loss": 0.1398,
      "step": 5660
    },
    {
      "epoch": 0.2835,
      "grad_norm": 0.32812875509262085,
      "learning_rate": 2.5092506308338062e-05,
      "loss": 0.1589,
      "step": 5670
    },
    {
      "epoch": 0.284,
      "grad_norm": 0.5507664084434509,
      "learning_rate": 2.5074615291332164e-05,
      "loss": 0.1464,
      "step": 5680
    },
    {
      "epoch": 0.2845,
      "grad_norm": 0.4043440818786621,
      "learning_rate": 2.505669812509657e-05,
      "loss": 0.1464,
      "step": 5690
    },
    {
      "step": 5700,
      "wer/bud500": 0.0686263045575467
    },
    {
      "step": 5700,
      "wer/private": 0.3416289592760181
    },
    {
      "epoch": 0.285,
      "grad_norm": 0.38034796714782715,
      "learning_rate": 2.503875485613629e-05,
      "loss": 0.1403,
      "step": 5700
    },
    {
      "epoch": 0.285,
      "eval_loss": 0.08676969259977341,
      "eval_runtime": 202.1323,
      "eval_samples_per_second": 37.104,
      "eval_steps_per_second": 0.292,
      "step": 5700
    },
    {
      "epoch": 0.2855,
      "grad_norm": 0.4058317542076111,
      "learning_rate": 2.5020785531024096e-05,
      "loss": 0.1319,
      "step": 5710
    },
    {
      "epoch": 0.286,
      "grad_norm": 0.4078703820705414,
      "learning_rate": 2.500279019640037e-05,
      "loss": 0.1484,
      "step": 5720
    },
    {
      "epoch": 0.2865,
      "grad_norm": 0.41426315903663635,
      "learning_rate": 2.498476889897302e-05,
      "loss": 0.1441,
      "step": 5730
    },
    {
      "epoch": 0.287,
      "grad_norm": 0.4407992660999298,
      "learning_rate": 2.4966721685517324e-05,
      "loss": 0.1531,
      "step": 5740
    },
    {
      "step": 5750,
      "wer/bud500": 0.06261876224164645
    },
    {
      "step": 5750,
      "wer/private": 0.38009049773755654
    },
    {
      "epoch": 0.2875,
      "grad_norm": 0.4606337547302246,
      "learning_rate": 2.494864860287585e-05,
      "loss": 0.1415,
      "step": 5750
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.34876489639282227,
      "learning_rate": 2.4930549697958298e-05,
      "loss": 0.1394,
      "step": 5760
    },
    {
      "epoch": 0.2885,
      "grad_norm": 0.4229840040206909,
      "learning_rate": 2.491242501774139e-05,
      "loss": 0.138,
      "step": 5770
    },
    {
      "epoch": 0.289,
      "grad_norm": 0.3508189022541046,
      "learning_rate": 2.489427460926874e-05,
      "loss": 0.1584,
      "step": 5780
    },
    {
      "epoch": 0.2895,
      "grad_norm": 0.4129384756088257,
      "learning_rate": 2.4876098519650775e-05,
      "loss": 0.1386,
      "step": 5790
    },
    {
      "step": 5800,
      "wer/bud500": 0.06562984184523636
    },
    {
      "step": 5800,
      "wer/private": 0.36312217194570134
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5252379179000854,
      "learning_rate": 2.4857896796064536e-05,
      "loss": 0.1383,
      "step": 5800
    },
    {
      "epoch": 0.29,
      "eval_loss": 0.08655627816915512,
      "eval_runtime": 202.4914,
      "eval_samples_per_second": 37.039,
      "eval_steps_per_second": 0.291,
      "step": 5800
    },
    {
      "epoch": 0.2905,
      "grad_norm": 0.365631103515625,
      "learning_rate": 2.483966948575363e-05,
      "loss": 0.1426,
      "step": 5810
    },
    {
      "epoch": 0.291,
      "grad_norm": 0.4163304269313812,
      "learning_rate": 2.482141663602806e-05,
      "loss": 0.135,
      "step": 5820
    },
    {
      "epoch": 0.2915,
      "grad_norm": 0.365704208612442,
      "learning_rate": 2.4803138294264125e-05,
      "loss": 0.1349,
      "step": 5830
    },
    {
      "epoch": 0.292,
      "grad_norm": 0.33802077174186707,
      "learning_rate": 2.4784834507904282e-05,
      "loss": 0.1491,
      "step": 5840
    },
    {
      "step": 5850,
      "wer/bud500": 0.06546905604116117
    },
    {
      "step": 5850,
      "wer/private": 0.3506787330316742
    },
    {
      "epoch": 0.2925,
      "grad_norm": 0.3961862325668335,
      "learning_rate": 2.4766505324457042e-05,
      "loss": 0.1487,
      "step": 5850
    },
    {
      "epoch": 0.293,
      "grad_norm": 0.3979003131389618,
      "learning_rate": 2.474815079149683e-05,
      "loss": 0.1479,
      "step": 5860
    },
    {
      "epoch": 0.2935,
      "grad_norm": 0.5759485960006714,
      "learning_rate": 2.4729770956663866e-05,
      "loss": 0.1685,
      "step": 5870
    },
    {
      "epoch": 0.294,
      "grad_norm": 0.4306832551956177,
      "learning_rate": 2.4711365867664037e-05,
      "loss": 0.1475,
      "step": 5880
    },
    {
      "epoch": 0.2945,
      "grad_norm": 0.3992384076118469,
      "learning_rate": 2.469293557226879e-05,
      "loss": 0.1367,
      "step": 5890
    },
    {
      "step": 5900,
      "wer/bud500": 0.06225333995965738
    },
    {
      "step": 5900,
      "wer/private": 0.32918552036199095
    },
    {
      "epoch": 0.295,
      "grad_norm": 0.4340026378631592,
      "learning_rate": 2.4674480118314993e-05,
      "loss": 0.1593,
      "step": 5900
    },
    {
      "epoch": 0.295,
      "eval_loss": 0.08636178821325302,
      "eval_runtime": 202.0864,
      "eval_samples_per_second": 37.113,
      "eval_steps_per_second": 0.292,
      "step": 5900
    },
    {
      "epoch": 0.2955,
      "grad_norm": 0.39534318447113037,
      "learning_rate": 2.465599955370481e-05,
      "loss": 0.1477,
      "step": 5910
    },
    {
      "epoch": 0.296,
      "grad_norm": 0.4063144028186798,
      "learning_rate": 2.463749392640559e-05,
      "loss": 0.1403,
      "step": 5920
    },
    {
      "epoch": 0.2965,
      "grad_norm": 0.3410293757915497,
      "learning_rate": 2.461896328444972e-05,
      "loss": 0.1484,
      "step": 5930
    },
    {
      "epoch": 0.297,
      "grad_norm": 0.43110227584838867,
      "learning_rate": 2.4600407675934526e-05,
      "loss": 0.1446,
      "step": 5940
    },
    {
      "step": 5950,
      "wer/bud500": 0.062326424416055196
    },
    {
      "step": 5950,
      "wer/private": 0.36425339366515835
    },
    {
      "epoch": 0.2975,
      "grad_norm": 0.34816646575927734,
      "learning_rate": 2.4581827149022135e-05,
      "loss": 0.1317,
      "step": 5950
    },
    {
      "epoch": 0.298,
      "grad_norm": 0.37638360261917114,
      "learning_rate": 2.4563221751939336e-05,
      "loss": 0.1338,
      "step": 5960
    },
    {
      "epoch": 0.2985,
      "grad_norm": 0.4383629858493805,
      "learning_rate": 2.4544591532977495e-05,
      "loss": 0.1473,
      "step": 5970
    },
    {
      "epoch": 0.299,
      "grad_norm": 0.37827572226524353,
      "learning_rate": 2.452593654049239e-05,
      "loss": 0.1464,
      "step": 5980
    },
    {
      "epoch": 0.2995,
      "grad_norm": 0.40078407526016235,
      "learning_rate": 2.4507256822904097e-05,
      "loss": 0.159,
      "step": 5990
    },
    {
      "step": 6000,
      "wer/bud500": 0.06273569737188295
    },
    {
      "step": 6000,
      "wer/private": 0.36538461538461536
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.34480583667755127,
      "learning_rate": 2.448855242869687e-05,
      "loss": 0.1385,
      "step": 6000
    },
    {
      "epoch": 0.3,
      "eval_loss": 0.08651011437177658,
      "eval_runtime": 201.9982,
      "eval_samples_per_second": 37.129,
      "eval_steps_per_second": 0.292,
      "step": 6000
    },
    {
      "epoch": 0.3005,
      "grad_norm": 0.4705899655818939,
      "learning_rate": 2.4469823406419016e-05,
      "loss": 0.1309,
      "step": 6010
    },
    {
      "epoch": 0.301,
      "grad_norm": 0.37197768688201904,
      "learning_rate": 2.4451069804682766e-05,
      "loss": 0.1398,
      "step": 6020
    },
    {
      "epoch": 0.3015,
      "grad_norm": 0.3986082375049591,
      "learning_rate": 2.443229167216415e-05,
      "loss": 0.1481,
      "step": 6030
    },
    {
      "epoch": 0.302,
      "grad_norm": 0.35478073358535767,
      "learning_rate": 2.441348905760285e-05,
      "loss": 0.1586,
      "step": 6040
    },
    {
      "step": 6050,
      "wer/bud500": 0.06253106089396906
    },
    {
      "step": 6050,
      "wer/private": 0.3404977375565611
    },
    {
      "epoch": 0.3025,
      "grad_norm": 0.3684535622596741,
      "learning_rate": 2.4394662009802128e-05,
      "loss": 0.1376,
      "step": 6050
    },
    {
      "epoch": 0.303,
      "grad_norm": 0.4417736232280731,
      "learning_rate": 2.437581057762863e-05,
      "loss": 0.1396,
      "step": 6060
    },
    {
      "epoch": 0.3035,
      "grad_norm": 0.4036995470523834,
      "learning_rate": 2.435693481001232e-05,
      "loss": 0.1425,
      "step": 6070
    },
    {
      "epoch": 0.304,
      "grad_norm": 0.39604946970939636,
      "learning_rate": 2.4338034755946296e-05,
      "loss": 0.1366,
      "step": 6080
    },
    {
      "epoch": 0.3045,
      "grad_norm": 0.3537193536758423,
      "learning_rate": 2.4319110464486722e-05,
      "loss": 0.1489,
      "step": 6090
    },
    {
      "step": 6100,
      "wer/bud500": 0.06598064723594586
    },
    {
      "step": 6100,
      "wer/private": 0.36877828054298645
    },
    {
      "epoch": 0.305,
      "grad_norm": 0.3818317949771881,
      "learning_rate": 2.430016198475265e-05,
      "loss": 0.1549,
      "step": 6100
    },
    {
      "epoch": 0.305,
      "eval_loss": 0.08684932440519333,
      "eval_runtime": 203.2143,
      "eval_samples_per_second": 36.907,
      "eval_steps_per_second": 0.29,
      "step": 6100
    },
    {
      "epoch": 0.3055,
      "grad_norm": 0.3844160735607147,
      "learning_rate": 2.428118936592593e-05,
      "loss": 0.1392,
      "step": 6110
    },
    {
      "epoch": 0.306,
      "grad_norm": 0.3991709053516388,
      "learning_rate": 2.426219265725106e-05,
      "loss": 0.1505,
      "step": 6120
    },
    {
      "epoch": 0.3065,
      "grad_norm": 0.3963675796985626,
      "learning_rate": 2.4243171908035057e-05,
      "loss": 0.1502,
      "step": 6130
    },
    {
      "epoch": 0.307,
      "grad_norm": 0.46446493268013,
      "learning_rate": 2.4224127167647354e-05,
      "loss": 0.1505,
      "step": 6140
    },
    {
      "step": 6150,
      "wer/bud500": 0.06893325927441751
    },
    {
      "step": 6150,
      "wer/private": 0.3416289592760181
    },
    {
      "epoch": 0.3075,
      "grad_norm": 0.33244359493255615,
      "learning_rate": 2.4205058485519632e-05,
      "loss": 0.1453,
      "step": 6150
    },
    {
      "epoch": 0.308,
      "grad_norm": 0.4010940492153168,
      "learning_rate": 2.4185965911145734e-05,
      "loss": 0.1547,
      "step": 6160
    },
    {
      "epoch": 0.3085,
      "grad_norm": 0.36836981773376465,
      "learning_rate": 2.416684949408151e-05,
      "loss": 0.154,
      "step": 6170
    },
    {
      "epoch": 0.309,
      "grad_norm": 0.4522603452205658,
      "learning_rate": 2.414770928394469e-05,
      "loss": 0.1608,
      "step": 6180
    },
    {
      "epoch": 0.3095,
      "grad_norm": 0.3692491054534912,
      "learning_rate": 2.412854533041476e-05,
      "loss": 0.1521,
      "step": 6190
    },
    {
      "step": 6200,
      "wer/bud500": 0.06869938901394451
    },
    {
      "step": 6200,
      "wer/private": 0.35294117647058826
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.38472649455070496,
      "learning_rate": 2.4109357683232848e-05,
      "loss": 0.1457,
      "step": 6200
    },
    {
      "epoch": 0.31,
      "eval_loss": 0.08661055564880371,
      "eval_runtime": 202.0317,
      "eval_samples_per_second": 37.123,
      "eval_steps_per_second": 0.292,
      "step": 6200
    },
    {
      "epoch": 0.3105,
      "grad_norm": 0.40199220180511475,
      "learning_rate": 2.4090146392201565e-05,
      "loss": 0.1345,
      "step": 6210
    },
    {
      "epoch": 0.311,
      "grad_norm": 0.36688679456710815,
      "learning_rate": 2.4070911507184898e-05,
      "loss": 0.1439,
      "step": 6220
    },
    {
      "epoch": 0.3115,
      "grad_norm": 0.4264446794986725,
      "learning_rate": 2.4051653078108063e-05,
      "loss": 0.139,
      "step": 6230
    },
    {
      "epoch": 0.312,
      "grad_norm": 0.41693976521492004,
      "learning_rate": 2.40323711549574e-05,
      "loss": 0.1488,
      "step": 6240
    },
    {
      "step": 6250,
      "wer/bud500": 0.06443125676031222
    },
    {
      "step": 6250,
      "wer/private": 0.3552036199095023
    },
    {
      "epoch": 0.3125,
      "grad_norm": 0.42928722500801086,
      "learning_rate": 2.4013065787780224e-05,
      "loss": 0.1409,
      "step": 6250
    },
    {
      "epoch": 0.313,
      "grad_norm": 0.4097120761871338,
      "learning_rate": 2.3993737026684697e-05,
      "loss": 0.1369,
      "step": 6260
    },
    {
      "epoch": 0.3135,
      "grad_norm": 0.38477879762649536,
      "learning_rate": 2.3974384921839704e-05,
      "loss": 0.1361,
      "step": 6270
    },
    {
      "epoch": 0.314,
      "grad_norm": 0.3855265974998474,
      "learning_rate": 2.395500952347472e-05,
      "loss": 0.1445,
      "step": 6280
    },
    {
      "epoch": 0.3145,
      "grad_norm": 0.39031997323036194,
      "learning_rate": 2.3935610881879685e-05,
      "loss": 0.147,
      "step": 6290
    },
    {
      "step": 6300,
      "wer/bud500": 0.06495746484637648
    },
    {
      "step": 6300,
      "wer/private": 0.3563348416289593
    },
    {
      "epoch": 0.315,
      "grad_norm": 0.4603695869445801,
      "learning_rate": 2.3916189047404856e-05,
      "loss": 0.1525,
      "step": 6300
    },
    {
      "epoch": 0.315,
      "eval_loss": 0.08630946278572083,
      "eval_runtime": 202.2124,
      "eval_samples_per_second": 37.09,
      "eval_steps_per_second": 0.292,
      "step": 6300
    },
    {
      "epoch": 0.3155,
      "grad_norm": 0.4876498579978943,
      "learning_rate": 2.389674407046069e-05,
      "loss": 0.143,
      "step": 6310
    },
    {
      "epoch": 0.316,
      "grad_norm": 0.480430006980896,
      "learning_rate": 2.387727600151773e-05,
      "loss": 0.1378,
      "step": 6320
    },
    {
      "epoch": 0.3165,
      "grad_norm": 0.4541977345943451,
      "learning_rate": 2.3857784891106433e-05,
      "loss": 0.1328,
      "step": 6330
    },
    {
      "epoch": 0.317,
      "grad_norm": 0.36879345774650574,
      "learning_rate": 2.383827078981707e-05,
      "loss": 0.1544,
      "step": 6340
    },
    {
      "step": 6350,
      "wer/bud500": 0.06504516619405384
    },
    {
      "step": 6350,
      "wer/private": 0.35294117647058826
    },
    {
      "epoch": 0.3175,
      "grad_norm": 0.36446553468704224,
      "learning_rate": 2.381873374829959e-05,
      "loss": 0.1476,
      "step": 6350
    },
    {
      "epoch": 0.318,
      "grad_norm": 0.4634505808353424,
      "learning_rate": 2.3799173817263487e-05,
      "loss": 0.1468,
      "step": 6360
    },
    {
      "epoch": 0.3185,
      "grad_norm": 0.38799309730529785,
      "learning_rate": 2.3779591047477647e-05,
      "loss": 0.1437,
      "step": 6370
    },
    {
      "epoch": 0.319,
      "grad_norm": 0.5147581696510315,
      "learning_rate": 2.3759985489770258e-05,
      "loss": 0.1397,
      "step": 6380
    },
    {
      "epoch": 0.3195,
      "grad_norm": 0.38988396525382996,
      "learning_rate": 2.374035719502864e-05,
      "loss": 0.151,
      "step": 6390
    },
    {
      "step": 6400,
      "wer/bud500": 0.0654544391498816
    },
    {
      "step": 6400,
      "wer/private": 0.36764705882352944
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.44061630964279175,
      "learning_rate": 2.372070621419914e-05,
      "loss": 0.1368,
      "step": 6400
    },
    {
      "epoch": 0.32,
      "eval_loss": 0.08626744896173477,
      "eval_runtime": 201.8323,
      "eval_samples_per_second": 37.16,
      "eval_steps_per_second": 0.292,
      "step": 6400
    },
    {
      "epoch": 0.3205,
      "grad_norm": 0.5034003257751465,
      "learning_rate": 2.3701032598286984e-05,
      "loss": 0.1404,
      "step": 6410
    },
    {
      "epoch": 0.321,
      "grad_norm": 0.3726806938648224,
      "learning_rate": 2.3681336398356137e-05,
      "loss": 0.1454,
      "step": 6420
    },
    {
      "epoch": 0.3215,
      "grad_norm": 0.42188191413879395,
      "learning_rate": 2.36616176655292e-05,
      "loss": 0.1501,
      "step": 6430
    },
    {
      "epoch": 0.322,
      "grad_norm": 0.49959346652030945,
      "learning_rate": 2.364187645098725e-05,
      "loss": 0.1542,
      "step": 6440
    },
    {
      "step": 6450,
      "wer/bud500": 0.06520595199812904
    },
    {
      "step": 6450,
      "wer/private": 0.3404977375565611
    },
    {
      "epoch": 0.3225,
      "grad_norm": 0.5049461722373962,
      "learning_rate": 2.3622112805969713e-05,
      "loss": 0.1445,
      "step": 6450
    },
    {
      "epoch": 0.323,
      "grad_norm": 0.3950217664241791,
      "learning_rate": 2.3602326781774243e-05,
      "loss": 0.1295,
      "step": 6460
    },
    {
      "epoch": 0.3235,
      "grad_norm": 0.46481528878211975,
      "learning_rate": 2.3582518429756578e-05,
      "loss": 0.1427,
      "step": 6470
    },
    {
      "epoch": 0.324,
      "grad_norm": 0.3569053113460541,
      "learning_rate": 2.3562687801330405e-05,
      "loss": 0.1405,
      "step": 6480
    },
    {
      "epoch": 0.3245,
      "grad_norm": 0.36211222410202026,
      "learning_rate": 2.354283494796724e-05,
      "loss": 0.1459,
      "step": 6490
    },
    {
      "step": 6500,
      "wer/bud500": 0.061975619025345687
    },
    {
      "step": 6500,
      "wer/private": 0.32918552036199095
    },
    {
      "epoch": 0.325,
      "grad_norm": 0.42845505475997925,
      "learning_rate": 2.352295992119627e-05,
      "loss": 0.1283,
      "step": 6500
    },
    {
      "epoch": 0.325,
      "eval_loss": 0.08576980978250504,
      "eval_runtime": 202.2976,
      "eval_samples_per_second": 37.074,
      "eval_steps_per_second": 0.292,
      "step": 6500
    },
    {
      "epoch": 0.3255,
      "grad_norm": 0.48926952481269836,
      "learning_rate": 2.350306277260425e-05,
      "loss": 0.1646,
      "step": 6510
    },
    {
      "epoch": 0.326,
      "grad_norm": 0.6481740474700928,
      "learning_rate": 2.3483143553835345e-05,
      "loss": 0.1527,
      "step": 6520
    },
    {
      "epoch": 0.3265,
      "grad_norm": 0.5690939426422119,
      "learning_rate": 2.3463202316590997e-05,
      "loss": 0.1355,
      "step": 6530
    },
    {
      "epoch": 0.327,
      "grad_norm": 0.4173011779785156,
      "learning_rate": 2.3443239112629818e-05,
      "loss": 0.1468,
      "step": 6540
    },
    {
      "step": 6550,
      "wer/bud500": 0.06201946969918438
    },
    {
      "step": 6550,
      "wer/private": 0.3212669683257919
    },
    {
      "epoch": 0.3275,
      "grad_norm": 0.4654732942581177,
      "learning_rate": 2.3423253993767424e-05,
      "loss": 0.1526,
      "step": 6550
    },
    {
      "epoch": 0.328,
      "grad_norm": 0.4254304766654968,
      "learning_rate": 2.3403247011876308e-05,
      "loss": 0.1562,
      "step": 6560
    },
    {
      "epoch": 0.3285,
      "grad_norm": 0.4391672909259796,
      "learning_rate": 2.3383218218885713e-05,
      "loss": 0.1432,
      "step": 6570
    },
    {
      "epoch": 0.329,
      "grad_norm": 0.4141944944858551,
      "learning_rate": 2.3363167666781504e-05,
      "loss": 0.1528,
      "step": 6580
    },
    {
      "epoch": 0.3295,
      "grad_norm": 0.3618374466896057,
      "learning_rate": 2.334309540760601e-05,
      "loss": 0.1426,
      "step": 6590
    },
    {
      "step": 6600,
      "wer/bud500": 0.062209489285818695
    },
    {
      "step": 6600,
      "wer/private": 0.3246606334841629
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.4510054290294647,
      "learning_rate": 2.3323001493457915e-05,
      "loss": 0.1453,
      "step": 6600
    },
    {
      "epoch": 0.33,
      "eval_loss": 0.0857904925942421,
      "eval_runtime": 201.8601,
      "eval_samples_per_second": 37.154,
      "eval_steps_per_second": 0.292,
      "step": 6600
    },
    {
      "epoch": 0.3305,
      "grad_norm": 0.4194272756576538,
      "learning_rate": 2.3302885976492083e-05,
      "loss": 0.1437,
      "step": 6610
    },
    {
      "epoch": 0.331,
      "grad_norm": 0.5018552541732788,
      "learning_rate": 2.3282748908919483e-05,
      "loss": 0.1395,
      "step": 6620
    },
    {
      "epoch": 0.3315,
      "grad_norm": 0.43039315938949585,
      "learning_rate": 2.3262590343007e-05,
      "loss": 0.1405,
      "step": 6630
    },
    {
      "epoch": 0.332,
      "grad_norm": 0.5165089964866638,
      "learning_rate": 2.324241033107733e-05,
      "loss": 0.1435,
      "step": 6640
    },
    {
      "step": 6650,
      "wer/bud500": 0.06219487239453913
    },
    {
      "step": 6650,
      "wer/private": 0.3597285067873303
    },
    {
      "epoch": 0.3325,
      "grad_norm": 0.42731553316116333,
      "learning_rate": 2.3222208925508813e-05,
      "loss": 0.1375,
      "step": 6650
    },
    {
      "epoch": 0.333,
      "grad_norm": 0.4926145076751709,
      "learning_rate": 2.3201986178735344e-05,
      "loss": 0.1426,
      "step": 6660
    },
    {
      "epoch": 0.3335,
      "grad_norm": 0.43809500336647034,
      "learning_rate": 2.3181742143246197e-05,
      "loss": 0.1648,
      "step": 6670
    },
    {
      "epoch": 0.334,
      "grad_norm": 0.42555156350135803,
      "learning_rate": 2.3161476871585894e-05,
      "loss": 0.1637,
      "step": 6680
    },
    {
      "epoch": 0.3345,
      "grad_norm": 0.5259286165237427,
      "learning_rate": 2.3141190416354096e-05,
      "loss": 0.151,
      "step": 6690
    },
    {
      "step": 6700,
      "wer/bud500": 0.062151021720700445
    },
    {
      "step": 6700,
      "wer/private": 0.3269230769230769
    },
    {
      "epoch": 0.335,
      "grad_norm": 0.43192094564437866,
      "learning_rate": 2.3120882830205426e-05,
      "loss": 0.1459,
      "step": 6700
    },
    {
      "epoch": 0.335,
      "eval_loss": 0.08590109646320343,
      "eval_runtime": 202.374,
      "eval_samples_per_second": 37.06,
      "eval_steps_per_second": 0.292,
      "step": 6700
    },
    {
      "epoch": 0.3355,
      "grad_norm": 0.3626177906990051,
      "learning_rate": 2.310055416584937e-05,
      "loss": 0.1324,
      "step": 6710
    },
    {
      "epoch": 0.336,
      "grad_norm": 0.3693111538887024,
      "learning_rate": 2.3080204476050122e-05,
      "loss": 0.1502,
      "step": 6720
    },
    {
      "epoch": 0.3365,
      "grad_norm": 0.3688863515853882,
      "learning_rate": 2.3059833813626438e-05,
      "loss": 0.1493,
      "step": 6730
    },
    {
      "epoch": 0.337,
      "grad_norm": 0.322641521692276,
      "learning_rate": 2.3039442231451522e-05,
      "loss": 0.1407,
      "step": 6740
    },
    {
      "step": 6750,
      "wer/bud500": 0.062092554155582194
    },
    {
      "step": 6750,
      "wer/private": 0.3257918552036199
    },
    {
      "epoch": 0.3375,
      "grad_norm": 0.3785138726234436,
      "learning_rate": 2.3019029782452862e-05,
      "loss": 0.153,
      "step": 6750
    },
    {
      "epoch": 0.338,
      "grad_norm": 0.3907468318939209,
      "learning_rate": 2.2998596519612124e-05,
      "loss": 0.1438,
      "step": 6760
    },
    {
      "epoch": 0.3385,
      "grad_norm": 0.40674272179603577,
      "learning_rate": 2.2978142495964985e-05,
      "loss": 0.1438,
      "step": 6770
    },
    {
      "epoch": 0.339,
      "grad_norm": 0.3371659815311432,
      "learning_rate": 2.295766776460101e-05,
      "loss": 0.1324,
      "step": 6780
    },
    {
      "epoch": 0.3395,
      "grad_norm": 0.4457228481769562,
      "learning_rate": 2.2937172378663522e-05,
      "loss": 0.1447,
      "step": 6790
    },
    {
      "step": 6800,
      "wer/bud500": 0.062384891981173446
    },
    {
      "step": 6800,
      "wer/private": 0.3190045248868778
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.3653724491596222,
      "learning_rate": 2.2916656391349435e-05,
      "loss": 0.1623,
      "step": 6800
    },
    {
      "epoch": 0.34,
      "eval_loss": 0.0864851102232933,
      "eval_runtime": 202.0377,
      "eval_samples_per_second": 37.122,
      "eval_steps_per_second": 0.292,
      "step": 6800
    },
    {
      "epoch": 0.3405,
      "grad_norm": 0.4335024654865265,
      "learning_rate": 2.2896119855909156e-05,
      "loss": 0.1432,
      "step": 6810
    },
    {
      "epoch": 0.341,
      "grad_norm": 0.3719708025455475,
      "learning_rate": 2.2875562825646407e-05,
      "loss": 0.1431,
      "step": 6820
    },
    {
      "epoch": 0.3415,
      "grad_norm": 0.4348156452178955,
      "learning_rate": 2.285498535391812e-05,
      "loss": 0.1453,
      "step": 6830
    },
    {
      "epoch": 0.342,
      "grad_norm": 0.41036415100097656,
      "learning_rate": 2.2834387494134275e-05,
      "loss": 0.1516,
      "step": 6840
    },
    {
      "step": 6850,
      "wer/bud500": 0.06517671821556992
    },
    {
      "step": 6850,
      "wer/private": 0.3212669683257919
    },
    {
      "epoch": 0.3425,
      "grad_norm": 0.480282723903656,
      "learning_rate": 2.2813769299757784e-05,
      "loss": 0.1516,
      "step": 6850
    },
    {
      "epoch": 0.343,
      "grad_norm": 0.4121401906013489,
      "learning_rate": 2.279313082430431e-05,
      "loss": 0.1524,
      "step": 6860
    },
    {
      "epoch": 0.3435,
      "grad_norm": 0.38417670130729675,
      "learning_rate": 2.2772472121342192e-05,
      "loss": 0.1467,
      "step": 6870
    },
    {
      "epoch": 0.344,
      "grad_norm": 0.40400058031082153,
      "learning_rate": 2.2751793244492247e-05,
      "loss": 0.1409,
      "step": 6880
    },
    {
      "epoch": 0.3445,
      "grad_norm": 0.3886260986328125,
      "learning_rate": 2.273109424742766e-05,
      "loss": 0.1416,
      "step": 6890
    },
    {
      "step": 6900,
      "wer/bud500": 0.061931768351507
    },
    {
      "step": 6900,
      "wer/private": 0.3223981900452489
    },
    {
      "epoch": 0.345,
      "grad_norm": 0.5825560092926025,
      "learning_rate": 2.2710375183873838e-05,
      "loss": 0.1414,
      "step": 6900
    },
    {
      "epoch": 0.345,
      "eval_loss": 0.08538541942834854,
      "eval_runtime": 218.3488,
      "eval_samples_per_second": 34.349,
      "eval_steps_per_second": 0.27,
      "step": 6900
    },
    {
      "epoch": 0.3455,
      "grad_norm": 0.4257892370223999,
      "learning_rate": 2.2689636107608277e-05,
      "loss": 0.1402,
      "step": 6910
    },
    {
      "epoch": 0.346,
      "grad_norm": 0.34569570422172546,
      "learning_rate": 2.2668877072460416e-05,
      "loss": 0.1388,
      "step": 6920
    },
    {
      "epoch": 0.3465,
      "grad_norm": 0.5833098888397217,
      "learning_rate": 2.2648098132311492e-05,
      "loss": 0.1388,
      "step": 6930
    },
    {
      "epoch": 0.347,
      "grad_norm": 0.38209855556488037,
      "learning_rate": 2.262729934109441e-05,
      "loss": 0.1356,
      "step": 6940
    },
    {
      "step": 6950,
      "wer/bud500": 0.06460665945566697
    },
    {
      "step": 6950,
      "wer/private": 0.3427601809954751
    },
    {
      "epoch": 0.3475,
      "grad_norm": 0.36857831478118896,
      "learning_rate": 2.2606480752793606e-05,
      "loss": 0.1338,
      "step": 6950
    },
    {
      "epoch": 0.348,
      "grad_norm": 0.45035097002983093,
      "learning_rate": 2.2585642421444893e-05,
      "loss": 0.1348,
      "step": 6960
    },
    {
      "epoch": 0.3485,
      "grad_norm": 0.44496020674705505,
      "learning_rate": 2.2564784401135333e-05,
      "loss": 0.142,
      "step": 6970
    },
    {
      "epoch": 0.349,
      "grad_norm": 0.6418196558952332,
      "learning_rate": 2.2543906746003078e-05,
      "loss": 0.1428,
      "step": 6980
    },
    {
      "epoch": 0.3495,
      "grad_norm": 0.3767825961112976,
      "learning_rate": 2.2523009510237268e-05,
      "loss": 0.1386,
      "step": 6990
    },
    {
      "step": 7000,
      "wer/bud500": 0.06182945011255006
    },
    {
      "step": 7000,
      "wer/private": 0.33031674208144796
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.3835366368293762,
      "learning_rate": 2.250209274807784e-05,
      "loss": 0.1384,
      "step": 7000
    },
    {
      "epoch": 0.35,
      "eval_loss": 0.08555655181407928,
      "eval_runtime": 218.9317,
      "eval_samples_per_second": 34.257,
      "eval_steps_per_second": 0.269,
      "step": 7000
    },
    {
      "epoch": 0.3505,
      "grad_norm": 0.4328334629535675,
      "learning_rate": 2.2481156513815435e-05,
      "loss": 0.1519,
      "step": 7010
    },
    {
      "epoch": 0.351,
      "grad_norm": 0.4242846965789795,
      "learning_rate": 2.2460200861791218e-05,
      "loss": 0.1375,
      "step": 7020
    },
    {
      "epoch": 0.3515,
      "grad_norm": 0.3863305449485779,
      "learning_rate": 2.2439225846396763e-05,
      "loss": 0.1387,
      "step": 7030
    },
    {
      "epoch": 0.352,
      "grad_norm": 0.4494771659374237,
      "learning_rate": 2.2418231522073897e-05,
      "loss": 0.1519,
      "step": 7040
    },
    {
      "step": 7050,
      "wer/bud500": 0.06520595199812904
    },
    {
      "step": 7050,
      "wer/private": 0.334841628959276
    },
    {
      "epoch": 0.3525,
      "grad_norm": 0.4005126655101776,
      "learning_rate": 2.2397217943314572e-05,
      "loss": 0.139,
      "step": 7050
    },
    {
      "epoch": 0.353,
      "grad_norm": 0.39261573553085327,
      "learning_rate": 2.2376185164660704e-05,
      "loss": 0.1346,
      "step": 7060
    },
    {
      "epoch": 0.3535,
      "grad_norm": 0.3696962296962738,
      "learning_rate": 2.2355133240704062e-05,
      "loss": 0.1489,
      "step": 7070
    },
    {
      "epoch": 0.354,
      "grad_norm": 0.34812095761299133,
      "learning_rate": 2.2334062226086093e-05,
      "loss": 0.1379,
      "step": 7080
    },
    {
      "epoch": 0.3545,
      "grad_norm": 0.4701317846775055,
      "learning_rate": 2.2312972175497798e-05,
      "loss": 0.1529,
      "step": 7090
    },
    {
      "step": 7100,
      "wer/bud500": 0.06196100213406613
    },
    {
      "step": 7100,
      "wer/private": 0.3178733031674208
    },
    {
      "epoch": 0.355,
      "grad_norm": 0.5472075343132019,
      "learning_rate": 2.2291863143679584e-05,
      "loss": 0.1464,
      "step": 7100
    },
    {
      "epoch": 0.355,
      "eval_loss": 0.08534225076436996,
      "eval_runtime": 221.0532,
      "eval_samples_per_second": 33.928,
      "eval_steps_per_second": 0.267,
      "step": 7100
    },
    {
      "epoch": 0.3555,
      "grad_norm": 0.40852051973342896,
      "learning_rate": 2.227073518542113e-05,
      "loss": 0.1344,
      "step": 7110
    },
    {
      "epoch": 0.356,
      "grad_norm": 0.35128429532051086,
      "learning_rate": 2.224958835556124e-05,
      "loss": 0.135,
      "step": 7120
    },
    {
      "epoch": 0.3565,
      "grad_norm": 0.4507766664028168,
      "learning_rate": 2.2228422708987697e-05,
      "loss": 0.1451,
      "step": 7130
    },
    {
      "epoch": 0.357,
      "grad_norm": 0.41240614652633667,
      "learning_rate": 2.2207238300637123e-05,
      "loss": 0.1486,
      "step": 7140
    },
    {
      "step": 7150,
      "wer/bud500": 0.06514748443301079
    },
    {
      "step": 7150,
      "wer/private": 0.3246606334841629
    },
    {
      "epoch": 0.3575,
      "grad_norm": 0.4175037145614624,
      "learning_rate": 2.218603518549485e-05,
      "loss": 0.148,
      "step": 7150
    },
    {
      "epoch": 0.358,
      "grad_norm": 0.4367856979370117,
      "learning_rate": 2.2164813418594742e-05,
      "loss": 0.1538,
      "step": 7160
    },
    {
      "epoch": 0.3585,
      "grad_norm": 0.49462568759918213,
      "learning_rate": 2.2143573055019088e-05,
      "loss": 0.1545,
      "step": 7170
    },
    {
      "epoch": 0.359,
      "grad_norm": 0.33615773916244507,
      "learning_rate": 2.2122314149898446e-05,
      "loss": 0.1531,
      "step": 7180
    },
    {
      "epoch": 0.3595,
      "grad_norm": 0.4354277551174164,
      "learning_rate": 2.21010367584115e-05,
      "loss": 0.1488,
      "step": 7190
    },
    {
      "step": 7200,
      "wer/bud500": 0.06163943052591575
    },
    {
      "step": 7200,
      "wer/private": 0.35180995475113125
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.366830050945282,
      "learning_rate": 2.207974093578492e-05,
      "loss": 0.1389,
      "step": 7200
    },
    {
      "epoch": 0.36,
      "eval_loss": 0.08534426987171173,
      "eval_runtime": 218.5723,
      "eval_samples_per_second": 34.314,
      "eval_steps_per_second": 0.27,
      "step": 7200
    },
    {
      "epoch": 0.3605,
      "grad_norm": 0.5304949283599854,
      "learning_rate": 2.2058426737293195e-05,
      "loss": 0.1377,
      "step": 7210
    },
    {
      "epoch": 0.361,
      "grad_norm": 0.443096786737442,
      "learning_rate": 2.2037094218258533e-05,
      "loss": 0.1377,
      "step": 7220
    },
    {
      "epoch": 0.3615,
      "grad_norm": 0.4178987145423889,
      "learning_rate": 2.2015743434050688e-05,
      "loss": 0.1499,
      "step": 7230
    },
    {
      "epoch": 0.362,
      "grad_norm": 0.35771000385284424,
      "learning_rate": 2.199437444008681e-05,
      "loss": 0.138,
      "step": 7240
    },
    {
      "step": 7250,
      "wer/bud500": 0.06500131552021517
    },
    {
      "step": 7250,
      "wer/private": 0.39705882352941174
    },
    {
      "epoch": 0.3625,
      "grad_norm": 0.5776960253715515,
      "learning_rate": 2.1972987291831327e-05,
      "loss": 0.1433,
      "step": 7250
    },
    {
      "epoch": 0.363,
      "grad_norm": 0.47802647948265076,
      "learning_rate": 2.1951582044795787e-05,
      "loss": 0.15,
      "step": 7260
    },
    {
      "epoch": 0.3635,
      "grad_norm": 0.362631231546402,
      "learning_rate": 2.193015875453871e-05,
      "loss": 0.1326,
      "step": 7270
    },
    {
      "epoch": 0.364,
      "grad_norm": 0.4386747181415558,
      "learning_rate": 2.190871747666544e-05,
      "loss": 0.1454,
      "step": 7280
    },
    {
      "epoch": 0.3645,
      "grad_norm": 0.4573267698287964,
      "learning_rate": 2.1887258266828024e-05,
      "loss": 0.157,
      "step": 7290
    },
    {
      "step": 7300,
      "wer/bud500": 0.06491361417253778
    },
    {
      "step": 7300,
      "wer/private": 0.4061085972850679
    },
    {
      "epoch": 0.365,
      "grad_norm": 0.43938663601875305,
      "learning_rate": 2.186578118072505e-05,
      "loss": 0.1446,
      "step": 7300
    },
    {
      "epoch": 0.365,
      "eval_loss": 0.08581074327230453,
      "eval_runtime": 222.2793,
      "eval_samples_per_second": 33.741,
      "eval_steps_per_second": 0.265,
      "step": 7300
    },
    {
      "epoch": 0.3655,
      "grad_norm": 0.3909321427345276,
      "learning_rate": 2.18442862741015e-05,
      "loss": 0.1468,
      "step": 7310
    },
    {
      "epoch": 0.366,
      "grad_norm": 0.3583092987537384,
      "learning_rate": 2.18227736027486e-05,
      "loss": 0.1417,
      "step": 7320
    },
    {
      "epoch": 0.3665,
      "grad_norm": 0.3487439751625061,
      "learning_rate": 2.180124322250371e-05,
      "loss": 0.1508,
      "step": 7330
    },
    {
      "epoch": 0.367,
      "grad_norm": 0.5886825323104858,
      "learning_rate": 2.1779695189250136e-05,
      "loss": 0.1371,
      "step": 7340
    },
    {
      "step": 7350,
      "wer/bud500": 0.061697898091034
    },
    {
      "step": 7350,
      "wer/private": 0.3733031674208145
    },
    {
      "epoch": 0.3675,
      "grad_norm": 0.34025558829307556,
      "learning_rate": 2.1758129558917008e-05,
      "loss": 0.1419,
      "step": 7350
    },
    {
      "epoch": 0.368,
      "grad_norm": 0.40446048974990845,
      "learning_rate": 2.1736546387479125e-05,
      "loss": 0.1531,
      "step": 7360
    },
    {
      "epoch": 0.3685,
      "grad_norm": 0.36712080240249634,
      "learning_rate": 2.171494573095683e-05,
      "loss": 0.139,
      "step": 7370
    },
    {
      "epoch": 0.369,
      "grad_norm": 0.4043123126029968,
      "learning_rate": 2.1693327645415834e-05,
      "loss": 0.1357,
      "step": 7380
    },
    {
      "epoch": 0.3695,
      "grad_norm": 0.376321017742157,
      "learning_rate": 2.1671692186967096e-05,
      "loss": 0.1412,
      "step": 7390
    },
    {
      "step": 7400,
      "wer/bud500": 0.06505978308533342
    },
    {
      "step": 7400,
      "wer/private": 0.3665158371040724
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.37714457511901855,
      "learning_rate": 2.1650039411766657e-05,
      "loss": 0.1381,
      "step": 7400
    },
    {
      "epoch": 0.37,
      "eval_loss": 0.08507353812456131,
      "eval_runtime": 219.3684,
      "eval_samples_per_second": 34.189,
      "eval_steps_per_second": 0.269,
      "step": 7400
    },
    {
      "epoch": 0.3705,
      "grad_norm": 0.4288749396800995,
      "learning_rate": 2.1628369376015516e-05,
      "loss": 0.1493,
      "step": 7410
    },
    {
      "epoch": 0.371,
      "grad_norm": 0.47939276695251465,
      "learning_rate": 2.160668213595947e-05,
      "loss": 0.1469,
      "step": 7420
    },
    {
      "epoch": 0.3715,
      "grad_norm": 0.34047219157218933,
      "learning_rate": 2.1584977747888962e-05,
      "loss": 0.1383,
      "step": 7430
    },
    {
      "epoch": 0.372,
      "grad_norm": 0.42106226086616516,
      "learning_rate": 2.156325626813895e-05,
      "loss": 0.1435,
      "step": 7440
    },
    {
      "step": 7450,
      "wer/bud500": 0.06235565819861432
    },
    {
      "step": 7450,
      "wer/private": 0.38122171945701355
    },
    {
      "epoch": 0.3725,
      "grad_norm": 0.36069875955581665,
      "learning_rate": 2.154151775308876e-05,
      "loss": 0.1301,
      "step": 7450
    },
    {
      "epoch": 0.373,
      "grad_norm": 0.41131943464279175,
      "learning_rate": 2.1519762259161924e-05,
      "loss": 0.1394,
      "step": 7460
    },
    {
      "epoch": 0.3735,
      "grad_norm": 0.3801504671573639,
      "learning_rate": 2.149798984282605e-05,
      "loss": 0.1459,
      "step": 7470
    },
    {
      "epoch": 0.374,
      "grad_norm": 0.41844436526298523,
      "learning_rate": 2.1476200560592665e-05,
      "loss": 0.1555,
      "step": 7480
    },
    {
      "epoch": 0.3745,
      "grad_norm": 0.44673147797584534,
      "learning_rate": 2.145439446901708e-05,
      "loss": 0.1456,
      "step": 7490
    },
    {
      "step": 7500,
      "wer/bud500": 0.06418276960855965
    },
    {
      "step": 7500,
      "wer/private": 0.34502262443438914
    },
    {
      "epoch": 0.375,
      "grad_norm": 0.36113980412483215,
      "learning_rate": 2.143257162469822e-05,
      "loss": 0.1436,
      "step": 7500
    },
    {
      "epoch": 0.375,
      "eval_loss": 0.08486269414424896,
      "eval_runtime": 218.7541,
      "eval_samples_per_second": 34.285,
      "eval_steps_per_second": 0.27,
      "step": 7500
    },
    {
      "epoch": 0.3755,
      "grad_norm": 0.4800073802471161,
      "learning_rate": 2.1410732084278517e-05,
      "loss": 0.1457,
      "step": 7510
    },
    {
      "epoch": 0.376,
      "grad_norm": 0.4054034650325775,
      "learning_rate": 2.138887590444371e-05,
      "loss": 0.1482,
      "step": 7520
    },
    {
      "epoch": 0.3765,
      "grad_norm": 0.4005603790283203,
      "learning_rate": 2.136700314192275e-05,
      "loss": 0.1584,
      "step": 7530
    },
    {
      "epoch": 0.377,
      "grad_norm": 0.43843159079551697,
      "learning_rate": 2.134511385348762e-05,
      "loss": 0.1384,
      "step": 7540
    },
    {
      "step": 7550,
      "wer/bud500": 0.06453357499926915
    },
    {
      "step": 7550,
      "wer/private": 0.4117647058823529
    },
    {
      "epoch": 0.3775,
      "grad_norm": 0.3826380670070648,
      "learning_rate": 2.132320809595319e-05,
      "loss": 0.1359,
      "step": 7550
    },
    {
      "epoch": 0.378,
      "grad_norm": 0.3401568830013275,
      "learning_rate": 2.1301285926177098e-05,
      "loss": 0.1486,
      "step": 7560
    },
    {
      "epoch": 0.3785,
      "grad_norm": 0.41155415773391724,
      "learning_rate": 2.1279347401059546e-05,
      "loss": 0.1464,
      "step": 7570
    },
    {
      "epoch": 0.379,
      "grad_norm": 0.4167034924030304,
      "learning_rate": 2.125739257754323e-05,
      "loss": 0.1434,
      "step": 7580
    },
    {
      "epoch": 0.3795,
      "grad_norm": 0.39942193031311035,
      "learning_rate": 2.123542151261311e-05,
      "loss": 0.1409,
      "step": 7590
    },
    {
      "step": 7600,
      "wer/bud500": 0.0641243020434414
    },
    {
      "step": 7600,
      "wer/private": 0.3269230769230769
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.3541036546230316,
      "learning_rate": 2.1213434263296328e-05,
      "loss": 0.143,
      "step": 7600
    },
    {
      "epoch": 0.38,
      "eval_loss": 0.08476483076810837,
      "eval_runtime": 218.1911,
      "eval_samples_per_second": 34.374,
      "eval_steps_per_second": 0.27,
      "step": 7600
    },
    {
      "epoch": 0.3805,
      "grad_norm": 0.3900751769542694,
      "learning_rate": 2.1191430886662018e-05,
      "loss": 0.1433,
      "step": 7610
    },
    {
      "epoch": 0.381,
      "grad_norm": 0.3469489514827728,
      "learning_rate": 2.1169411439821188e-05,
      "loss": 0.1492,
      "step": 7620
    },
    {
      "epoch": 0.3815,
      "grad_norm": 0.39025452733039856,
      "learning_rate": 2.1147375979926543e-05,
      "loss": 0.1408,
      "step": 7630
    },
    {
      "epoch": 0.382,
      "grad_norm": 0.4900255501270294,
      "learning_rate": 2.1125324564172354e-05,
      "loss": 0.1465,
      "step": 7640
    },
    {
      "step": 7650,
      "wer/bud500": 0.06463589323822609
    },
    {
      "step": 7650,
      "wer/private": 0.3563348416289593
    },
    {
      "epoch": 0.3825,
      "grad_norm": 0.42091503739356995,
      "learning_rate": 2.1103257249794313e-05,
      "loss": 0.136,
      "step": 7650
    },
    {
      "epoch": 0.383,
      "grad_norm": 0.362643301486969,
      "learning_rate": 2.1081174094069375e-05,
      "loss": 0.1473,
      "step": 7660
    },
    {
      "epoch": 0.3835,
      "grad_norm": 0.3535986840724945,
      "learning_rate": 2.105907515431561e-05,
      "loss": 0.1408,
      "step": 7670
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.38952767848968506,
      "learning_rate": 2.103696048789205e-05,
      "loss": 0.1446,
      "step": 7680
    },
    {
      "epoch": 0.3845,
      "grad_norm": 0.4247024655342102,
      "learning_rate": 2.1014830152198562e-05,
      "loss": 0.1411,
      "step": 7690
    },
    {
      "step": 7700,
      "wer/bud500": 0.06443125676031222
    },
    {
      "step": 7700,
      "wer/private": 0.333710407239819
    },
    {
      "epoch": 0.385,
      "grad_norm": 0.4465532898902893,
      "learning_rate": 2.099268420467567e-05,
      "loss": 0.1495,
      "step": 7700
    },
    {
      "epoch": 0.385,
      "eval_loss": 0.08482963591814041,
      "eval_runtime": 219.2824,
      "eval_samples_per_second": 34.202,
      "eval_steps_per_second": 0.269,
      "step": 7700
    },
    {
      "epoch": 0.3855,
      "grad_norm": 0.33615928888320923,
      "learning_rate": 2.0970522702804428e-05,
      "loss": 0.1375,
      "step": 7710
    },
    {
      "epoch": 0.386,
      "grad_norm": 0.37728554010391235,
      "learning_rate": 2.0948345704106255e-05,
      "loss": 0.147,
      "step": 7720
    },
    {
      "epoch": 0.3865,
      "grad_norm": 0.3885713517665863,
      "learning_rate": 2.09261532661428e-05,
      "loss": 0.1405,
      "step": 7730
    },
    {
      "epoch": 0.387,
      "grad_norm": 0.3238115906715393,
      "learning_rate": 2.090394544651578e-05,
      "loss": 0.1504,
      "step": 7740
    },
    {
      "step": 7750,
      "wer/bud500": 0.06450434121671003
    },
    {
      "step": 7750,
      "wer/private": 0.3393665158371041
    },
    {
      "epoch": 0.3875,
      "grad_norm": 0.43285807967185974,
      "learning_rate": 2.0881722302866836e-05,
      "loss": 0.1445,
      "step": 7750
    },
    {
      "epoch": 0.388,
      "grad_norm": 0.38183286786079407,
      "learning_rate": 2.085948389287739e-05,
      "loss": 0.1519,
      "step": 7760
    },
    {
      "epoch": 0.3885,
      "grad_norm": 0.39363521337509155,
      "learning_rate": 2.0837230274268482e-05,
      "loss": 0.1375,
      "step": 7770
    },
    {
      "epoch": 0.389,
      "grad_norm": 0.39875125885009766,
      "learning_rate": 2.0814961504800618e-05,
      "loss": 0.1388,
      "step": 7780
    },
    {
      "epoch": 0.3895,
      "grad_norm": 0.3604433238506317,
      "learning_rate": 2.0792677642273658e-05,
      "loss": 0.1423,
      "step": 7790
    },
    {
      "step": 7800,
      "wer/bud500": 0.06456280878182828
    },
    {
      "step": 7800,
      "wer/private": 0.3744343891402715
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.47415414452552795,
      "learning_rate": 2.0770378744526606e-05,
      "loss": 0.1483,
      "step": 7800
    },
    {
      "epoch": 0.39,
      "eval_loss": 0.0849098265171051,
      "eval_runtime": 218.0993,
      "eval_samples_per_second": 34.388,
      "eval_steps_per_second": 0.271,
      "step": 7800
    },
    {
      "epoch": 0.3905,
      "grad_norm": 0.3896189033985138,
      "learning_rate": 2.0748064869437508e-05,
      "loss": 0.128,
      "step": 7810
    },
    {
      "epoch": 0.391,
      "grad_norm": 0.43876832723617554,
      "learning_rate": 2.0725736074923275e-05,
      "loss": 0.1461,
      "step": 7820
    },
    {
      "epoch": 0.3915,
      "grad_norm": 0.35525572299957275,
      "learning_rate": 2.070339241893956e-05,
      "loss": 0.1291,
      "step": 7830
    },
    {
      "epoch": 0.392,
      "grad_norm": 0.5821254849433899,
      "learning_rate": 2.068103395948056e-05,
      "loss": 0.1407,
      "step": 7840
    },
    {
      "step": 7850,
      "wer/bud500": 0.061551729178238375
    },
    {
      "step": 7850,
      "wer/private": 0.3382352941176471
    },
    {
      "epoch": 0.3925,
      "grad_norm": 0.3568134009838104,
      "learning_rate": 2.0658660754578918e-05,
      "loss": 0.143,
      "step": 7850
    },
    {
      "epoch": 0.393,
      "grad_norm": 0.4311404824256897,
      "learning_rate": 2.0636272862305545e-05,
      "loss": 0.1499,
      "step": 7860
    },
    {
      "epoch": 0.3935,
      "grad_norm": 0.381206214427948,
      "learning_rate": 2.0613870340769477e-05,
      "loss": 0.1439,
      "step": 7870
    },
    {
      "epoch": 0.394,
      "grad_norm": 0.4190171957015991,
      "learning_rate": 2.059145324811771e-05,
      "loss": 0.1446,
      "step": 7880
    },
    {
      "epoch": 0.3945,
      "grad_norm": 0.37375107407569885,
      "learning_rate": 2.0569021642535063e-05,
      "loss": 0.1346,
      "step": 7890
    },
    {
      "step": 7900,
      "wer/bud500": 0.06137632648288362
    },
    {
      "step": 7900,
      "wer/private": 0.36199095022624433
    },
    {
      "epoch": 0.395,
      "grad_norm": 0.3682345747947693,
      "learning_rate": 2.0546575582244043e-05,
      "loss": 0.1487,
      "step": 7900
    },
    {
      "epoch": 0.395,
      "eval_loss": 0.0847356766462326,
      "eval_runtime": 219.227,
      "eval_samples_per_second": 34.211,
      "eval_steps_per_second": 0.269,
      "step": 7900
    },
    {
      "epoch": 0.3955,
      "grad_norm": 0.3822689354419708,
      "learning_rate": 2.0524115125504648e-05,
      "loss": 0.1332,
      "step": 7910
    },
    {
      "epoch": 0.396,
      "grad_norm": 0.3779017925262451,
      "learning_rate": 2.0501640330614252e-05,
      "loss": 0.1447,
      "step": 7920
    },
    {
      "epoch": 0.3965,
      "grad_norm": 0.5905019044876099,
      "learning_rate": 2.0479151255907452e-05,
      "loss": 0.1545,
      "step": 7930
    },
    {
      "epoch": 0.397,
      "grad_norm": 0.3928374946117401,
      "learning_rate": 2.045664795975591e-05,
      "loss": 0.1396,
      "step": 7940
    },
    {
      "step": 7950,
      "wer/bud500": 0.061464027830561
    },
    {
      "step": 7950,
      "wer/private": 0.36764705882352944
    },
    {
      "epoch": 0.3975,
      "grad_norm": 0.4114335775375366,
      "learning_rate": 2.0434130500568188e-05,
      "loss": 0.1339,
      "step": 7950
    },
    {
      "epoch": 0.398,
      "grad_norm": 0.4112982749938965,
      "learning_rate": 2.0411598936789614e-05,
      "loss": 0.1466,
      "step": 7960
    },
    {
      "epoch": 0.3985,
      "grad_norm": 0.42864736914634705,
      "learning_rate": 2.038905332690213e-05,
      "loss": 0.1491,
      "step": 7970
    },
    {
      "epoch": 0.399,
      "grad_norm": 0.4826141595840454,
      "learning_rate": 2.0366493729424133e-05,
      "loss": 0.1439,
      "step": 7980
    },
    {
      "epoch": 0.3995,
      "grad_norm": 0.467428058385849,
      "learning_rate": 2.034392020291033e-05,
      "loss": 0.1389,
      "step": 7990
    },
    {
      "step": 8000,
      "wer/bud500": 0.06142017715672231
    },
    {
      "step": 8000,
      "wer/private": 0.3438914027149321
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.37204092741012573,
      "learning_rate": 2.032133280595156e-05,
      "loss": 0.1479,
      "step": 8000
    },
    {
      "epoch": 0.4,
      "eval_loss": 0.08425618708133698,
      "eval_runtime": 218.3653,
      "eval_samples_per_second": 34.346,
      "eval_steps_per_second": 0.27,
      "step": 8000
    },
    {
      "epoch": 0.4005,
      "grad_norm": 0.4214123487472534,
      "learning_rate": 2.02987315971747e-05,
      "loss": 0.1472,
      "step": 8010
    },
    {
      "epoch": 0.401,
      "grad_norm": 0.4171588718891144,
      "learning_rate": 2.0276116635242443e-05,
      "loss": 0.1656,
      "step": 8020
    },
    {
      "epoch": 0.4015,
      "grad_norm": 0.3477981388568878,
      "learning_rate": 2.0253487978853195e-05,
      "loss": 0.1473,
      "step": 8030
    },
    {
      "epoch": 0.402,
      "grad_norm": 0.4255479872226715,
      "learning_rate": 2.023084568674091e-05,
      "loss": 0.1612,
      "step": 8040
    },
    {
      "step": 8050,
      "wer/bud500": 0.06124477446136756
    },
    {
      "step": 8050,
      "wer/private": 0.40271493212669685
    },
    {
      "epoch": 0.4025,
      "grad_norm": 0.4223208725452423,
      "learning_rate": 2.0208189817674925e-05,
      "loss": 0.1421,
      "step": 8050
    },
    {
      "epoch": 0.403,
      "grad_norm": 0.3768894672393799,
      "learning_rate": 2.018552043045982e-05,
      "loss": 0.1329,
      "step": 8060
    },
    {
      "epoch": 0.4035,
      "grad_norm": 0.3727166950702667,
      "learning_rate": 2.016283758393526e-05,
      "loss": 0.138,
      "step": 8070
    },
    {
      "epoch": 0.404,
      "grad_norm": 0.41721704602241516,
      "learning_rate": 2.0140141336975852e-05,
      "loss": 0.1301,
      "step": 8080
    },
    {
      "epoch": 0.4045,
      "grad_norm": 0.3826947808265686,
      "learning_rate": 2.0117431748490977e-05,
      "loss": 0.1344,
      "step": 8090
    },
    {
      "step": 8100,
      "wer/bud500": 0.06115707311369018
    },
    {
      "step": 8100,
      "wer/private": 0.2997737556561086
    },
    {
      "epoch": 0.405,
      "grad_norm": 0.41051095724105835,
      "learning_rate": 2.0094708877424646e-05,
      "loss": 0.1355,
      "step": 8100
    },
    {
      "epoch": 0.405,
      "eval_loss": 0.08412281423807144,
      "eval_runtime": 221.4791,
      "eval_samples_per_second": 33.863,
      "eval_steps_per_second": 0.266,
      "step": 8100
    },
    {
      "epoch": 0.4055,
      "grad_norm": 0.37575411796569824,
      "learning_rate": 2.007197278275535e-05,
      "loss": 0.1486,
      "step": 8110
    },
    {
      "epoch": 0.406,
      "grad_norm": 0.4552063047885895,
      "learning_rate": 2.0049223523495893e-05,
      "loss": 0.1561,
      "step": 8120
    },
    {
      "epoch": 0.4065,
      "grad_norm": 0.40218445658683777,
      "learning_rate": 2.0026461158693265e-05,
      "loss": 0.1446,
      "step": 8130
    },
    {
      "epoch": 0.407,
      "grad_norm": 0.447388231754303,
      "learning_rate": 2.000368574742845e-05,
      "loss": 0.1354,
      "step": 8140
    },
    {
      "step": 8150,
      "wer/bud500": 0.06105475487473324
    },
    {
      "step": 8150,
      "wer/private": 0.40158371040723984
    },
    {
      "epoch": 0.4075,
      "grad_norm": 0.3645728826522827,
      "learning_rate": 1.998089734881631e-05,
      "loss": 0.1455,
      "step": 8150
    },
    {
      "epoch": 0.408,
      "grad_norm": 0.5258944630622864,
      "learning_rate": 1.995809602200543e-05,
      "loss": 0.1411,
      "step": 8160
    },
    {
      "epoch": 0.4085,
      "grad_norm": 0.3491966128349304,
      "learning_rate": 1.993528182617791e-05,
      "loss": 0.1378,
      "step": 8170
    },
    {
      "epoch": 0.409,
      "grad_norm": 0.5312515497207642,
      "learning_rate": 1.9912454820549283e-05,
      "loss": 0.1437,
      "step": 8180
    },
    {
      "epoch": 0.4095,
      "grad_norm": 0.3623226284980774,
      "learning_rate": 1.9889615064368332e-05,
      "loss": 0.1263,
      "step": 8190
    },
    {
      "step": 8200,
      "wer/bud500": 0.061200923787528866
    },
    {
      "step": 8200,
      "wer/private": 0.4004524886877828
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.40861231088638306,
      "learning_rate": 1.9866762616916925e-05,
      "loss": 0.1549,
      "step": 8200
    },
    {
      "epoch": 0.41,
      "eval_loss": 0.08436064422130585,
      "eval_runtime": 220.393,
      "eval_samples_per_second": 34.03,
      "eval_steps_per_second": 0.268,
      "step": 8200
    },
    {
      "epoch": 0.4105,
      "grad_norm": 0.40996450185775757,
      "learning_rate": 1.9843897537509863e-05,
      "loss": 0.1429,
      "step": 8210
    },
    {
      "epoch": 0.411,
      "grad_norm": 0.40694254636764526,
      "learning_rate": 1.9821019885494752e-05,
      "loss": 0.1453,
      "step": 8220
    },
    {
      "epoch": 0.4115,
      "grad_norm": 0.44288933277130127,
      "learning_rate": 1.9798129720251823e-05,
      "loss": 0.1367,
      "step": 8230
    },
    {
      "epoch": 0.412,
      "grad_norm": 0.4068737030029297,
      "learning_rate": 1.977522710119378e-05,
      "loss": 0.1469,
      "step": 8240
    },
    {
      "step": 8250,
      "wer/bud500": 0.061127839331131056
    },
    {
      "step": 8250,
      "wer/private": 0.39819004524886875
    },
    {
      "epoch": 0.4125,
      "grad_norm": 0.45238977670669556,
      "learning_rate": 1.975231208776566e-05,
      "loss": 0.1499,
      "step": 8250
    },
    {
      "epoch": 0.413,
      "grad_norm": 0.42012110352516174,
      "learning_rate": 1.9729384739444666e-05,
      "loss": 0.1553,
      "step": 8260
    },
    {
      "epoch": 0.4135,
      "grad_norm": 0.40566694736480713,
      "learning_rate": 1.9706445115740023e-05,
      "loss": 0.1351,
      "step": 8270
    },
    {
      "epoch": 0.414,
      "grad_norm": 0.43090271949768066,
      "learning_rate": 1.9683493276192802e-05,
      "loss": 0.1452,
      "step": 8280
    },
    {
      "epoch": 0.4145,
      "grad_norm": 0.41651299595832825,
      "learning_rate": 1.96605292803758e-05,
      "loss": 0.1315,
      "step": 8290
    },
    {
      "step": 8300,
      "wer/bud500": 0.06451895810798959
    },
    {
      "step": 8300,
      "wer/private": 0.3936651583710407
    },
    {
      "epoch": 0.415,
      "grad_norm": 0.432506263256073,
      "learning_rate": 1.9637553187893352e-05,
      "loss": 0.1398,
      "step": 8300
    },
    {
      "epoch": 0.415,
      "eval_loss": 0.08472562581300735,
      "eval_runtime": 219.2749,
      "eval_samples_per_second": 34.204,
      "eval_steps_per_second": 0.269,
      "step": 8300
    },
    {
      "epoch": 0.4155,
      "grad_norm": 0.5301079154014587,
      "learning_rate": 1.96145650583812e-05,
      "loss": 0.1383,
      "step": 8310
    },
    {
      "epoch": 0.416,
      "grad_norm": 0.3781922161579132,
      "learning_rate": 1.9591564951506325e-05,
      "loss": 0.1483,
      "step": 8320
    },
    {
      "epoch": 0.4165,
      "grad_norm": 0.42671656608581543,
      "learning_rate": 1.9568552926966796e-05,
      "loss": 0.1407,
      "step": 8330
    },
    {
      "epoch": 0.417,
      "grad_norm": 0.4454124867916107,
      "learning_rate": 1.9545529044491612e-05,
      "loss": 0.1433,
      "step": 8340
    },
    {
      "step": 8350,
      "wer/bud500": 0.06438740608647353
    },
    {
      "step": 8350,
      "wer/private": 0.3902714932126697
    },
    {
      "epoch": 0.4175,
      "grad_norm": 0.4169407784938812,
      "learning_rate": 1.9522493363840552e-05,
      "loss": 0.1392,
      "step": 8350
    },
    {
      "epoch": 0.418,
      "grad_norm": 0.3963719308376312,
      "learning_rate": 1.949944594480402e-05,
      "loss": 0.1415,
      "step": 8360
    },
    {
      "epoch": 0.4185,
      "grad_norm": 0.5659347772598267,
      "learning_rate": 1.94763868472029e-05,
      "loss": 0.1401,
      "step": 8370
    },
    {
      "epoch": 0.419,
      "grad_norm": 0.42371198534965515,
      "learning_rate": 1.945331613088835e-05,
      "loss": 0.133,
      "step": 8380
    },
    {
      "epoch": 0.4195,
      "grad_norm": 0.3714841604232788,
      "learning_rate": 1.943023385574172e-05,
      "loss": 0.1359,
      "step": 8390
    },
    {
      "step": 8400,
      "wer/bud500": 0.0642412371736779
    },
    {
      "step": 8400,
      "wer/private": 0.37895927601809953
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.4833691418170929,
      "learning_rate": 1.940714008167436e-05,
      "loss": 0.1449,
      "step": 8400
    },
    {
      "epoch": 0.42,
      "eval_loss": 0.08432991057634354,
      "eval_runtime": 218.2948,
      "eval_samples_per_second": 34.357,
      "eval_steps_per_second": 0.27,
      "step": 8400
    },
    {
      "epoch": 0.4205,
      "grad_norm": 0.523371696472168,
      "learning_rate": 1.9384034868627448e-05,
      "loss": 0.1365,
      "step": 8410
    },
    {
      "epoch": 0.421,
      "grad_norm": 0.4069975018501282,
      "learning_rate": 1.9360918276571865e-05,
      "loss": 0.14,
      "step": 8420
    },
    {
      "epoch": 0.4215,
      "grad_norm": 0.43546921014785767,
      "learning_rate": 1.933779036550802e-05,
      "loss": 0.1434,
      "step": 8430
    },
    {
      "epoch": 0.422,
      "grad_norm": 0.4807335138320923,
      "learning_rate": 1.931465119546571e-05,
      "loss": 0.1448,
      "step": 8440
    },
    {
      "step": 8450,
      "wer/bud500": 0.06403660069576403
    },
    {
      "step": 8450,
      "wer/private": 0.38687782805429866
    },
    {
      "epoch": 0.4225,
      "grad_norm": 0.3835165202617645,
      "learning_rate": 1.9291500826503945e-05,
      "loss": 0.1328,
      "step": 8450
    },
    {
      "epoch": 0.423,
      "grad_norm": 0.41855955123901367,
      "learning_rate": 1.9268339318710813e-05,
      "loss": 0.1427,
      "step": 8460
    },
    {
      "epoch": 0.4235,
      "grad_norm": 0.4230242669582367,
      "learning_rate": 1.9245166732203303e-05,
      "loss": 0.1533,
      "step": 8470
    },
    {
      "epoch": 0.424,
      "grad_norm": 0.43821099400520325,
      "learning_rate": 1.922198312712717e-05,
      "loss": 0.1403,
      "step": 8480
    },
    {
      "epoch": 0.4245,
      "grad_norm": 0.47169655561447144,
      "learning_rate": 1.9198788563656757e-05,
      "loss": 0.1424,
      "step": 8490
    },
    {
      "step": 8500,
      "wer/bud500": 0.06419738649983922
    },
    {
      "step": 8500,
      "wer/private": 0.36877828054298645
    },
    {
      "epoch": 0.425,
      "grad_norm": 0.40469950437545776,
      "learning_rate": 1.9175583101994856e-05,
      "loss": 0.1431,
      "step": 8500
    },
    {
      "epoch": 0.425,
      "eval_loss": 0.08413543552160263,
      "eval_runtime": 219.3442,
      "eval_samples_per_second": 34.193,
      "eval_steps_per_second": 0.269,
      "step": 8500
    },
    {
      "epoch": 0.4255,
      "grad_norm": 0.35134172439575195,
      "learning_rate": 1.9152366802372556e-05,
      "loss": 0.1438,
      "step": 8510
    },
    {
      "epoch": 0.426,
      "grad_norm": 0.36462077498435974,
      "learning_rate": 1.9129139725049052e-05,
      "loss": 0.1446,
      "step": 8520
    },
    {
      "epoch": 0.4265,
      "grad_norm": 0.4703938066959381,
      "learning_rate": 1.9105901930311538e-05,
      "loss": 0.1352,
      "step": 8530
    },
    {
      "epoch": 0.427,
      "grad_norm": 0.37255650758743286,
      "learning_rate": 1.9082653478475008e-05,
      "loss": 0.1324,
      "step": 8540
    },
    {
      "step": 8550,
      "wer/bud500": 0.06421200339111878
    },
    {
      "step": 8550,
      "wer/private": 0.3427601809954751
    },
    {
      "epoch": 0.4275,
      "grad_norm": 0.4478302597999573,
      "learning_rate": 1.905939442988213e-05,
      "loss": 0.1441,
      "step": 8550
    },
    {
      "epoch": 0.428,
      "grad_norm": 0.383754700422287,
      "learning_rate": 1.9036124844903067e-05,
      "loss": 0.1372,
      "step": 8560
    },
    {
      "epoch": 0.4285,
      "grad_norm": 0.4168323576450348,
      "learning_rate": 1.901284478393533e-05,
      "loss": 0.1377,
      "step": 8570
    },
    {
      "epoch": 0.429,
      "grad_norm": 0.4514620304107666,
      "learning_rate": 1.898955430740363e-05,
      "loss": 0.1533,
      "step": 8580
    },
    {
      "epoch": 0.4295,
      "grad_norm": 0.4099310338497162,
      "learning_rate": 1.896625347575971e-05,
      "loss": 0.1426,
      "step": 8590
    },
    {
      "step": 8600,
      "wer/bud500": 0.06427047095623703
    },
    {
      "step": 8600,
      "wer/private": 0.38461538461538464
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.42839473485946655,
      "learning_rate": 1.894294234948218e-05,
      "loss": 0.1413,
      "step": 8600
    },
    {
      "epoch": 0.43,
      "eval_loss": 0.08401455730199814,
      "eval_runtime": 218.6253,
      "eval_samples_per_second": 34.305,
      "eval_steps_per_second": 0.27,
      "step": 8600
    },
    {
      "epoch": 0.4305,
      "grad_norm": 0.40275663137435913,
      "learning_rate": 1.891962098907638e-05,
      "loss": 0.1635,
      "step": 8610
    },
    {
      "epoch": 0.431,
      "grad_norm": 0.4761950969696045,
      "learning_rate": 1.8896289455074215e-05,
      "loss": 0.1394,
      "step": 8620
    },
    {
      "epoch": 0.4315,
      "grad_norm": 0.3810219168663025,
      "learning_rate": 1.8872947808033977e-05,
      "loss": 0.1406,
      "step": 8630
    },
    {
      "epoch": 0.432,
      "grad_norm": 0.38251787424087524,
      "learning_rate": 1.8849596108540237e-05,
      "loss": 0.1351,
      "step": 8640
    },
    {
      "step": 8650,
      "wer/bud500": 0.06434355541263484
    },
    {
      "step": 8650,
      "wer/private": 0.3834841628959276
    },
    {
      "epoch": 0.4325,
      "grad_norm": 0.5046746134757996,
      "learning_rate": 1.8826234417203634e-05,
      "loss": 0.1367,
      "step": 8650
    },
    {
      "epoch": 0.433,
      "grad_norm": 0.4498917758464813,
      "learning_rate": 1.880286279466075e-05,
      "loss": 0.138,
      "step": 8660
    },
    {
      "epoch": 0.4335,
      "grad_norm": 0.42376333475112915,
      "learning_rate": 1.8779481301573948e-05,
      "loss": 0.135,
      "step": 8670
    },
    {
      "epoch": 0.434,
      "grad_norm": 0.38162943720817566,
      "learning_rate": 1.8756089998631206e-05,
      "loss": 0.1315,
      "step": 8680
    },
    {
      "epoch": 0.4345,
      "grad_norm": 0.4217642843723297,
      "learning_rate": 1.873268894654596e-05,
      "loss": 0.1426,
      "step": 8690
    },
    {
      "step": 8700,
      "wer/bud500": 0.06456280878182828
    },
    {
      "step": 8700,
      "wer/private": 0.39592760180995473
    },
    {
      "epoch": 0.435,
      "grad_norm": 0.4358225166797638,
      "learning_rate": 1.8709278206056963e-05,
      "loss": 0.1334,
      "step": 8700
    },
    {
      "epoch": 0.435,
      "eval_loss": 0.08388806879520416,
      "eval_runtime": 207.9105,
      "eval_samples_per_second": 36.073,
      "eval_steps_per_second": 0.284,
      "step": 8700
    },
    {
      "epoch": 0.4355,
      "grad_norm": 0.4490034282207489,
      "learning_rate": 1.868585783792809e-05,
      "loss": 0.1452,
      "step": 8710
    },
    {
      "epoch": 0.436,
      "grad_norm": 0.4172270596027374,
      "learning_rate": 1.8662427902948238e-05,
      "loss": 0.1447,
      "step": 8720
    },
    {
      "epoch": 0.4365,
      "grad_norm": 0.4251777231693268,
      "learning_rate": 1.863898846193111e-05,
      "loss": 0.1434,
      "step": 8730
    },
    {
      "epoch": 0.437,
      "grad_norm": 0.3666606843471527,
      "learning_rate": 1.86155395757151e-05,
      "loss": 0.1292,
      "step": 8740
    },
    {
      "step": 8750,
      "wer/bud500": 0.0644751074341509
    },
    {
      "step": 8750,
      "wer/private": 0.5769230769230769
    },
    {
      "epoch": 0.4375,
      "grad_norm": 0.35599222779273987,
      "learning_rate": 1.8592081305163093e-05,
      "loss": 0.134,
      "step": 8750
    },
    {
      "epoch": 0.438,
      "grad_norm": 0.5472573041915894,
      "learning_rate": 1.856861371116237e-05,
      "loss": 0.1357,
      "step": 8760
    },
    {
      "epoch": 0.4385,
      "grad_norm": 0.4098342955112457,
      "learning_rate": 1.854513685462437e-05,
      "loss": 0.1442,
      "step": 8770
    },
    {
      "epoch": 0.439,
      "grad_norm": 0.46296414732933044,
      "learning_rate": 1.85216507964846e-05,
      "loss": 0.1316,
      "step": 8780
    },
    {
      "epoch": 0.4395,
      "grad_norm": 0.36432772874832153,
      "learning_rate": 1.849815559770244e-05,
      "loss": 0.138,
      "step": 8790
    },
    {
      "step": 8800,
      "wer/bud500": 0.0640073669132049
    },
    {
      "step": 8800,
      "wer/private": 0.40158371040723984
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.391562283039093,
      "learning_rate": 1.8477002153951303e-05,
      "loss": 0.1306,
      "step": 8800
    },
    {
      "epoch": 0.44,
      "eval_loss": 0.08412375301122665,
      "eval_runtime": 206.802,
      "eval_samples_per_second": 36.267,
      "eval_steps_per_second": 0.285,
      "step": 8800
    },
    {
      "epoch": 0.4405,
      "grad_norm": 0.4545952081680298,
      "learning_rate": 1.845348975597655e-05,
      "loss": 0.1465,
      "step": 8810
    },
    {
      "epoch": 0.441,
      "grad_norm": 0.39361223578453064,
      "learning_rate": 1.8429968394275216e-05,
      "loss": 0.1357,
      "step": 8820
    },
    {
      "epoch": 0.4415,
      "grad_norm": 0.4180378317832947,
      "learning_rate": 1.840643812989831e-05,
      "loss": 0.1432,
      "step": 8830
    },
    {
      "epoch": 0.442,
      "grad_norm": 0.43938568234443665,
      "learning_rate": 1.8382899023919967e-05,
      "loss": 0.1403,
      "step": 8840
    },
    {
      "step": 8850,
      "wer/bud500": 0.06406583447832315
    },
    {
      "step": 8850,
      "wer/private": 0.4095022624434389
    },
    {
      "epoch": 0.4425,
      "grad_norm": 0.36326563358306885,
      "learning_rate": 1.8359351137437254e-05,
      "loss": 0.1409,
      "step": 8850
    },
    {
      "epoch": 0.443,
      "grad_norm": 0.3544257581233978,
      "learning_rate": 1.833579453157003e-05,
      "loss": 0.1463,
      "step": 8860
    },
    {
      "epoch": 0.4435,
      "grad_norm": 0.4250912666320801,
      "learning_rate": 1.831222926746078e-05,
      "loss": 0.1358,
      "step": 8870
    },
    {
      "epoch": 0.444,
      "grad_norm": 0.43871447443962097,
      "learning_rate": 1.8288655406274495e-05,
      "loss": 0.1358,
      "step": 8880
    },
    {
      "epoch": 0.4445,
      "grad_norm": 0.4055945575237274,
      "learning_rate": 1.826507300919843e-05,
      "loss": 0.1525,
      "step": 8890
    },
    {
      "step": 8900,
      "wer/bud500": 0.06428508784751659
    },
    {
      "step": 8900,
      "wer/private": 0.38009049773755654
    },
    {
      "epoch": 0.445,
      "grad_norm": 0.3969240188598633,
      "learning_rate": 1.8241482137442035e-05,
      "loss": 0.1326,
      "step": 8900
    },
    {
      "epoch": 0.445,
      "eval_loss": 0.08379971235990524,
      "eval_runtime": 207.7714,
      "eval_samples_per_second": 36.097,
      "eval_steps_per_second": 0.284,
      "step": 8900
    },
    {
      "epoch": 0.4455,
      "grad_norm": 0.44759660959243774,
      "learning_rate": 1.8217882852236733e-05,
      "loss": 0.1353,
      "step": 8910
    },
    {
      "epoch": 0.446,
      "grad_norm": 0.39115792512893677,
      "learning_rate": 1.8194275214835804e-05,
      "loss": 0.1395,
      "step": 8920
    },
    {
      "epoch": 0.4465,
      "grad_norm": 0.42021262645721436,
      "learning_rate": 1.817065928651419e-05,
      "loss": 0.135,
      "step": 8930
    },
    {
      "epoch": 0.447,
      "grad_norm": 0.42783695459365845,
      "learning_rate": 1.8147035128568353e-05,
      "loss": 0.1343,
      "step": 8940
    },
    {
      "step": 8950,
      "wer/bud500": 0.0639635162393662
    },
    {
      "step": 8950,
      "wer/private": 0.3393665158371041
    },
    {
      "epoch": 0.4475,
      "grad_norm": 0.4586471915245056,
      "learning_rate": 1.812340280231614e-05,
      "loss": 0.1237,
      "step": 8950
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.457473486661911,
      "learning_rate": 1.8099762369096564e-05,
      "loss": 0.1524,
      "step": 8960
    },
    {
      "epoch": 0.4485,
      "grad_norm": 0.4413578510284424,
      "learning_rate": 1.8076113890269704e-05,
      "loss": 0.1311,
      "step": 8970
    },
    {
      "epoch": 0.449,
      "grad_norm": 0.4095612168312073,
      "learning_rate": 1.805245742721651e-05,
      "loss": 0.1397,
      "step": 8980
    },
    {
      "epoch": 0.4495,
      "grad_norm": 0.44554653763771057,
      "learning_rate": 1.8028793041338667e-05,
      "loss": 0.1348,
      "step": 8990
    },
    {
      "step": 9000,
      "wer/bud500": 0.06124477446136756
    },
    {
      "step": 9000,
      "wer/private": 0.34502262443438914
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.39027032256126404,
      "learning_rate": 1.8005120794058412e-05,
      "loss": 0.1442,
      "step": 9000
    },
    {
      "epoch": 0.45,
      "eval_loss": 0.08374065905809402,
      "eval_runtime": 206.5152,
      "eval_samples_per_second": 36.317,
      "eval_steps_per_second": 0.286,
      "step": 9000
    },
    {
      "epoch": 0.4505,
      "grad_norm": 0.4051668047904968,
      "learning_rate": 1.7981440746818395e-05,
      "loss": 0.1423,
      "step": 9010
    },
    {
      "epoch": 0.451,
      "grad_norm": 0.3375937342643738,
      "learning_rate": 1.7957752961081507e-05,
      "loss": 0.127,
      "step": 9020
    },
    {
      "epoch": 0.4515,
      "grad_norm": 0.39472928643226624,
      "learning_rate": 1.7934057498330724e-05,
      "loss": 0.1272,
      "step": 9030
    },
    {
      "epoch": 0.452,
      "grad_norm": 0.369877427816391,
      "learning_rate": 1.7910354420068953e-05,
      "loss": 0.1547,
      "step": 9040
    },
    {
      "step": 9050,
      "wer/bud500": 0.060908585961937614
    },
    {
      "step": 9050,
      "wer/private": 0.36199095022624433
    },
    {
      "epoch": 0.4525,
      "grad_norm": 0.42339882254600525,
      "learning_rate": 1.7886643787818863e-05,
      "loss": 0.134,
      "step": 9050
    },
    {
      "epoch": 0.453,
      "grad_norm": 0.41376549005508423,
      "learning_rate": 1.7862925663122734e-05,
      "loss": 0.1475,
      "step": 9060
    },
    {
      "epoch": 0.4535,
      "grad_norm": 0.4232148230075836,
      "learning_rate": 1.783920010754229e-05,
      "loss": 0.1433,
      "step": 9070
    },
    {
      "epoch": 0.454,
      "grad_norm": 0.4419946074485779,
      "learning_rate": 1.781546718265854e-05,
      "loss": 0.1503,
      "step": 9080
    },
    {
      "epoch": 0.4545,
      "grad_norm": 0.32503509521484375,
      "learning_rate": 1.7791726950071624e-05,
      "loss": 0.1387,
      "step": 9090
    },
    {
      "step": 9100,
      "wer/bud500": 0.06086473528809893
    },
    {
      "step": 9100,
      "wer/private": 0.3585972850678733
    },
    {
      "epoch": 0.455,
      "grad_norm": 0.5068128705024719,
      "learning_rate": 1.7767979471400648e-05,
      "loss": 0.1467,
      "step": 9100
    },
    {
      "epoch": 0.455,
      "eval_loss": 0.08361291885375977,
      "eval_runtime": 207.1827,
      "eval_samples_per_second": 36.2,
      "eval_steps_per_second": 0.285,
      "step": 9100
    },
    {
      "epoch": 0.4555,
      "grad_norm": 0.4815545380115509,
      "learning_rate": 1.774422480828353e-05,
      "loss": 0.1573,
      "step": 9110
    },
    {
      "epoch": 0.456,
      "grad_norm": 0.3960159718990326,
      "learning_rate": 1.7720463022376828e-05,
      "loss": 0.1363,
      "step": 9120
    },
    {
      "epoch": 0.4565,
      "grad_norm": 0.3880404531955719,
      "learning_rate": 1.7696694175355593e-05,
      "loss": 0.1416,
      "step": 9130
    },
    {
      "epoch": 0.457,
      "grad_norm": 0.45796895027160645,
      "learning_rate": 1.7672918328913204e-05,
      "loss": 0.1438,
      "step": 9140
    },
    {
      "step": 9150,
      "wer/bud500": 0.060967053527055864
    },
    {
      "step": 9150,
      "wer/private": 0.38687782805429866
    },
    {
      "epoch": 0.4575,
      "grad_norm": 0.460845410823822,
      "learning_rate": 1.7649135544761203e-05,
      "loss": 0.1557,
      "step": 9150
    },
    {
      "epoch": 0.458,
      "grad_norm": 0.4572925269603729,
      "learning_rate": 1.7625345884629144e-05,
      "loss": 0.1369,
      "step": 9160
    },
    {
      "epoch": 0.4585,
      "grad_norm": 0.5170207619667053,
      "learning_rate": 1.760154941026442e-05,
      "loss": 0.1382,
      "step": 9170
    },
    {
      "epoch": 0.459,
      "grad_norm": 0.32698413729667664,
      "learning_rate": 1.7577746183432125e-05,
      "loss": 0.1319,
      "step": 9180
    },
    {
      "epoch": 0.4595,
      "grad_norm": 0.33726996183395386,
      "learning_rate": 1.755393626591486e-05,
      "loss": 0.1328,
      "step": 9190
    },
    {
      "step": 9200,
      "wer/bud500": 0.06058701435378724
    },
    {
      "step": 9200,
      "wer/private": 0.3608597285067873
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.4224500358104706,
      "learning_rate": 1.7530119719512617e-05,
      "loss": 0.1412,
      "step": 9200
    },
    {
      "epoch": 0.46,
      "eval_loss": 0.08356446772813797,
      "eval_runtime": 207.3816,
      "eval_samples_per_second": 36.165,
      "eval_steps_per_second": 0.284,
      "step": 9200
    },
    {
      "epoch": 0.4605,
      "grad_norm": 0.43623974919319153,
      "learning_rate": 1.7506296606042568e-05,
      "loss": 0.1434,
      "step": 9210
    },
    {
      "epoch": 0.461,
      "grad_norm": 0.3929203748703003,
      "learning_rate": 1.7482466987338945e-05,
      "loss": 0.145,
      "step": 9220
    },
    {
      "epoch": 0.4615,
      "grad_norm": 0.40992215275764465,
      "learning_rate": 1.7458630925252867e-05,
      "loss": 0.1306,
      "step": 9230
    },
    {
      "epoch": 0.462,
      "grad_norm": 0.406751811504364,
      "learning_rate": 1.7434788481652158e-05,
      "loss": 0.1362,
      "step": 9240
    },
    {
      "step": 9250,
      "wer/bud500": 0.06064548191890549
    },
    {
      "step": 9250,
      "wer/private": 0.36764705882352944
    },
    {
      "epoch": 0.4625,
      "grad_norm": 0.40550798177719116,
      "learning_rate": 1.7410939718421233e-05,
      "loss": 0.1346,
      "step": 9250
    },
    {
      "epoch": 0.463,
      "grad_norm": 0.492933988571167,
      "learning_rate": 1.738708469746089e-05,
      "loss": 0.1448,
      "step": 9260
    },
    {
      "epoch": 0.4635,
      "grad_norm": 0.4465576410293579,
      "learning_rate": 1.7363223480688175e-05,
      "loss": 0.1505,
      "step": 9270
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.3837379515171051,
      "learning_rate": 1.733935613003622e-05,
      "loss": 0.1472,
      "step": 9280
    },
    {
      "epoch": 0.4645,
      "grad_norm": 0.44626057147979736,
      "learning_rate": 1.731548270745407e-05,
      "loss": 0.1436,
      "step": 9290
    },
    {
      "step": 9300,
      "wer/bud500": 0.06074780015786243
    },
    {
      "step": 9300,
      "wer/private": 0.3574660633484163
    },
    {
      "epoch": 0.465,
      "grad_norm": 0.3587435185909271,
      "learning_rate": 1.7291603274906532e-05,
      "loss": 0.128,
      "step": 9300
    },
    {
      "epoch": 0.465,
      "eval_loss": 0.08351624757051468,
      "eval_runtime": 206.5094,
      "eval_samples_per_second": 36.318,
      "eval_steps_per_second": 0.286,
      "step": 9300
    },
    {
      "epoch": 0.4655,
      "grad_norm": 0.4003990590572357,
      "learning_rate": 1.7267717894374022e-05,
      "loss": 0.1442,
      "step": 9310
    },
    {
      "epoch": 0.466,
      "grad_norm": 0.461373507976532,
      "learning_rate": 1.7243826627852374e-05,
      "loss": 0.1585,
      "step": 9320
    },
    {
      "epoch": 0.4665,
      "grad_norm": 0.5479495525360107,
      "learning_rate": 1.721992953735272e-05,
      "loss": 0.1315,
      "step": 9330
    },
    {
      "epoch": 0.467,
      "grad_norm": 0.4027438461780548,
      "learning_rate": 1.7196026684901307e-05,
      "loss": 0.143,
      "step": 9340
    },
    {
      "step": 9350,
      "wer/bud500": 0.06082088461426024
    },
    {
      "step": 9350,
      "wer/private": 0.34728506787330315
    },
    {
      "epoch": 0.4675,
      "grad_norm": 0.3760348856449127,
      "learning_rate": 1.7172118132539318e-05,
      "loss": 0.1297,
      "step": 9350
    },
    {
      "epoch": 0.468,
      "grad_norm": 0.3996759355068207,
      "learning_rate": 1.714820394232275e-05,
      "loss": 0.159,
      "step": 9360
    },
    {
      "epoch": 0.4685,
      "grad_norm": 0.3769628405570984,
      "learning_rate": 1.7124284176322225e-05,
      "loss": 0.1369,
      "step": 9370
    },
    {
      "epoch": 0.469,
      "grad_norm": 0.4369066059589386,
      "learning_rate": 1.710035889662283e-05,
      "loss": 0.1354,
      "step": 9380
    },
    {
      "epoch": 0.4695,
      "grad_norm": 0.42485907673835754,
      "learning_rate": 1.7076428165323994e-05,
      "loss": 0.1463,
      "step": 9390
    },
    {
      "step": 9400,
      "wer/bud500": 0.060236208963077735
    },
    {
      "step": 9400,
      "wer/private": 0.33710407239819007
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.39534470438957214,
      "learning_rate": 1.705249204453925e-05,
      "loss": 0.1394,
      "step": 9400
    },
    {
      "epoch": 0.47,
      "eval_loss": 0.0831761434674263,
      "eval_runtime": 207.0399,
      "eval_samples_per_second": 36.225,
      "eval_steps_per_second": 0.285,
      "step": 9400
    },
    {
      "epoch": 0.4705,
      "grad_norm": 0.4887882173061371,
      "learning_rate": 1.7028550596396157e-05,
      "loss": 0.1319,
      "step": 9410
    },
    {
      "epoch": 0.471,
      "grad_norm": 0.5754568576812744,
      "learning_rate": 1.700460388303609e-05,
      "loss": 0.1404,
      "step": 9420
    },
    {
      "epoch": 0.4715,
      "grad_norm": 0.3607076108455658,
      "learning_rate": 1.6980651966614075e-05,
      "loss": 0.138,
      "step": 9430
    },
    {
      "epoch": 0.472,
      "grad_norm": 0.4395536780357361,
      "learning_rate": 1.695669490929866e-05,
      "loss": 0.1451,
      "step": 9440
    },
    {
      "step": 9450,
      "wer/bud500": 0.06055778057122811
    },
    {
      "step": 9450,
      "wer/private": 0.35180995475113125
    },
    {
      "epoch": 0.4725,
      "grad_norm": 0.38587990403175354,
      "learning_rate": 1.693273277327175e-05,
      "loss": 0.1329,
      "step": 9450
    },
    {
      "epoch": 0.473,
      "grad_norm": 0.35537081956863403,
      "learning_rate": 1.6908765620728394e-05,
      "loss": 0.1236,
      "step": 9460
    },
    {
      "epoch": 0.4735,
      "grad_norm": 0.39967286586761475,
      "learning_rate": 1.688479351387669e-05,
      "loss": 0.1259,
      "step": 9470
    },
    {
      "epoch": 0.474,
      "grad_norm": 0.4492742121219635,
      "learning_rate": 1.6860816514937583e-05,
      "loss": 0.1452,
      "step": 9480
    },
    {
      "epoch": 0.4745,
      "grad_norm": 0.3857288062572479,
      "learning_rate": 1.6836834686144725e-05,
      "loss": 0.1439,
      "step": 9490
    },
    {
      "step": 9500,
      "wer/bud500": 0.06063086502762592
    },
    {
      "step": 9500,
      "wer/private": 0.3733031674208145
    },
    {
      "epoch": 0.475,
      "grad_norm": 0.45331689715385437,
      "learning_rate": 1.6812848089744307e-05,
      "loss": 0.1476,
      "step": 9500
    },
    {
      "epoch": 0.475,
      "eval_loss": 0.08380002528429031,
      "eval_runtime": 209.7566,
      "eval_samples_per_second": 35.756,
      "eval_steps_per_second": 0.281,
      "step": 9500
    },
    {
      "epoch": 0.4755,
      "grad_norm": 0.4796973764896393,
      "learning_rate": 1.6788856787994863e-05,
      "loss": 0.1553,
      "step": 9510
    },
    {
      "epoch": 0.476,
      "grad_norm": 0.46071892976760864,
      "learning_rate": 1.676486084316719e-05,
      "loss": 0.1376,
      "step": 9520
    },
    {
      "epoch": 0.4765,
      "grad_norm": 0.4858667552471161,
      "learning_rate": 1.6740860317544095e-05,
      "loss": 0.1576,
      "step": 9530
    },
    {
      "epoch": 0.477,
      "grad_norm": 0.406808465719223,
      "learning_rate": 1.6716855273420293e-05,
      "loss": 0.1421,
      "step": 9540
    },
    {
      "step": 9550,
      "wer/bud500": 0.060543163679948546
    },
    {
      "step": 9550,
      "wer/private": 0.36990950226244346
    },
    {
      "epoch": 0.4775,
      "grad_norm": 0.45035260915756226,
      "learning_rate": 1.6692845773102225e-05,
      "loss": 0.1377,
      "step": 9550
    },
    {
      "epoch": 0.478,
      "grad_norm": 0.43820881843566895,
      "learning_rate": 1.66688318789079e-05,
      "loss": 0.1387,
      "step": 9560
    },
    {
      "epoch": 0.4785,
      "grad_norm": 0.44187507033348083,
      "learning_rate": 1.6644813653166722e-05,
      "loss": 0.1311,
      "step": 9570
    },
    {
      "epoch": 0.479,
      "grad_norm": 0.4420414865016937,
      "learning_rate": 1.6620791158219348e-05,
      "loss": 0.1301,
      "step": 9580
    },
    {
      "epoch": 0.4795,
      "grad_norm": 0.43486925959587097,
      "learning_rate": 1.6596764456417515e-05,
      "loss": 0.1306,
      "step": 9590
    },
    {
      "step": 9600,
      "wer/bud500": 0.0636565615224954
    },
    {
      "step": 9600,
      "wer/private": 0.3427601809954751
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3669965863227844,
      "learning_rate": 1.6572733610123875e-05,
      "loss": 0.1331,
      "step": 9600
    },
    {
      "epoch": 0.48,
      "eval_loss": 0.08327243477106094,
      "eval_runtime": 204.0264,
      "eval_samples_per_second": 36.76,
      "eval_steps_per_second": 0.289,
      "step": 9600
    },
    {
      "epoch": 0.4805,
      "grad_norm": 0.5050569176673889,
      "learning_rate": 1.654869868171184e-05,
      "loss": 0.1369,
      "step": 9610
    },
    {
      "epoch": 0.481,
      "grad_norm": 0.40241625905036926,
      "learning_rate": 1.652465973356541e-05,
      "loss": 0.1435,
      "step": 9620
    },
    {
      "epoch": 0.4815,
      "grad_norm": 0.524631679058075,
      "learning_rate": 1.6500616828079033e-05,
      "loss": 0.1496,
      "step": 9630
    },
    {
      "epoch": 0.482,
      "grad_norm": 0.33344441652297974,
      "learning_rate": 1.6476570027657417e-05,
      "loss": 0.1476,
      "step": 9640
    },
    {
      "step": 9650,
      "wer/bud500": 0.060426228549712045
    },
    {
      "step": 9650,
      "wer/private": 0.33710407239819007
    },
    {
      "epoch": 0.4825,
      "grad_norm": 0.43281835317611694,
      "learning_rate": 1.645251939471538e-05,
      "loss": 0.1425,
      "step": 9650
    },
    {
      "epoch": 0.483,
      "grad_norm": 0.48359742760658264,
      "learning_rate": 1.6428464991677693e-05,
      "loss": 0.1364,
      "step": 9660
    },
    {
      "epoch": 0.4835,
      "grad_norm": 0.3621113896369934,
      "learning_rate": 1.6404406880978912e-05,
      "loss": 0.1337,
      "step": 9670
    },
    {
      "epoch": 0.484,
      "grad_norm": 0.3525741398334503,
      "learning_rate": 1.638034512506321e-05,
      "loss": 0.1358,
      "step": 9680
    },
    {
      "epoch": 0.4845,
      "grad_norm": 0.5420010089874268,
      "learning_rate": 1.6356279786384227e-05,
      "loss": 0.1411,
      "step": 9690
    },
    {
      "step": 9700,
      "wer/bud500": 0.06009004005028211
    },
    {
      "step": 9700,
      "wer/private": 0.33144796380090497
    },
    {
      "epoch": 0.485,
      "grad_norm": 0.6172387599945068,
      "learning_rate": 1.6332210927404898e-05,
      "loss": 0.1425,
      "step": 9700
    },
    {
      "epoch": 0.485,
      "eval_loss": 0.08335960656404495,
      "eval_runtime": 204.9028,
      "eval_samples_per_second": 36.603,
      "eval_steps_per_second": 0.288,
      "step": 9700
    },
    {
      "epoch": 0.4855,
      "grad_norm": 0.40742436051368713,
      "learning_rate": 1.6308138610597305e-05,
      "loss": 0.1412,
      "step": 9710
    },
    {
      "epoch": 0.486,
      "grad_norm": 0.41537684202194214,
      "learning_rate": 1.6284062898442495e-05,
      "loss": 0.1476,
      "step": 9720
    },
    {
      "epoch": 0.4865,
      "grad_norm": 0.37530648708343506,
      "learning_rate": 1.625998385343033e-05,
      "loss": 0.131,
      "step": 9730
    },
    {
      "epoch": 0.487,
      "grad_norm": 0.4718537926673889,
      "learning_rate": 1.6235901538059324e-05,
      "loss": 0.143,
      "step": 9740
    },
    {
      "step": 9750,
      "wer/bud500": 0.06049931300610986
    },
    {
      "step": 9750,
      "wer/private": 0.32805429864253394
    },
    {
      "epoch": 0.4875,
      "grad_norm": 0.4715442657470703,
      "learning_rate": 1.6211816014836477e-05,
      "loss": 0.1463,
      "step": 9750
    },
    {
      "epoch": 0.488,
      "grad_norm": 0.42736268043518066,
      "learning_rate": 1.6187727346277113e-05,
      "loss": 0.1403,
      "step": 9760
    },
    {
      "epoch": 0.4885,
      "grad_norm": 0.47125133872032166,
      "learning_rate": 1.616363559490474e-05,
      "loss": 0.1405,
      "step": 9770
    },
    {
      "epoch": 0.489,
      "grad_norm": 0.6724454760551453,
      "learning_rate": 1.613954082325083e-05,
      "loss": 0.1532,
      "step": 9780
    },
    {
      "epoch": 0.4895,
      "grad_norm": 0.37284278869628906,
      "learning_rate": 1.6115443093854733e-05,
      "loss": 0.1446,
      "step": 9790
    },
    {
      "step": 9800,
      "wer/bud500": 0.060908585961937614
    },
    {
      "step": 9800,
      "wer/private": 0.32918552036199095
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.4734265208244324,
      "learning_rate": 1.6091342469263447e-05,
      "loss": 0.1349,
      "step": 9800
    },
    {
      "epoch": 0.49,
      "eval_loss": 0.08326227217912674,
      "eval_runtime": 205.1058,
      "eval_samples_per_second": 36.566,
      "eval_steps_per_second": 0.288,
      "step": 9800
    },
    {
      "epoch": 0.4905,
      "grad_norm": 0.42978766560554504,
      "learning_rate": 1.6067239012031508e-05,
      "loss": 0.1532,
      "step": 9810
    },
    {
      "epoch": 0.491,
      "grad_norm": 0.41522732377052307,
      "learning_rate": 1.604313278472078e-05,
      "loss": 0.1302,
      "step": 9820
    },
    {
      "epoch": 0.4915,
      "grad_norm": 0.433436781167984,
      "learning_rate": 1.6019023849900337e-05,
      "loss": 0.14,
      "step": 9830
    },
    {
      "epoch": 0.492,
      "grad_norm": 0.43354058265686035,
      "learning_rate": 1.5994912270146272e-05,
      "loss": 0.1443,
      "step": 9840
    },
    {
      "step": 9850,
      "wer/bud500": 0.06063086502762592
    },
    {
      "step": 9850,
      "wer/private": 0.33031674208144796
    },
    {
      "epoch": 0.4925,
      "grad_norm": 0.42922401428222656,
      "learning_rate": 1.5970798108041544e-05,
      "loss": 0.1538,
      "step": 9850
    },
    {
      "epoch": 0.493,
      "grad_norm": 0.3907785415649414,
      "learning_rate": 1.5946681426175817e-05,
      "loss": 0.1404,
      "step": 9860
    },
    {
      "epoch": 0.4935,
      "grad_norm": 0.9269673824310303,
      "learning_rate": 1.5922562287145286e-05,
      "loss": 0.1442,
      "step": 9870
    },
    {
      "epoch": 0.494,
      "grad_norm": 0.3863978087902069,
      "learning_rate": 1.589844075355254e-05,
      "loss": 0.1492,
      "step": 9880
    },
    {
      "epoch": 0.4945,
      "grad_norm": 0.391253799200058,
      "learning_rate": 1.587431688800637e-05,
      "loss": 0.1471,
      "step": 9890
    },
    {
      "step": 9900,
      "wer/bud500": 0.06016312450667992
    },
    {
      "step": 9900,
      "wer/private": 0.34728506787330315
    },
    {
      "epoch": 0.495,
      "grad_norm": 0.3863603472709656,
      "learning_rate": 1.5850190753121617e-05,
      "loss": 0.1459,
      "step": 9900
    },
    {
      "epoch": 0.495,
      "eval_loss": 0.0837320014834404,
      "eval_runtime": 206.2169,
      "eval_samples_per_second": 36.369,
      "eval_steps_per_second": 0.286,
      "step": 9900
    },
    {
      "epoch": 0.4955,
      "grad_norm": 0.5926646590232849,
      "learning_rate": 1.5826062411519028e-05,
      "loss": 0.1445,
      "step": 9910
    },
    {
      "epoch": 1.0005,
      "grad_norm": 0.5198044180870056,
      "learning_rate": 1.5801931925825067e-05,
      "loss": 0.1241,
      "step": 9920
    },
    {
      "epoch": 1.001,
      "grad_norm": 0.39972439408302307,
      "learning_rate": 1.577779935867176e-05,
      "loss": 0.1485,
      "step": 9930
    },
    {
      "epoch": 1.0015,
      "grad_norm": 0.40324509143829346,
      "learning_rate": 1.5753664772696546e-05,
      "loss": 0.1417,
      "step": 9940
    },
    {
      "step": 9950,
      "wer/bud500": 0.060177741397959485
    },
    {
      "step": 9950,
      "wer/private": 0.33031674208144796
    },
    {
      "epoch": 1.002,
      "grad_norm": 0.47890663146972656,
      "learning_rate": 1.572952823054209e-05,
      "loss": 0.1514,
      "step": 9950
    },
    {
      "epoch": 1.0025,
      "grad_norm": 0.4513969421386719,
      "learning_rate": 1.5705389794856152e-05,
      "loss": 0.1485,
      "step": 9960
    },
    {
      "epoch": 1.003,
      "grad_norm": 0.40077707171440125,
      "learning_rate": 1.5681249528291392e-05,
      "loss": 0.1468,
      "step": 9970
    },
    {
      "epoch": 1.0035,
      "grad_norm": 0.3780869245529175,
      "learning_rate": 1.5657107493505226e-05,
      "loss": 0.1354,
      "step": 9980
    },
    {
      "epoch": 1.004,
      "grad_norm": 0.40948259830474854,
      "learning_rate": 1.5632963753159667e-05,
      "loss": 0.148,
      "step": 9990
    },
    {
      "step": 10000,
      "wer/bud500": 0.06032391031075511
    },
    {
      "step": 10000,
      "wer/private": 0.3382352941176471
    },
    {
      "epoch": 1.0045,
      "grad_norm": 0.35626330971717834,
      "learning_rate": 1.5608818369921143e-05,
      "loss": 0.1351,
      "step": 10000
    },
    {
      "epoch": 1.0045,
      "eval_loss": 0.08369145542383194,
      "eval_runtime": 204.9792,
      "eval_samples_per_second": 36.589,
      "eval_steps_per_second": 0.288,
      "step": 10000
    },
    {
      "epoch": 1.005,
      "grad_norm": 0.4439525008201599,
      "learning_rate": 1.5584671406460348e-05,
      "loss": 0.1336,
      "step": 10010
    },
    {
      "epoch": 1.0055,
      "grad_norm": 0.4163508713245392,
      "learning_rate": 1.5560522925452096e-05,
      "loss": 0.1315,
      "step": 10020
    },
    {
      "epoch": 1.006,
      "grad_norm": 0.3901071548461914,
      "learning_rate": 1.5536372989575114e-05,
      "loss": 0.1387,
      "step": 10030
    },
    {
      "epoch": 1.0065,
      "grad_norm": 0.34300822019577026,
      "learning_rate": 1.5512221661511916e-05,
      "loss": 0.1399,
      "step": 10040
    },
    {
      "step": 10050,
      "wer/bud500": 0.06026544274563686
    },
    {
      "step": 10050,
      "wer/private": 0.3235294117647059
    },
    {
      "epoch": 1.007,
      "grad_norm": 0.3991570472717285,
      "learning_rate": 1.5488069003948634e-05,
      "loss": 0.1402,
      "step": 10050
    },
    {
      "epoch": 1.0075,
      "grad_norm": 0.49936729669570923,
      "learning_rate": 1.546391507957485e-05,
      "loss": 0.134,
      "step": 10060
    },
    {
      "epoch": 1.008,
      "grad_norm": 0.363731324672699,
      "learning_rate": 1.543975995108343e-05,
      "loss": 0.1379,
      "step": 10070
    },
    {
      "epoch": 1.0085,
      "grad_norm": 0.4230264127254486,
      "learning_rate": 1.5415603681170354e-05,
      "loss": 0.1449,
      "step": 10080
    },
    {
      "epoch": 1.009,
      "grad_norm": 0.4007437527179718,
      "learning_rate": 1.5391446332534593e-05,
      "loss": 0.1407,
      "step": 10090
    },
    {
      "step": 10100,
      "wer/bud500": 0.060353144093314236
    },
    {
      "step": 10100,
      "wer/private": 0.3246606334841629
    },
    {
      "epoch": 1.0095,
      "grad_norm": 0.4690008759498596,
      "learning_rate": 1.5367287967877897e-05,
      "loss": 0.1525,
      "step": 10100
    },
    {
      "epoch": 1.0095,
      "eval_loss": 0.08321019262075424,
      "eval_runtime": 204.4729,
      "eval_samples_per_second": 36.68,
      "eval_steps_per_second": 0.289,
      "step": 10100
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.4532380700111389,
      "learning_rate": 1.5343128649904655e-05,
      "loss": 0.1463,
      "step": 10110
    },
    {
      "epoch": 1.0105,
      "grad_norm": 0.3699447214603424,
      "learning_rate": 1.5318968441321732e-05,
      "loss": 0.1427,
      "step": 10120
    },
    {
      "epoch": 1.011,
      "grad_norm": 0.4136722683906555,
      "learning_rate": 1.5294807404838313e-05,
      "loss": 0.1374,
      "step": 10130
    },
    {
      "epoch": 1.0115,
      "grad_norm": 0.38451066613197327,
      "learning_rate": 1.527064560316572e-05,
      "loss": 0.1435,
      "step": 10140
    },
    {
      "step": 10150,
      "wer/bud500": 0.06067471570146461
    },
    {
      "step": 10150,
      "wer/private": 0.4920814479638009
    },
    {
      "epoch": 1.012,
      "grad_norm": 0.4957388937473297,
      "learning_rate": 1.5246483099017263e-05,
      "loss": 0.148,
      "step": 10150
    },
    {
      "epoch": 1.0125,
      "grad_norm": 0.4672091603279114,
      "learning_rate": 1.5222319955108087e-05,
      "loss": 0.1268,
      "step": 10160
    },
    {
      "epoch": 1.013,
      "grad_norm": 0.47710442543029785,
      "learning_rate": 1.5198156234154981e-05,
      "loss": 0.1494,
      "step": 10170
    },
    {
      "epoch": 1.0135,
      "grad_norm": 0.4780887961387634,
      "learning_rate": 1.5173991998876244e-05,
      "loss": 0.1544,
      "step": 10180
    },
    {
      "epoch": 1.014,
      "grad_norm": 0.5007839202880859,
      "learning_rate": 1.51498273119915e-05,
      "loss": 0.1429,
      "step": 10190
    },
    {
      "step": 10200,
      "wer/bud500": 0.060426228549712045
    },
    {
      "step": 10200,
      "wer/private": 0.35180995475113125
    },
    {
      "epoch": 1.0145,
      "grad_norm": 0.3712376058101654,
      "learning_rate": 1.512566223622156e-05,
      "loss": 0.1383,
      "step": 10200
    },
    {
      "epoch": 1.0145,
      "eval_loss": 0.08319107443094254,
      "eval_runtime": 215.1705,
      "eval_samples_per_second": 34.856,
      "eval_steps_per_second": 0.274,
      "step": 10200
    },
    {
      "epoch": 1.015,
      "grad_norm": 0.4142884314060211,
      "learning_rate": 1.510149683428823e-05,
      "loss": 0.1454,
      "step": 10210
    },
    {
      "epoch": 1.0155,
      "grad_norm": 0.45927369594573975,
      "learning_rate": 1.5077331168914164e-05,
      "loss": 0.143,
      "step": 10220
    },
    {
      "epoch": 1.016,
      "grad_norm": 0.3943536877632141,
      "learning_rate": 1.5053165302822704e-05,
      "loss": 0.14,
      "step": 10230
    },
    {
      "epoch": 1.0165,
      "grad_norm": 0.37694206833839417,
      "learning_rate": 1.5028999298737723e-05,
      "loss": 0.1236,
      "step": 10240
    },
    {
      "step": 10250,
      "wer/bud500": 0.06022159207179817
    },
    {
      "step": 10250,
      "wer/private": 0.3416289592760181
    },
    {
      "epoch": 1.017,
      "grad_norm": 0.5165417194366455,
      "learning_rate": 1.500483321938343e-05,
      "loss": 0.1528,
      "step": 10250
    },
    {
      "epoch": 1.0175,
      "grad_norm": 0.4187304377555847,
      "learning_rate": 1.4980667127484244e-05,
      "loss": 0.1486,
      "step": 10260
    },
    {
      "epoch": 1.018,
      "grad_norm": 0.4074884057044983,
      "learning_rate": 1.4956501085764614e-05,
      "loss": 0.1446,
      "step": 10270
    },
    {
      "epoch": 1.0185,
      "grad_norm": 0.41244348883628845,
      "learning_rate": 1.4932335156948861e-05,
      "loss": 0.137,
      "step": 10280
    },
    {
      "epoch": 1.019,
      "grad_norm": 0.49316149950027466,
      "learning_rate": 1.4908169403761006e-05,
      "loss": 0.1399,
      "step": 10290
    },
    {
      "step": 10300,
      "wer/bud500": 0.06000233870260473
    },
    {
      "step": 10300,
      "wer/private": 0.3190045248868778
    },
    {
      "epoch": 1.0195,
      "grad_norm": 0.4114686846733093,
      "learning_rate": 1.4884003888924615e-05,
      "loss": 0.1304,
      "step": 10300
    },
    {
      "epoch": 1.0195,
      "eval_loss": 0.08282067626714706,
      "eval_runtime": 204.3265,
      "eval_samples_per_second": 36.706,
      "eval_steps_per_second": 0.289,
      "step": 10300
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.45870310068130493,
      "learning_rate": 1.4859838675162656e-05,
      "loss": 0.1466,
      "step": 10310
    },
    {
      "epoch": 1.0205,
      "grad_norm": 0.40959736704826355,
      "learning_rate": 1.4835673825197279e-05,
      "loss": 0.1483,
      "step": 10320
    },
    {
      "epoch": 1.021,
      "grad_norm": 0.4222567081451416,
      "learning_rate": 1.481150940174971e-05,
      "loss": 0.1424,
      "step": 10330
    },
    {
      "epoch": 1.0215,
      "grad_norm": 0.5004175305366516,
      "learning_rate": 1.4787345467540079e-05,
      "loss": 0.14,
      "step": 10340
    },
    {
      "step": 10350,
      "wer/bud500": 0.060294676528195985
    },
    {
      "step": 10350,
      "wer/private": 0.332579185520362
    },
    {
      "epoch": 1.022,
      "grad_norm": 0.40568065643310547,
      "learning_rate": 1.4763182085287226e-05,
      "loss": 0.1353,
      "step": 10350
    },
    {
      "epoch": 1.0225,
      "grad_norm": 0.4209349453449249,
      "learning_rate": 1.4739019317708571e-05,
      "loss": 0.1447,
      "step": 10360
    },
    {
      "epoch": 1.023,
      "grad_norm": 0.3562094271183014,
      "learning_rate": 1.4714857227519932e-05,
      "loss": 0.1363,
      "step": 10370
    },
    {
      "epoch": 1.0235,
      "grad_norm": 0.43461453914642334,
      "learning_rate": 1.4690695877435366e-05,
      "loss": 0.1311,
      "step": 10380
    },
    {
      "epoch": 1.024,
      "grad_norm": 0.447751522064209,
      "learning_rate": 1.466653533016702e-05,
      "loss": 0.1339,
      "step": 10390
    },
    {
      "step": 10400,
      "wer/bud500": 0.05990002046364779
    },
    {
      "step": 10400,
      "wer/private": 0.33597285067873306
    },
    {
      "epoch": 1.0245,
      "grad_norm": 0.45978015661239624,
      "learning_rate": 1.464237564842495e-05,
      "loss": 0.1355,
      "step": 10400
    },
    {
      "epoch": 1.0245,
      "eval_loss": 0.08320602029561996,
      "eval_runtime": 204.6433,
      "eval_samples_per_second": 36.649,
      "eval_steps_per_second": 0.288,
      "step": 10400
    },
    {
      "epoch": 1.025,
      "grad_norm": 0.42849212884902954,
      "learning_rate": 1.4618216894916967e-05,
      "loss": 0.1354,
      "step": 10410
    },
    {
      "epoch": 1.0255,
      "grad_norm": 0.48008251190185547,
      "learning_rate": 1.4594059132348469e-05,
      "loss": 0.1583,
      "step": 10420
    },
    {
      "epoch": 1.026,
      "grad_norm": 0.3792818784713745,
      "learning_rate": 1.4569902423422287e-05,
      "loss": 0.1408,
      "step": 10430
    },
    {
      "epoch": 1.0265,
      "grad_norm": 0.4724309742450714,
      "learning_rate": 1.454574683083851e-05,
      "loss": 0.1387,
      "step": 10440
    },
    {
      "step": 10450,
      "wer/bud500": 0.06033852720203467
    },
    {
      "step": 10450,
      "wer/private": 0.3190045248868778
    },
    {
      "epoch": 1.027,
      "grad_norm": 0.35912084579467773,
      "learning_rate": 1.4521592417294347e-05,
      "loss": 0.1334,
      "step": 10450
    },
    {
      "epoch": 1.0275,
      "grad_norm": 0.4302535951137543,
      "learning_rate": 1.4497439245483927e-05,
      "loss": 0.1361,
      "step": 10460
    },
    {
      "epoch": 1.028,
      "grad_norm": 0.4150812029838562,
      "learning_rate": 1.4473287378098169e-05,
      "loss": 0.1348,
      "step": 10470
    },
    {
      "epoch": 1.0285,
      "grad_norm": 0.4501473009586334,
      "learning_rate": 1.4449136877824593e-05,
      "loss": 0.1404,
      "step": 10480
    },
    {
      "epoch": 1.029,
      "grad_norm": 0.5536491274833679,
      "learning_rate": 1.4424987807347181e-05,
      "loss": 0.1493,
      "step": 10490
    },
    {
      "step": 10500,
      "wer/bud500": 0.060411611658432486
    },
    {
      "step": 10500,
      "wer/private": 0.3190045248868778
    },
    {
      "epoch": 1.0295,
      "grad_norm": 0.5397350192070007,
      "learning_rate": 1.4400840229346204e-05,
      "loss": 0.1458,
      "step": 10500
    },
    {
      "epoch": 1.0295,
      "eval_loss": 0.08325561136007309,
      "eval_runtime": 204.3443,
      "eval_samples_per_second": 36.703,
      "eval_steps_per_second": 0.289,
      "step": 10500
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.5593399405479431,
      "learning_rate": 1.4376694206498057e-05,
      "loss": 0.152,
      "step": 10510
    },
    {
      "epoch": 1.0305,
      "grad_norm": 0.38168683648109436,
      "learning_rate": 1.4352549801475098e-05,
      "loss": 0.1381,
      "step": 10520
    },
    {
      "epoch": 1.031,
      "grad_norm": 0.3951334059238434,
      "learning_rate": 1.4328407076945482e-05,
      "loss": 0.1467,
      "step": 10530
    },
    {
      "epoch": 1.0315,
      "grad_norm": 0.4111391305923462,
      "learning_rate": 1.4304266095573004e-05,
      "loss": 0.1325,
      "step": 10540
    },
    {
      "step": 10550,
      "wer/bud500": 0.060294676528195985
    },
    {
      "step": 10550,
      "wer/private": 0.3257918552036199
    },
    {
      "epoch": 1.032,
      "grad_norm": 0.32915976643562317,
      "learning_rate": 1.4280126920016948e-05,
      "loss": 0.1348,
      "step": 10550
    },
    {
      "epoch": 1.0325,
      "grad_norm": 0.4236656129360199,
      "learning_rate": 1.4255989612931892e-05,
      "loss": 0.1541,
      "step": 10560
    },
    {
      "epoch": 1.033,
      "grad_norm": 0.378288596868515,
      "learning_rate": 1.4231854236967571e-05,
      "loss": 0.1521,
      "step": 10570
    },
    {
      "epoch": 1.0335,
      "grad_norm": 0.44337064027786255,
      "learning_rate": 1.4207720854768715e-05,
      "loss": 0.1448,
      "step": 10580
    },
    {
      "epoch": 1.034,
      "grad_norm": 0.45059284567832947,
      "learning_rate": 1.4183589528974866e-05,
      "loss": 0.1454,
      "step": 10590
    },
    {
      "step": 10600,
      "wer/bud500": 0.060177741397959485
    },
    {
      "step": 10600,
      "wer/private": 0.3190045248868778
    },
    {
      "epoch": 1.0345,
      "grad_norm": 0.40970587730407715,
      "learning_rate": 1.4159460322220237e-05,
      "loss": 0.145,
      "step": 10600
    },
    {
      "epoch": 1.0345,
      "eval_loss": 0.08315227925777435,
      "eval_runtime": 212.4709,
      "eval_samples_per_second": 35.299,
      "eval_steps_per_second": 0.278,
      "step": 10600
    },
    {
      "epoch": 1.035,
      "grad_norm": 0.4538758099079132,
      "learning_rate": 1.4135333297133537e-05,
      "loss": 0.1406,
      "step": 10610
    },
    {
      "epoch": 1.0355,
      "grad_norm": 0.4099876284599304,
      "learning_rate": 1.4111208516337815e-05,
      "loss": 0.1367,
      "step": 10620
    },
    {
      "epoch": 1.036,
      "grad_norm": 0.41452836990356445,
      "learning_rate": 1.4087086042450306e-05,
      "loss": 0.1435,
      "step": 10630
    },
    {
      "epoch": 1.0365,
      "grad_norm": 0.4061163663864136,
      "learning_rate": 1.406296593808223e-05,
      "loss": 0.1376,
      "step": 10640
    },
    {
      "step": 10650,
      "wer/bud500": 0.06026544274563686
    },
    {
      "step": 10650,
      "wer/private": 0.31447963800904977
    },
    {
      "epoch": 1.037,
      "grad_norm": 0.41848430037498474,
      "learning_rate": 1.4038848265838671e-05,
      "loss": 0.1468,
      "step": 10650
    },
    {
      "epoch": 1.0375,
      "grad_norm": 0.4931454658508301,
      "learning_rate": 1.4014733088318415e-05,
      "loss": 0.1291,
      "step": 10660
    },
    {
      "epoch": 1.038,
      "grad_norm": 0.43156906962394714,
      "learning_rate": 1.399062046811375e-05,
      "loss": 0.1322,
      "step": 10670
    },
    {
      "epoch": 1.0385,
      "grad_norm": 0.4326753616333008,
      "learning_rate": 1.396651046781034e-05,
      "loss": 0.1406,
      "step": 10680
    },
    {
      "epoch": 1.039,
      "grad_norm": 0.414456844329834,
      "learning_rate": 1.3942403149987045e-05,
      "loss": 0.1427,
      "step": 10690
    },
    {
      "step": 10700,
      "wer/bud500": 0.060236208963077735
    },
    {
      "step": 10700,
      "wer/private": 0.32805429864253394
    },
    {
      "epoch": 1.0395,
      "grad_norm": 0.48257577419281006,
      "learning_rate": 1.3918298577215757e-05,
      "loss": 0.1531,
      "step": 10700
    },
    {
      "epoch": 1.0395,
      "eval_loss": 0.08304817229509354,
      "eval_runtime": 204.7853,
      "eval_samples_per_second": 36.624,
      "eval_steps_per_second": 0.288,
      "step": 10700
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.37705567479133606,
      "learning_rate": 1.3894196812061251e-05,
      "loss": 0.136,
      "step": 10710
    },
    {
      "epoch": 1.0405,
      "grad_norm": 0.3846965730190277,
      "learning_rate": 1.3870097917081011e-05,
      "loss": 0.1318,
      "step": 10720
    },
    {
      "epoch": 1.041,
      "grad_norm": 0.37713882327079773,
      "learning_rate": 1.3846001954825071e-05,
      "loss": 0.1396,
      "step": 10730
    },
    {
      "epoch": 1.0415,
      "grad_norm": 0.4886952340602875,
      "learning_rate": 1.3821908987835865e-05,
      "loss": 0.136,
      "step": 10740
    },
    {
      "step": 10750,
      "wer/bud500": 0.06315958721899026
    },
    {
      "step": 10750,
      "wer/private": 0.3178733031674208
    },
    {
      "epoch": 1.042,
      "grad_norm": 0.41813766956329346,
      "learning_rate": 1.3797819078648026e-05,
      "loss": 0.1328,
      "step": 10750
    },
    {
      "epoch": 1.0425,
      "grad_norm": 0.9106715321540833,
      "learning_rate": 1.377373228978827e-05,
      "loss": 0.142,
      "step": 10760
    },
    {
      "epoch": 1.043,
      "grad_norm": 0.4803566634654999,
      "learning_rate": 1.3749648683775217e-05,
      "loss": 0.1369,
      "step": 10770
    },
    {
      "epoch": 1.0435,
      "grad_norm": 0.4082932472229004,
      "learning_rate": 1.3725568323119214e-05,
      "loss": 0.1359,
      "step": 10780
    },
    {
      "epoch": 1.044,
      "grad_norm": 0.49387869238853455,
      "learning_rate": 1.3701491270322188e-05,
      "loss": 0.1491,
      "step": 10790
    },
    {
      "step": 10800,
      "wer/bud500": 0.060236208963077735
    },
    {
      "step": 10800,
      "wer/private": 0.332579185520362
    },
    {
      "epoch": 1.0445,
      "grad_norm": 0.5917909145355225,
      "learning_rate": 1.3677417587877488e-05,
      "loss": 0.1259,
      "step": 10800
    },
    {
      "epoch": 1.0445,
      "eval_loss": 0.08275698125362396,
      "eval_runtime": 206.3964,
      "eval_samples_per_second": 36.338,
      "eval_steps_per_second": 0.286,
      "step": 10800
    },
    {
      "epoch": 1.045,
      "grad_norm": 0.41731980443000793,
      "learning_rate": 1.36533473382697e-05,
      "loss": 0.1328,
      "step": 10810
    },
    {
      "epoch": 1.0455,
      "grad_norm": 0.42159467935562134,
      "learning_rate": 1.3629280583974513e-05,
      "loss": 0.1255,
      "step": 10820
    },
    {
      "epoch": 1.046,
      "grad_norm": 0.42784833908081055,
      "learning_rate": 1.3605217387458536e-05,
      "loss": 0.1418,
      "step": 10830
    },
    {
      "epoch": 1.0465,
      "grad_norm": 0.4625111222267151,
      "learning_rate": 1.3581157811179148e-05,
      "loss": 0.1415,
      "step": 10840
    },
    {
      "step": 10850,
      "wer/bud500": 0.05979770222469085
    },
    {
      "step": 10850,
      "wer/private": 0.332579185520362
    },
    {
      "epoch": 1.047,
      "grad_norm": 0.3472943603992462,
      "learning_rate": 1.3557101917584341e-05,
      "loss": 0.1315,
      "step": 10850
    },
    {
      "epoch": 1.0475,
      "grad_norm": 0.34140533208847046,
      "learning_rate": 1.3533049769112516e-05,
      "loss": 0.127,
      "step": 10860
    },
    {
      "epoch": 1.048,
      "grad_norm": 0.5232540965080261,
      "learning_rate": 1.3509001428192392e-05,
      "loss": 0.151,
      "step": 10870
    },
    {
      "epoch": 1.0485,
      "grad_norm": 0.35688820481300354,
      "learning_rate": 1.3484956957242784e-05,
      "loss": 0.1396,
      "step": 10880
    },
    {
      "epoch": 1.049,
      "grad_norm": 0.44301140308380127,
      "learning_rate": 1.3460916418672464e-05,
      "loss": 0.1414,
      "step": 10890
    },
    {
      "step": 10900,
      "wer/bud500": 0.059885403572368226
    },
    {
      "step": 10900,
      "wer/private": 0.33597285067873306
    },
    {
      "epoch": 1.0495,
      "grad_norm": 0.3611624240875244,
      "learning_rate": 1.3436879874880002e-05,
      "loss": 0.1576,
      "step": 10900
    },
    {
      "epoch": 1.0495,
      "eval_loss": 0.08296123147010803,
      "eval_runtime": 204.0873,
      "eval_samples_per_second": 36.749,
      "eval_steps_per_second": 0.289,
      "step": 10900
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.6013851165771484,
      "learning_rate": 1.34128473882536e-05,
      "loss": 0.1433,
      "step": 10910
    },
    {
      "epoch": 1.0505,
      "grad_norm": 0.4377356469631195,
      "learning_rate": 1.3388819021170918e-05,
      "loss": 0.1529,
      "step": 10920
    },
    {
      "epoch": 1.051,
      "grad_norm": 0.3638923764228821,
      "learning_rate": 1.3364794835998937e-05,
      "loss": 0.1538,
      "step": 10930
    },
    {
      "epoch": 1.0515,
      "grad_norm": 0.36034804582595825,
      "learning_rate": 1.3340774895093776e-05,
      "loss": 0.1438,
      "step": 10940
    },
    {
      "step": 10950,
      "wer/bud500": 0.060236208963077735
    },
    {
      "step": 10950,
      "wer/private": 0.33597285067873306
    },
    {
      "epoch": 1.052,
      "grad_norm": 0.4140593409538269,
      "learning_rate": 1.3316759260800545e-05,
      "loss": 0.1306,
      "step": 10950
    },
    {
      "epoch": 1.0525,
      "grad_norm": 0.4797365665435791,
      "learning_rate": 1.3292747995453178e-05,
      "loss": 0.1414,
      "step": 10960
    },
    {
      "epoch": 1.053,
      "grad_norm": 0.42531630396842957,
      "learning_rate": 1.3268741161374243e-05,
      "loss": 0.1346,
      "step": 10970
    },
    {
      "epoch": 1.0535,
      "grad_norm": 0.45694419741630554,
      "learning_rate": 1.324473882087484e-05,
      "loss": 0.1335,
      "step": 10980
    },
    {
      "epoch": 1.054,
      "grad_norm": 0.4332951009273529,
      "learning_rate": 1.3220741036254387e-05,
      "loss": 0.1434,
      "step": 10990
    },
    {
      "step": 11000,
      "wer/bud500": 0.05979770222469085
    },
    {
      "step": 11000,
      "wer/private": 0.3382352941176471
    },
    {
      "epoch": 1.0545,
      "grad_norm": 0.39910417795181274,
      "learning_rate": 1.3196747869800482e-05,
      "loss": 0.1363,
      "step": 11000
    },
    {
      "epoch": 1.0545,
      "eval_loss": 0.082784503698349,
      "eval_runtime": 204.851,
      "eval_samples_per_second": 36.612,
      "eval_steps_per_second": 0.288,
      "step": 11000
    },
    {
      "epoch": 0.0005,
      "grad_norm": 0.4504670798778534,
      "learning_rate": 1.3172759383788741e-05,
      "loss": 0.1361,
      "step": 11010
    },
    {
      "epoch": 0.001,
      "grad_norm": 0.3432881534099579,
      "learning_rate": 1.314877564048262e-05,
      "loss": 0.1368,
      "step": 11020
    },
    {
      "epoch": 0.0015,
      "grad_norm": 0.4488510191440582,
      "learning_rate": 1.3124796702133272e-05,
      "loss": 0.1326,
      "step": 11030
    },
    {
      "epoch": 0.002,
      "grad_norm": 0.41561251878738403,
      "learning_rate": 1.3100822630979378e-05,
      "loss": 0.1364,
      "step": 11040
    },
    {
      "step": 11050,
      "wer/bud500": 0.059812319115970417
    },
    {
      "step": 11050,
      "wer/private": 0.35407239819004527
    },
    {
      "epoch": 0.0025,
      "grad_norm": 0.45478758215904236,
      "learning_rate": 1.3076853489246984e-05,
      "loss": 0.15,
      "step": 11050
    },
    {
      "epoch": 0.003,
      "grad_norm": 0.41957905888557434,
      "learning_rate": 1.3052889339149351e-05,
      "loss": 0.1396,
      "step": 11060
    },
    {
      "epoch": 0.0035,
      "grad_norm": 0.4112098515033722,
      "learning_rate": 1.3028930242886778e-05,
      "loss": 0.1419,
      "step": 11070
    },
    {
      "epoch": 0.004,
      "grad_norm": 0.4971354305744171,
      "learning_rate": 1.3004976262646426e-05,
      "loss": 0.1291,
      "step": 11080
    },
    {
      "epoch": 0.0045,
      "grad_norm": 0.42412590980529785,
      "learning_rate": 1.2981027460602214e-05,
      "loss": 0.1312,
      "step": 11090
    },
    {
      "step": 11100,
      "wer/bud500": 0.060294676528195985
    },
    {
      "step": 11100,
      "wer/private": 0.31108597285067874
    },
    {
      "epoch": 0.005,
      "grad_norm": 0.6112428307533264,
      "learning_rate": 1.2957083898914595e-05,
      "loss": 0.1382,
      "step": 11100
    },
    {
      "epoch": 0.005,
      "eval_loss": 0.08270299434661865,
      "eval_runtime": 213.9157,
      "eval_samples_per_second": 35.061,
      "eval_steps_per_second": 0.276,
      "step": 11100
    },
    {
      "epoch": 0.0055,
      "grad_norm": 0.4005507826805115,
      "learning_rate": 1.293314563973043e-05,
      "loss": 0.1278,
      "step": 11110
    },
    {
      "epoch": 0.006,
      "grad_norm": 0.44047075510025024,
      "learning_rate": 1.2909212745182817e-05,
      "loss": 0.1317,
      "step": 11120
    },
    {
      "epoch": 0.0065,
      "grad_norm": 0.4151027798652649,
      "learning_rate": 1.2885285277390923e-05,
      "loss": 0.1554,
      "step": 11130
    },
    {
      "epoch": 0.007,
      "grad_norm": 0.47424036264419556,
      "learning_rate": 1.2861363298459834e-05,
      "loss": 0.1418,
      "step": 11140
    },
    {
      "step": 11150,
      "wer/bud500": 0.06010465694156167
    },
    {
      "step": 11150,
      "wer/private": 0.3269230769230769
    },
    {
      "epoch": 0.0075,
      "grad_norm": 0.4367401599884033,
      "learning_rate": 1.2837446870480389e-05,
      "loss": 0.136,
      "step": 11150
    },
    {
      "epoch": 0.008,
      "grad_norm": 0.37733274698257446,
      "learning_rate": 1.2813536055529026e-05,
      "loss": 0.1336,
      "step": 11160
    },
    {
      "epoch": 0.0085,
      "grad_norm": 0.4182380735874176,
      "learning_rate": 1.2789630915667604e-05,
      "loss": 0.1329,
      "step": 11170
    },
    {
      "epoch": 0.009,
      "grad_norm": 0.46110981702804565,
      "learning_rate": 1.276573151294326e-05,
      "loss": 0.1371,
      "step": 11180
    },
    {
      "epoch": 0.0095,
      "grad_norm": 0.45965859293937683,
      "learning_rate": 1.2741837909388228e-05,
      "loss": 0.1325,
      "step": 11190
    },
    {
      "step": 11200,
      "wer/bud500": 0.06032391031075511
    },
    {
      "step": 11200,
      "wer/private": 0.32918552036199095
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.40670523047447205,
      "learning_rate": 1.27179501670197e-05,
      "loss": 0.1435,
      "step": 11200
    },
    {
      "epoch": 0.01,
      "eval_loss": 0.0829487144947052,
      "eval_runtime": 214.2601,
      "eval_samples_per_second": 35.004,
      "eval_steps_per_second": 0.275,
      "step": 11200
    },
    {
      "epoch": 0.0105,
      "grad_norm": 0.41921883821487427,
      "learning_rate": 1.2694068347839657e-05,
      "loss": 0.1466,
      "step": 11210
    },
    {
      "epoch": 0.011,
      "grad_norm": 0.3792644143104553,
      "learning_rate": 1.2670192513834698e-05,
      "loss": 0.135,
      "step": 11220
    },
    {
      "epoch": 0.0115,
      "grad_norm": 0.5510780811309814,
      "learning_rate": 1.2646322726975895e-05,
      "loss": 0.1274,
      "step": 11230
    },
    {
      "epoch": 0.012,
      "grad_norm": 0.420757919549942,
      "learning_rate": 1.2622459049218614e-05,
      "loss": 0.1397,
      "step": 11240
    },
    {
      "step": 11250,
      "wer/bud500": 0.06033852720203467
    },
    {
      "step": 11250,
      "wer/private": 0.3257918552036199
    },
    {
      "epoch": 0.0125,
      "grad_norm": 0.4351549744606018,
      "learning_rate": 1.259860154250237e-05,
      "loss": 0.1348,
      "step": 11250
    },
    {
      "epoch": 0.013,
      "grad_norm": 0.4318230152130127,
      "learning_rate": 1.2574750268750664e-05,
      "loss": 0.1409,
      "step": 11260
    },
    {
      "epoch": 0.0135,
      "grad_norm": 0.3552094101905823,
      "learning_rate": 1.2550905289870821e-05,
      "loss": 0.1482,
      "step": 11270
    },
    {
      "epoch": 0.014,
      "grad_norm": 0.4920928478240967,
      "learning_rate": 1.2527066667753819e-05,
      "loss": 0.1324,
      "step": 11280
    },
    {
      "epoch": 0.0145,
      "grad_norm": 0.4561542570590973,
      "learning_rate": 1.2503234464274141e-05,
      "loss": 0.1422,
      "step": 11290
    },
    {
      "step": 11300,
      "wer/bud500": 0.05995848802876604
    },
    {
      "step": 11300,
      "wer/private": 0.3382352941176471
    },
    {
      "epoch": 0.015,
      "grad_norm": 0.4994414448738098,
      "learning_rate": 1.2479408741289606e-05,
      "loss": 0.1355,
      "step": 11300
    },
    {
      "epoch": 0.015,
      "eval_loss": 0.08302681893110275,
      "eval_runtime": 214.8,
      "eval_samples_per_second": 34.916,
      "eval_steps_per_second": 0.275,
      "step": 11300
    },
    {
      "epoch": 0.0155,
      "grad_norm": 0.8895420432090759,
      "learning_rate": 1.245558956064122e-05,
      "loss": 0.1431,
      "step": 11310
    },
    {
      "epoch": 0.016,
      "grad_norm": 0.44077545404434204,
      "learning_rate": 1.2431776984152998e-05,
      "loss": 0.1227,
      "step": 11320
    },
    {
      "epoch": 0.0165,
      "grad_norm": 0.4198078215122223,
      "learning_rate": 1.2407971073631826e-05,
      "loss": 0.1367,
      "step": 11330
    },
    {
      "epoch": 0.017,
      "grad_norm": 0.3834857940673828,
      "learning_rate": 1.2384171890867282e-05,
      "loss": 0.1277,
      "step": 11340
    },
    {
      "step": 11350,
      "wer/bud500": 0.05972461776829304
    },
    {
      "step": 11350,
      "wer/private": 0.32805429864253394
    },
    {
      "epoch": 0.0175,
      "grad_norm": 0.4298310875892639,
      "learning_rate": 1.2360379497631474e-05,
      "loss": 0.1485,
      "step": 11350
    },
    {
      "epoch": 0.018,
      "grad_norm": 0.48901423811912537,
      "learning_rate": 1.2336593955678901e-05,
      "loss": 0.1245,
      "step": 11360
    },
    {
      "epoch": 0.0185,
      "grad_norm": 0.5264348983764648,
      "learning_rate": 1.2312815326746266e-05,
      "loss": 0.1325,
      "step": 11370
    },
    {
      "epoch": 0.019,
      "grad_norm": 0.4027744233608246,
      "learning_rate": 1.2289043672552342e-05,
      "loss": 0.1354,
      "step": 11380
    },
    {
      "epoch": 0.0195,
      "grad_norm": 0.36496683955192566,
      "learning_rate": 1.226527905479779e-05,
      "loss": 0.1332,
      "step": 11390
    },
    {
      "step": 11400,
      "wer/bud500": 0.05979770222469085
    },
    {
      "step": 11400,
      "wer/private": 0.3246606334841629
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4181627333164215,
      "learning_rate": 1.2241521535165015e-05,
      "loss": 0.1463,
      "step": 11400
    },
    {
      "epoch": 0.02,
      "eval_loss": 0.08278760313987732,
      "eval_runtime": 213.3354,
      "eval_samples_per_second": 35.156,
      "eval_steps_per_second": 0.277,
      "step": 11400
    },
    {
      "epoch": 0.0205,
      "grad_norm": 0.566615104675293,
      "learning_rate": 1.2217771175317984e-05,
      "loss": 0.1271,
      "step": 11410
    },
    {
      "epoch": 0.021,
      "grad_norm": 0.39673173427581787,
      "learning_rate": 1.2194028036902097e-05,
      "loss": 0.1421,
      "step": 11420
    },
    {
      "epoch": 0.0215,
      "grad_norm": 0.6356768012046814,
      "learning_rate": 1.2170292181543996e-05,
      "loss": 0.1511,
      "step": 11430
    },
    {
      "epoch": 0.022,
      "grad_norm": 0.47167322039604187,
      "learning_rate": 1.2146563670851433e-05,
      "loss": 0.1336,
      "step": 11440
    },
    {
      "step": 11450,
      "wer/bud500": 0.06296956763235595
    },
    {
      "step": 11450,
      "wer/private": 0.32805429864253394
    },
    {
      "epoch": 0.0225,
      "grad_norm": 0.3407813012599945,
      "learning_rate": 1.2122842566413088e-05,
      "loss": 0.123,
      "step": 11450
    },
    {
      "epoch": 0.023,
      "grad_norm": 0.37189626693725586,
      "learning_rate": 1.2099128929798418e-05,
      "loss": 0.1377,
      "step": 11460
    },
    {
      "epoch": 0.0235,
      "grad_norm": 0.40303248167037964,
      "learning_rate": 1.2075422822557495e-05,
      "loss": 0.1442,
      "step": 11470
    },
    {
      "epoch": 0.024,
      "grad_norm": 0.453769326210022,
      "learning_rate": 1.205172430622086e-05,
      "loss": 0.1457,
      "step": 11480
    },
    {
      "epoch": 0.0245,
      "grad_norm": 0.3845580518245697,
      "learning_rate": 1.2028033442299335e-05,
      "loss": 0.1424,
      "step": 11490
    },
    {
      "step": 11500,
      "wer/bud500": 0.05978308533341129
    },
    {
      "step": 11500,
      "wer/private": 0.3427601809954751
    },
    {
      "epoch": 0.025,
      "grad_norm": 0.36971524357795715,
      "learning_rate": 1.2004350292283897e-05,
      "loss": 0.1389,
      "step": 11500
    },
    {
      "epoch": 0.025,
      "eval_loss": 0.0827108696103096,
      "eval_runtime": 212.9811,
      "eval_samples_per_second": 35.214,
      "eval_steps_per_second": 0.277,
      "step": 11500
    },
    {
      "epoch": 0.0255,
      "grad_norm": 0.368145614862442,
      "learning_rate": 1.1980674917645482e-05,
      "loss": 0.1305,
      "step": 11510
    },
    {
      "epoch": 0.026,
      "grad_norm": 0.3754902184009552,
      "learning_rate": 1.195700737983486e-05,
      "loss": 0.1348,
      "step": 11520
    },
    {
      "epoch": 0.0265,
      "grad_norm": 0.5116007924079895,
      "learning_rate": 1.1933347740282449e-05,
      "loss": 0.1447,
      "step": 11530
    },
    {
      "epoch": 0.027,
      "grad_norm": 0.4369296133518219,
      "learning_rate": 1.1909696060398177e-05,
      "loss": 0.1436,
      "step": 11540
    },
    {
      "step": 11550,
      "wer/bud500": 0.05984155289852954
    },
    {
      "step": 11550,
      "wer/private": 0.3382352941176471
    },
    {
      "epoch": 0.0275,
      "grad_norm": 0.4562186598777771,
      "learning_rate": 1.1886052401571302e-05,
      "loss": 0.1468,
      "step": 11550
    },
    {
      "epoch": 0.028,
      "grad_norm": 0.5014549493789673,
      "learning_rate": 1.1862416825170282e-05,
      "loss": 0.1285,
      "step": 11560
    },
    {
      "epoch": 0.0285,
      "grad_norm": 0.43237483501434326,
      "learning_rate": 1.1838789392542567e-05,
      "loss": 0.1331,
      "step": 11570
    },
    {
      "epoch": 0.029,
      "grad_norm": 0.4774021804332733,
      "learning_rate": 1.1815170165014486e-05,
      "loss": 0.1416,
      "step": 11580
    },
    {
      "epoch": 0.0295,
      "grad_norm": 0.5297204852104187,
      "learning_rate": 1.1791559203891078e-05,
      "loss": 0.1412,
      "step": 11590
    },
    {
      "step": 11600,
      "wer/bud500": 0.059651533311895225
    },
    {
      "step": 11600,
      "wer/private": 0.3235294117647059
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.3895637094974518,
      "learning_rate": 1.1767956570455915e-05,
      "loss": 0.1311,
      "step": 11600
    },
    {
      "epoch": 0.03,
      "eval_loss": 0.08253207057714462,
      "eval_runtime": 212.9958,
      "eval_samples_per_second": 35.212,
      "eval_steps_per_second": 0.277,
      "step": 11600
    },
    {
      "epoch": 0.0305,
      "grad_norm": 0.4854496419429779,
      "learning_rate": 1.1744362325970962e-05,
      "loss": 0.1554,
      "step": 11610
    },
    {
      "epoch": 0.031,
      "grad_norm": 0.41550183296203613,
      "learning_rate": 1.1720776531676398e-05,
      "loss": 0.1218,
      "step": 11620
    },
    {
      "epoch": 0.0315,
      "grad_norm": 0.4394586384296417,
      "learning_rate": 1.1697199248790478e-05,
      "loss": 0.1361,
      "step": 11630
    },
    {
      "epoch": 0.032,
      "grad_norm": 0.416349858045578,
      "learning_rate": 1.1673630538509367e-05,
      "loss": 0.1205,
      "step": 11640
    },
    {
      "step": 11650,
      "wer/bud500": 0.05949074750782004
    },
    {
      "step": 11650,
      "wer/private": 0.33144796380090497
    },
    {
      "epoch": 0.0325,
      "grad_norm": 0.691472053527832,
      "learning_rate": 1.1650070462006974e-05,
      "loss": 0.1492,
      "step": 11650
    },
    {
      "epoch": 0.033,
      "grad_norm": 0.42333418130874634,
      "learning_rate": 1.1626519080434796e-05,
      "loss": 0.1398,
      "step": 11660
    },
    {
      "epoch": 0.0335,
      "grad_norm": 0.39883658289909363,
      "learning_rate": 1.160297645492178e-05,
      "loss": 0.1487,
      "step": 11670
    },
    {
      "epoch": 0.034,
      "grad_norm": 0.3700932264328003,
      "learning_rate": 1.1579442646574121e-05,
      "loss": 0.1334,
      "step": 11680
    },
    {
      "epoch": 0.0345,
      "grad_norm": 0.8461557626724243,
      "learning_rate": 1.1555917716475136e-05,
      "loss": 0.1522,
      "step": 11690
    },
    {
      "step": 11700,
      "wer/bud500": 0.06003157248516386
    },
    {
      "step": 11700,
      "wer/private": 0.333710407239819
    },
    {
      "epoch": 0.035,
      "grad_norm": 0.4730803370475769,
      "learning_rate": 1.1532401725685111e-05,
      "loss": 0.1453,
      "step": 11700
    },
    {
      "epoch": 0.035,
      "eval_loss": 0.08240605145692825,
      "eval_runtime": 214.1078,
      "eval_samples_per_second": 35.029,
      "eval_steps_per_second": 0.276,
      "step": 11700
    },
    {
      "epoch": 0.0355,
      "grad_norm": 0.29740771651268005,
      "learning_rate": 1.150889473524112e-05,
      "loss": 0.1482,
      "step": 11710
    },
    {
      "epoch": 0.036,
      "grad_norm": 0.5662429928779602,
      "learning_rate": 1.1485396806156876e-05,
      "loss": 0.1321,
      "step": 11720
    },
    {
      "epoch": 0.0365,
      "grad_norm": 0.4149295389652252,
      "learning_rate": 1.1461907999422572e-05,
      "loss": 0.1475,
      "step": 11730
    },
    {
      "epoch": 0.037,
      "grad_norm": 0.39302492141723633,
      "learning_rate": 1.1438428376004724e-05,
      "loss": 0.1383,
      "step": 11740
    },
    {
      "step": 11750,
      "wer/bud500": 0.0599731049200456
    },
    {
      "step": 11750,
      "wer/private": 0.332579185520362
    },
    {
      "epoch": 0.0375,
      "grad_norm": 0.47112077474594116,
      "learning_rate": 1.1414957996846012e-05,
      "loss": 0.1348,
      "step": 11750
    },
    {
      "epoch": 0.038,
      "grad_norm": 0.40883082151412964,
      "learning_rate": 1.1391496922865124e-05,
      "loss": 0.1323,
      "step": 11760
    },
    {
      "epoch": 0.0385,
      "grad_norm": 0.48745203018188477,
      "learning_rate": 1.1368045214956596e-05,
      "loss": 0.1362,
      "step": 11770
    },
    {
      "epoch": 0.039,
      "grad_norm": 0.5110334157943726,
      "learning_rate": 1.1344602933990661e-05,
      "loss": 0.1352,
      "step": 11780
    },
    {
      "epoch": 0.0395,
      "grad_norm": 0.4751003682613373,
      "learning_rate": 1.1321170140813058e-05,
      "loss": 0.1459,
      "step": 11790
    },
    {
      "step": 11800,
      "wer/bud500": 0.060250825854357294
    },
    {
      "step": 11800,
      "wer/private": 0.3212669683257919
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.44251489639282227,
      "learning_rate": 1.1297746896244929e-05,
      "loss": 0.1277,
      "step": 11800
    },
    {
      "epoch": 0.04,
      "eval_loss": 0.08238870650529861,
      "eval_runtime": 213.735,
      "eval_samples_per_second": 35.09,
      "eval_steps_per_second": 0.276,
      "step": 11800
    },
    {
      "epoch": 0.0405,
      "grad_norm": 0.3703407347202301,
      "learning_rate": 1.1274333261082617e-05,
      "loss": 0.1317,
      "step": 11810
    },
    {
      "epoch": 0.041,
      "grad_norm": 0.4663970470428467,
      "learning_rate": 1.1250929296097531e-05,
      "loss": 0.1349,
      "step": 11820
    },
    {
      "epoch": 0.0415,
      "grad_norm": 0.35401782393455505,
      "learning_rate": 1.1227535062035974e-05,
      "loss": 0.1417,
      "step": 11830
    },
    {
      "epoch": 0.042,
      "grad_norm": 0.4657403528690338,
      "learning_rate": 1.1204150619618989e-05,
      "loss": 0.133,
      "step": 11840
    },
    {
      "step": 11850,
      "wer/bud500": 0.05992925424620692
    },
    {
      "step": 11850,
      "wer/private": 0.3257918552036199
    },
    {
      "epoch": 0.0425,
      "grad_norm": 0.3480289578437805,
      "learning_rate": 1.1180776029542215e-05,
      "loss": 0.1348,
      "step": 11850
    },
    {
      "epoch": 0.043,
      "grad_norm": 0.45853447914123535,
      "learning_rate": 1.1157411352475713e-05,
      "loss": 0.163,
      "step": 11860
    },
    {
      "epoch": 0.0435,
      "grad_norm": 0.3526533544063568,
      "learning_rate": 1.1134056649063807e-05,
      "loss": 0.1451,
      "step": 11870
    },
    {
      "epoch": 0.044,
      "grad_norm": 0.41451555490493774,
      "learning_rate": 1.1110711979924953e-05,
      "loss": 0.1496,
      "step": 11880
    },
    {
      "epoch": 0.0445,
      "grad_norm": 0.39308401942253113,
      "learning_rate": 1.108737740565155e-05,
      "loss": 0.1371,
      "step": 11890
    },
    {
      "step": 11900,
      "wer/bud500": 0.0593884292688631
    },
    {
      "step": 11900,
      "wer/private": 0.3201357466063348
    },
    {
      "epoch": 0.045,
      "grad_norm": 0.4519500434398651,
      "learning_rate": 1.106405298680978e-05,
      "loss": 0.1332,
      "step": 11900
    },
    {
      "epoch": 0.045,
      "eval_loss": 0.08233186602592468,
      "eval_runtime": 213.1838,
      "eval_samples_per_second": 35.181,
      "eval_steps_per_second": 0.277,
      "step": 11900
    },
    {
      "epoch": 0.0455,
      "grad_norm": 0.4838436543941498,
      "learning_rate": 1.1040738783939497e-05,
      "loss": 0.1389,
      "step": 11910
    },
    {
      "epoch": 0.046,
      "grad_norm": 0.5041335225105286,
      "learning_rate": 1.1017434857554018e-05,
      "loss": 0.136,
      "step": 11920
    },
    {
      "epoch": 0.0465,
      "grad_norm": 0.4014868140220642,
      "learning_rate": 1.0994141268139995e-05,
      "loss": 0.1376,
      "step": 11930
    },
    {
      "epoch": 0.047,
      "grad_norm": 0.372214138507843,
      "learning_rate": 1.097085807615725e-05,
      "loss": 0.1372,
      "step": 11940
    },
    {
      "step": 11950,
      "wer/bud500": 0.059534598181658724
    },
    {
      "step": 11950,
      "wer/private": 0.33144796380090497
    },
    {
      "epoch": 0.0475,
      "grad_norm": 0.44478559494018555,
      "learning_rate": 1.0947585342038605e-05,
      "loss": 0.1387,
      "step": 11950
    },
    {
      "epoch": 0.048,
      "grad_norm": 0.42092499136924744,
      "learning_rate": 1.0924323126189755e-05,
      "loss": 0.1507,
      "step": 11960
    },
    {
      "epoch": 0.0485,
      "grad_norm": 0.41154050827026367,
      "learning_rate": 1.0901071488989085e-05,
      "loss": 0.139,
      "step": 11970
    },
    {
      "epoch": 0.049,
      "grad_norm": 0.3667317032814026,
      "learning_rate": 1.0877830490787525e-05,
      "loss": 0.1329,
      "step": 11980
    },
    {
      "epoch": 0.0495,
      "grad_norm": 0.505347490310669,
      "learning_rate": 1.0854600191908404e-05,
      "loss": 0.1263,
      "step": 11990
    },
    {
      "step": 12000,
      "wer/bud500": 0.059286111029906156
    },
    {
      "step": 12000,
      "wer/private": 0.33144796380090497
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.461149662733078,
      "learning_rate": 1.0831380652647246e-05,
      "loss": 0.1404,
      "step": 12000
    },
    {
      "epoch": 0.05,
      "eval_loss": 0.08222043514251709,
      "eval_runtime": 213.1419,
      "eval_samples_per_second": 35.188,
      "eval_steps_per_second": 0.277,
      "step": 12000
    },
    {
      "epoch": 0.0505,
      "grad_norm": 0.38377419114112854,
      "learning_rate": 1.0808171933271676e-05,
      "loss": 0.1355,
      "step": 12010
    },
    {
      "epoch": 0.051,
      "grad_norm": 0.42886659502983093,
      "learning_rate": 1.0784974094021236e-05,
      "loss": 0.1473,
      "step": 12020
    },
    {
      "epoch": 0.0515,
      "grad_norm": 0.40223246812820435,
      "learning_rate": 1.0761787195107213e-05,
      "loss": 0.136,
      "step": 12030
    },
    {
      "epoch": 0.052,
      "grad_norm": 0.4381050765514374,
      "learning_rate": 1.073861129671251e-05,
      "loss": 0.1316,
      "step": 12040
    },
    {
      "step": 12050,
      "wer/bud500": 0.06270646358932382
    },
    {
      "step": 12050,
      "wer/private": 0.3506787330316742
    },
    {
      "epoch": 0.0525,
      "grad_norm": 0.347646564245224,
      "learning_rate": 1.0715446458991469e-05,
      "loss": 0.1527,
      "step": 12050
    },
    {
      "epoch": 0.053,
      "grad_norm": 0.422240287065506,
      "learning_rate": 1.0692292742069726e-05,
      "loss": 0.1366,
      "step": 12060
    },
    {
      "epoch": 0.0535,
      "grad_norm": 0.4734385311603546,
      "learning_rate": 1.0669150206044059e-05,
      "loss": 0.132,
      "step": 12070
    },
    {
      "epoch": 0.054,
      "grad_norm": 0.4273913502693176,
      "learning_rate": 1.064601891098221e-05,
      "loss": 0.1406,
      "step": 12080
    },
    {
      "epoch": 0.0545,
      "grad_norm": 0.5121455192565918,
      "learning_rate": 1.0622898916922765e-05,
      "loss": 0.1366,
      "step": 12090
    },
    {
      "step": 12100,
      "wer/bud500": 0.06308650276259245
    },
    {
      "step": 12100,
      "wer/private": 0.333710407239819
    },
    {
      "epoch": 0.055,
      "grad_norm": 0.38595980405807495,
      "learning_rate": 1.059979028387497e-05,
      "loss": 0.1281,
      "step": 12100
    },
    {
      "epoch": 0.055,
      "eval_loss": 0.0822264775633812,
      "eval_runtime": 214.2176,
      "eval_samples_per_second": 35.011,
      "eval_steps_per_second": 0.275,
      "step": 12100
    },
    {
      "epoch": 0.0555,
      "grad_norm": 0.4350171685218811,
      "learning_rate": 1.0576693071818559e-05,
      "loss": 0.1279,
      "step": 12110
    },
    {
      "epoch": 0.056,
      "grad_norm": 0.42693468928337097,
      "learning_rate": 1.0553607340703659e-05,
      "loss": 0.1353,
      "step": 12120
    },
    {
      "epoch": 0.0565,
      "grad_norm": 0.4239999055862427,
      "learning_rate": 1.053053315045058e-05,
      "loss": 0.1561,
      "step": 12130
    },
    {
      "epoch": 0.057,
      "grad_norm": 0.39252084493637085,
      "learning_rate": 1.0507470560949677e-05,
      "loss": 0.147,
      "step": 12140
    },
    {
      "step": 12150,
      "wer/bud500": 0.06283801561083989
    },
    {
      "step": 12150,
      "wer/private": 0.3416289592760181
    },
    {
      "epoch": 0.0575,
      "grad_norm": 0.43302980065345764,
      "learning_rate": 1.0484419632061194e-05,
      "loss": 0.1285,
      "step": 12150
    },
    {
      "epoch": 0.058,
      "grad_norm": 0.4262722432613373,
      "learning_rate": 1.0461380423615117e-05,
      "loss": 0.1394,
      "step": 12160
    },
    {
      "epoch": 0.0585,
      "grad_norm": 0.3832840025424957,
      "learning_rate": 1.0438352995410999e-05,
      "loss": 0.1414,
      "step": 12170
    },
    {
      "epoch": 0.059,
      "grad_norm": 0.5203368663787842,
      "learning_rate": 1.0415337407217821e-05,
      "loss": 0.1467,
      "step": 12180
    },
    {
      "epoch": 0.0595,
      "grad_norm": 0.5046555995941162,
      "learning_rate": 1.039233371877384e-05,
      "loss": 0.1438,
      "step": 12190
    },
    {
      "step": 12200,
      "wer/bud500": 0.05966615020317479
    },
    {
      "step": 12200,
      "wer/private": 0.3393665158371041
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4250056743621826,
      "learning_rate": 1.036934198978642e-05,
      "loss": 0.1376,
      "step": 12200
    },
    {
      "epoch": 0.06,
      "eval_loss": 0.08231618255376816,
      "eval_runtime": 213.6389,
      "eval_samples_per_second": 35.106,
      "eval_steps_per_second": 0.276,
      "step": 12200
    },
    {
      "epoch": 0.0605,
      "grad_norm": 0.3825341463088989,
      "learning_rate": 1.0346362279931891e-05,
      "loss": 0.141,
      "step": 12210
    },
    {
      "epoch": 0.061,
      "grad_norm": 0.4083750247955322,
      "learning_rate": 1.0323394648855365e-05,
      "loss": 0.1379,
      "step": 12220
    },
    {
      "epoch": 0.0615,
      "grad_norm": 0.44287753105163574,
      "learning_rate": 1.0300439156170626e-05,
      "loss": 0.137,
      "step": 12230
    },
    {
      "epoch": 0.062,
      "grad_norm": 0.4886976480484009,
      "learning_rate": 1.027749586145995e-05,
      "loss": 0.1336,
      "step": 12240
    },
    {
      "step": 12250,
      "wer/bud500": 0.06277954804572164
    },
    {
      "step": 12250,
      "wer/private": 0.32805429864253394
    },
    {
      "epoch": 0.0625,
      "grad_norm": 0.4636501967906952,
      "learning_rate": 1.025456482427394e-05,
      "loss": 0.1394,
      "step": 12250
    },
    {
      "epoch": 0.063,
      "grad_norm": 0.36656489968299866,
      "learning_rate": 1.0231646104131391e-05,
      "loss": 0.1314,
      "step": 12260
    },
    {
      "epoch": 0.0635,
      "grad_norm": 0.4086345136165619,
      "learning_rate": 1.0208739760519134e-05,
      "loss": 0.1447,
      "step": 12270
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.46313241124153137,
      "learning_rate": 1.018584585289186e-05,
      "loss": 0.1488,
      "step": 12280
    },
    {
      "epoch": 0.0645,
      "grad_norm": 0.4953530430793762,
      "learning_rate": 1.0162964440671998e-05,
      "loss": 0.1448,
      "step": 12290
    },
    {
      "step": 12300,
      "wer/bud500": 0.06264799602420557
    },
    {
      "step": 12300,
      "wer/private": 0.3382352941176471
    },
    {
      "epoch": 0.065,
      "grad_norm": 0.4947826564311981,
      "learning_rate": 1.0140095583249535e-05,
      "loss": 0.1387,
      "step": 12300
    },
    {
      "epoch": 0.065,
      "eval_loss": 0.08234952390193939,
      "eval_runtime": 212.6615,
      "eval_samples_per_second": 35.267,
      "eval_steps_per_second": 0.277,
      "step": 12300
    },
    {
      "epoch": 0.0655,
      "grad_norm": 0.41459405422210693,
      "learning_rate": 1.011723933998188e-05,
      "loss": 0.1413,
      "step": 12310
    },
    {
      "epoch": 0.066,
      "grad_norm": 0.5400380492210388,
      "learning_rate": 1.0094395770193699e-05,
      "loss": 0.1426,
      "step": 12320
    },
    {
      "epoch": 0.0665,
      "grad_norm": 0.4338702857494354,
      "learning_rate": 1.0071564933176744e-05,
      "loss": 0.1339,
      "step": 12330
    },
    {
      "epoch": 0.067,
      "grad_norm": 0.40191495418548584,
      "learning_rate": 1.0048746888189748e-05,
      "loss": 0.1434,
      "step": 12340
    },
    {
      "step": 12350,
      "wer/bud500": 0.06283801561083989
    },
    {
      "step": 12350,
      "wer/private": 0.32805429864253394
    },
    {
      "epoch": 0.0675,
      "grad_norm": 0.4546469449996948,
      "learning_rate": 1.0025941694458224e-05,
      "loss": 0.1423,
      "step": 12350
    },
    {
      "epoch": 0.068,
      "grad_norm": 0.5367525219917297,
      "learning_rate": 1.0003149411174334e-05,
      "loss": 0.1441,
      "step": 12360
    },
    {
      "epoch": 0.0685,
      "grad_norm": 0.47687795758247375,
      "learning_rate": 9.980370097496726e-06,
      "loss": 0.15,
      "step": 12370
    },
    {
      "epoch": 0.069,
      "grad_norm": 0.4111132323741913,
      "learning_rate": 9.957603812550396e-06,
      "loss": 0.1316,
      "step": 12380
    },
    {
      "epoch": 0.0695,
      "grad_norm": 0.5192073583602905,
      "learning_rate": 9.934850615426504e-06,
      "loss": 0.1396,
      "step": 12390
    },
    {
      "step": 12400,
      "wer/bud500": 0.06317420411026983
    },
    {
      "step": 12400,
      "wer/private": 0.3427601809954751
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4150504469871521,
      "learning_rate": 9.912110565182251e-06,
      "loss": 0.1416,
      "step": 12400
    },
    {
      "epoch": 0.07,
      "eval_loss": 0.08261572569608688,
      "eval_runtime": 214.5528,
      "eval_samples_per_second": 34.956,
      "eval_steps_per_second": 0.275,
      "step": 12400
    },
    {
      "epoch": 0.0705,
      "grad_norm": 0.4415535628795624,
      "learning_rate": 9.889383720840726e-06,
      "loss": 0.1398,
      "step": 12410
    },
    {
      "epoch": 0.071,
      "grad_norm": 0.5291740894317627,
      "learning_rate": 9.866670141390718e-06,
      "loss": 0.1535,
      "step": 12420
    },
    {
      "epoch": 0.0715,
      "grad_norm": 0.5112824440002441,
      "learning_rate": 9.843969885786608e-06,
      "loss": 0.1526,
      "step": 12430
    },
    {
      "epoch": 0.072,
      "grad_norm": 0.5598418116569519,
      "learning_rate": 9.821283012948178e-06,
      "loss": 0.1403,
      "step": 12440
    },
    {
      "step": 12450,
      "wer/bud500": 0.06296956763235595
    },
    {
      "step": 12450,
      "wer/private": 0.3269230769230769
    },
    {
      "epoch": 0.0725,
      "grad_norm": 0.5630600452423096,
      "learning_rate": 9.79860958176048e-06,
      "loss": 0.1398,
      "step": 12450
    },
    {
      "epoch": 0.073,
      "grad_norm": 0.4811550974845886,
      "learning_rate": 9.775949651073675e-06,
      "loss": 0.1405,
      "step": 12460
    },
    {
      "epoch": 0.0735,
      "grad_norm": 0.38359153270721436,
      "learning_rate": 9.753303279702893e-06,
      "loss": 0.138,
      "step": 12470
    },
    {
      "epoch": 0.074,
      "grad_norm": 0.3980245292186737,
      "learning_rate": 9.73067052642806e-06,
      "loss": 0.1341,
      "step": 12480
    },
    {
      "epoch": 0.0745,
      "grad_norm": 0.44925710558891296,
      "learning_rate": 9.708051449993755e-06,
      "loss": 0.1438,
      "step": 12490
    },
    {
      "step": 12500,
      "wer/bud500": 0.06260414535036689
    },
    {
      "step": 12500,
      "wer/private": 0.34502262443438914
    },
    {
      "epoch": 0.075,
      "grad_norm": 0.5082043409347534,
      "learning_rate": 9.685446109109063e-06,
      "loss": 0.1446,
      "step": 12500
    },
    {
      "epoch": 0.075,
      "eval_loss": 0.08229643851518631,
      "eval_runtime": 213.9769,
      "eval_samples_per_second": 35.051,
      "eval_steps_per_second": 0.276,
      "step": 12500
    },
    {
      "epoch": 0.0755,
      "grad_norm": 0.33301791548728943,
      "learning_rate": 9.66285456244741e-06,
      "loss": 0.1479,
      "step": 12510
    },
    {
      "epoch": 0.076,
      "grad_norm": 0.40080422163009644,
      "learning_rate": 9.640276868646434e-06,
      "loss": 0.1364,
      "step": 12520
    },
    {
      "epoch": 0.0765,
      "grad_norm": 0.3902129828929901,
      "learning_rate": 9.617713086307802e-06,
      "loss": 0.1361,
      "step": 12530
    },
    {
      "epoch": 0.077,
      "grad_norm": 0.5062968134880066,
      "learning_rate": 9.595163273997082e-06,
      "loss": 0.1344,
      "step": 12540
    },
    {
      "step": 12550,
      "wer/bud500": 0.06250182711140995
    },
    {
      "step": 12550,
      "wer/private": 0.35180995475113125
    },
    {
      "epoch": 0.0775,
      "grad_norm": 0.4281059205532074,
      "learning_rate": 9.57262749024357e-06,
      "loss": 0.1391,
      "step": 12550
    },
    {
      "epoch": 0.078,
      "grad_norm": 0.4632883071899414,
      "learning_rate": 9.550105793540164e-06,
      "loss": 0.1263,
      "step": 12560
    },
    {
      "epoch": 0.0785,
      "grad_norm": 0.5024181008338928,
      "learning_rate": 9.52759824234319e-06,
      "loss": 0.1403,
      "step": 12570
    },
    {
      "epoch": 0.079,
      "grad_norm": 0.45227572321891785,
      "learning_rate": 9.505104895072262e-06,
      "loss": 0.1518,
      "step": 12580
    },
    {
      "epoch": 0.0795,
      "grad_norm": 0.5081732869148254,
      "learning_rate": 9.482625810110129e-06,
      "loss": 0.1403,
      "step": 12590
    },
    {
      "step": 12600,
      "wer/bud500": 0.05968076709445435
    },
    {
      "step": 12600,
      "wer/private": 0.3438914027149321
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3894353210926056,
      "learning_rate": 9.460161045802512e-06,
      "loss": 0.1458,
      "step": 12600
    },
    {
      "epoch": 0.08,
      "eval_loss": 0.08247000724077225,
      "eval_runtime": 213.8375,
      "eval_samples_per_second": 35.073,
      "eval_steps_per_second": 0.276,
      "step": 12600
    },
    {
      "epoch": 0.0805,
      "grad_norm": 0.4745055139064789,
      "learning_rate": 9.43771066045797e-06,
      "loss": 0.1472,
      "step": 12610
    },
    {
      "epoch": 0.081,
      "grad_norm": 0.3834135830402374,
      "learning_rate": 9.41527471234774e-06,
      "loss": 0.1346,
      "step": 12620
    },
    {
      "epoch": 0.0815,
      "grad_norm": 0.3599455654621124,
      "learning_rate": 9.392853259705586e-06,
      "loss": 0.1296,
      "step": 12630
    },
    {
      "epoch": 0.082,
      "grad_norm": 0.5924979448318481,
      "learning_rate": 9.370446360727648e-06,
      "loss": 0.1441,
      "step": 12640
    },
    {
      "step": 12650,
      "wer/bud500": 0.05935919548630397
    },
    {
      "step": 12650,
      "wer/private": 0.3438914027149321
    },
    {
      "epoch": 0.0825,
      "grad_norm": 0.399453341960907,
      "learning_rate": 9.34805407357229e-06,
      "loss": 0.1491,
      "step": 12650
    },
    {
      "epoch": 0.083,
      "grad_norm": 0.4955017566680908,
      "learning_rate": 9.325676456359948e-06,
      "loss": 0.142,
      "step": 12660
    },
    {
      "epoch": 0.0835,
      "grad_norm": 0.593774139881134,
      "learning_rate": 9.303313567172985e-06,
      "loss": 0.1415,
      "step": 12670
    },
    {
      "epoch": 0.084,
      "grad_norm": 0.44586095213890076,
      "learning_rate": 9.280965464055536e-06,
      "loss": 0.1335,
      "step": 12680
    },
    {
      "epoch": 0.0845,
      "grad_norm": 0.3905821442604065,
      "learning_rate": 9.258632205013356e-06,
      "loss": 0.1426,
      "step": 12690
    },
    {
      "step": 12700,
      "wer/bud500": 0.062633379132926
    },
    {
      "step": 12700,
      "wer/private": 0.332579185520362
    },
    {
      "epoch": 0.085,
      "grad_norm": 0.4820587933063507,
      "learning_rate": 9.236313848013683e-06,
      "loss": 0.1388,
      "step": 12700
    },
    {
      "epoch": 0.085,
      "eval_loss": 0.0823795348405838,
      "eval_runtime": 214.9166,
      "eval_samples_per_second": 34.897,
      "eval_steps_per_second": 0.275,
      "step": 12700
    },
    {
      "epoch": 0.0855,
      "grad_norm": 0.3757873773574829,
      "learning_rate": 9.214010450985052e-06,
      "loss": 0.1295,
      "step": 12710
    },
    {
      "epoch": 0.086,
      "grad_norm": 0.4270474314689636,
      "learning_rate": 9.191722071817183e-06,
      "loss": 0.1348,
      "step": 12720
    },
    {
      "epoch": 0.0865,
      "grad_norm": 0.37339240312576294,
      "learning_rate": 9.169448768360826e-06,
      "loss": 0.1383,
      "step": 12730
    },
    {
      "epoch": 0.087,
      "grad_norm": 0.39860811829566956,
      "learning_rate": 9.147190598427583e-06,
      "loss": 0.1386,
      "step": 12740
    },
    {
      "step": 12750,
      "wer/bud500": 0.0593884292688631
    },
    {
      "step": 12750,
      "wer/private": 0.32918552036199095
    },
    {
      "epoch": 0.0875,
      "grad_norm": 0.46350911259651184,
      "learning_rate": 9.12494761978979e-06,
      "loss": 0.1508,
      "step": 12750
    },
    {
      "epoch": 0.088,
      "grad_norm": 0.3910578191280365,
      "learning_rate": 9.102719890180342e-06,
      "loss": 0.1364,
      "step": 12760
    },
    {
      "epoch": 0.0885,
      "grad_norm": 0.5252910852432251,
      "learning_rate": 9.080507467292559e-06,
      "loss": 0.1548,
      "step": 12770
    },
    {
      "epoch": 0.089,
      "grad_norm": 0.3340476155281067,
      "learning_rate": 9.058310408780033e-06,
      "loss": 0.1264,
      "step": 12780
    },
    {
      "epoch": 0.0895,
      "grad_norm": 0.3902447819709778,
      "learning_rate": 9.036128772256477e-06,
      "loss": 0.1358,
      "step": 12790
    },
    {
      "step": 12800,
      "wer/bud500": 0.05894992253047622
    },
    {
      "step": 12800,
      "wer/private": 0.3393665158371041
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.42118361592292786,
      "learning_rate": 9.013962615295571e-06,
      "loss": 0.1378,
      "step": 12800
    },
    {
      "epoch": 0.09,
      "eval_loss": 0.08219433575868607,
      "eval_runtime": 219.4106,
      "eval_samples_per_second": 34.182,
      "eval_steps_per_second": 0.269,
      "step": 12800
    },
    {
      "epoch": 0.0005,
      "grad_norm": 0.4853914678096771,
      "learning_rate": 8.99181199543083e-06,
      "loss": 0.1347,
      "step": 12810
    },
    {
      "epoch": 0.001,
      "grad_norm": 0.4143439531326294,
      "learning_rate": 8.969676970155418e-06,
      "loss": 0.1373,
      "step": 12820
    },
    {
      "epoch": 0.0015,
      "grad_norm": 0.4585603177547455,
      "learning_rate": 8.947557596922039e-06,
      "loss": 0.1418,
      "step": 12830
    },
    {
      "epoch": 0.002,
      "grad_norm": 0.47474178671836853,
      "learning_rate": 8.925453933142775e-06,
      "loss": 0.122,
      "step": 12840
    },
    {
      "step": 12850,
      "wer/bud500": 0.06248721022013038
    },
    {
      "step": 12850,
      "wer/private": 0.34615384615384615
    },
    {
      "epoch": 0.0025,
      "grad_norm": 0.3952546715736389,
      "learning_rate": 8.903366036188922e-06,
      "loss": 0.1441,
      "step": 12850
    },
    {
      "epoch": 0.003,
      "grad_norm": 0.37311428785324097,
      "learning_rate": 8.88129396339086e-06,
      "loss": 0.1352,
      "step": 12860
    },
    {
      "epoch": 0.0035,
      "grad_norm": 0.46922120451927185,
      "learning_rate": 8.859237772037891e-06,
      "loss": 0.1388,
      "step": 12870
    },
    {
      "epoch": 0.004,
      "grad_norm": 0.37602537870407104,
      "learning_rate": 8.837197519378097e-06,
      "loss": 0.1339,
      "step": 12880
    },
    {
      "epoch": 0.0045,
      "grad_norm": 0.4903164505958557,
      "learning_rate": 8.81517326261819e-06,
      "loss": 0.1364,
      "step": 12890
    },
    {
      "step": 12900,
      "wer/bud500": 0.0592714941386266
    },
    {
      "step": 12900,
      "wer/private": 0.32805429864253394
    },
    {
      "epoch": 0.005,
      "grad_norm": 0.5062024593353271,
      "learning_rate": 8.793165058923371e-06,
      "loss": 0.1506,
      "step": 12900
    },
    {
      "epoch": 0.005,
      "eval_loss": 0.08224084973335266,
      "eval_runtime": 210.5468,
      "eval_samples_per_second": 35.622,
      "eval_steps_per_second": 0.28,
      "step": 12900
    },
    {
      "epoch": 0.0055,
      "grad_norm": 0.4189999997615814,
      "learning_rate": 8.771172965417159e-06,
      "loss": 0.1416,
      "step": 12910
    },
    {
      "epoch": 0.006,
      "grad_norm": 0.5009680986404419,
      "learning_rate": 8.749197039181282e-06,
      "loss": 0.1252,
      "step": 12920
    },
    {
      "epoch": 0.0065,
      "grad_norm": 0.45400720834732056,
      "learning_rate": 8.72723733725548e-06,
      "loss": 0.1466,
      "step": 12930
    },
    {
      "epoch": 0.007,
      "grad_norm": 0.4641101658344269,
      "learning_rate": 8.70529391663739e-06,
      "loss": 0.1415,
      "step": 12940
    },
    {
      "step": 12950,
      "wer/bud500": 0.05934457859502441
    },
    {
      "step": 12950,
      "wer/private": 0.33710407239819007
    },
    {
      "epoch": 0.0075,
      "grad_norm": 0.44636330008506775,
      "learning_rate": 8.683366834282404e-06,
      "loss": 0.1303,
      "step": 12950
    },
    {
      "epoch": 0.008,
      "grad_norm": 0.44400227069854736,
      "learning_rate": 8.661456147103481e-06,
      "loss": 0.1436,
      "step": 12960
    },
    {
      "epoch": 0.0085,
      "grad_norm": 0.4227495789527893,
      "learning_rate": 8.639561911971048e-06,
      "loss": 0.1298,
      "step": 12970
    },
    {
      "epoch": 0.009,
      "grad_norm": 0.4083422124385834,
      "learning_rate": 8.617684185712833e-06,
      "loss": 0.1462,
      "step": 12980
    },
    {
      "epoch": 0.0095,
      "grad_norm": 0.4501851797103882,
      "learning_rate": 8.595823025113678e-06,
      "loss": 0.1432,
      "step": 12990
    },
    {
      "step": 13000,
      "wer/bud500": 0.059534598181658724
    },
    {
      "step": 13000,
      "wer/private": 0.333710407239819
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.43980488181114197,
      "learning_rate": 8.573978486915464e-06,
      "loss": 0.1448,
      "step": 13000
    },
    {
      "epoch": 0.01,
      "eval_loss": 0.08236618340015411,
      "eval_runtime": 209.9356,
      "eval_samples_per_second": 35.725,
      "eval_steps_per_second": 0.281,
      "step": 13000
    },
    {
      "epoch": 0.0105,
      "grad_norm": 0.4581640958786011,
      "learning_rate": 8.552150627816928e-06,
      "loss": 0.1448,
      "step": 13010
    },
    {
      "epoch": 0.011,
      "grad_norm": 0.3606370985507965,
      "learning_rate": 8.530339504473488e-06,
      "loss": 0.1354,
      "step": 13020
    },
    {
      "epoch": 0.0115,
      "grad_norm": 0.4799758791923523,
      "learning_rate": 8.510723849325724e-06,
      "loss": 0.1423,
      "step": 13030
    },
    {
      "epoch": 0.012,
      "grad_norm": 0.4346630871295929,
      "learning_rate": 8.488944679847005e-06,
      "loss": 0.1455,
      "step": 13040
    },
    {
      "step": 13050,
      "wer/bud500": 0.05954921507293829
    },
    {
      "step": 13050,
      "wer/private": 0.32805429864253394
    },
    {
      "epoch": 0.0125,
      "grad_norm": 0.4011150002479553,
      "learning_rate": 8.46718241017798e-06,
      "loss": 0.1315,
      "step": 13050
    },
    {
      "epoch": 0.013,
      "grad_norm": 0.41714274883270264,
      "learning_rate": 8.445437096803833e-06,
      "loss": 0.1437,
      "step": 13060
    },
    {
      "epoch": 0.0135,
      "grad_norm": 0.445436954498291,
      "learning_rate": 8.423708796165755e-06,
      "loss": 0.14,
      "step": 13070
    },
    {
      "epoch": 0.014,
      "grad_norm": 0.45921069383621216,
      "learning_rate": 8.401997564660767e-06,
      "loss": 0.1345,
      "step": 13080
    },
    {
      "epoch": 0.0145,
      "grad_norm": 0.4304400086402893,
      "learning_rate": 8.38030345864158e-06,
      "loss": 0.1388,
      "step": 13090
    },
    {
      "step": 13100,
      "wer/bud500": 0.05931534481246528
    },
    {
      "step": 13100,
      "wer/private": 0.33710407239819007
    },
    {
      "epoch": 0.015,
      "grad_norm": 0.38506171107292175,
      "learning_rate": 8.35862653441648e-06,
      "loss": 0.1271,
      "step": 13100
    },
    {
      "epoch": 0.015,
      "eval_loss": 0.08209894597530365,
      "eval_runtime": 208.6108,
      "eval_samples_per_second": 35.952,
      "eval_steps_per_second": 0.283,
      "step": 13100
    },
    {
      "epoch": 0.0155,
      "grad_norm": 0.4213311970233917,
      "learning_rate": 8.336966848249128e-06,
      "loss": 0.1399,
      "step": 13110
    },
    {
      "epoch": 0.016,
      "grad_norm": 0.4539048671722412,
      "learning_rate": 8.315324456358464e-06,
      "loss": 0.1235,
      "step": 13120
    },
    {
      "epoch": 0.0165,
      "grad_norm": 0.4206258952617645,
      "learning_rate": 8.29369941491853e-06,
      "loss": 0.1379,
      "step": 13130
    },
    {
      "epoch": 0.017,
      "grad_norm": 0.36788350343704224,
      "learning_rate": 8.27209178005833e-06,
      "loss": 0.1308,
      "step": 13140
    },
    {
      "step": 13150,
      "wer/bud500": 0.05954921507293829
    },
    {
      "step": 13150,
      "wer/private": 0.32805429864253394
    },
    {
      "epoch": 0.0175,
      "grad_norm": 0.42088285088539124,
      "learning_rate": 8.250501607861696e-06,
      "loss": 0.1423,
      "step": 13150
    },
    {
      "epoch": 0.018,
      "grad_norm": 0.38716328144073486,
      "learning_rate": 8.22892895436714e-06,
      "loss": 0.1265,
      "step": 13160
    },
    {
      "epoch": 0.0185,
      "grad_norm": 0.4759274125099182,
      "learning_rate": 8.207373875567683e-06,
      "loss": 0.1265,
      "step": 13170
    },
    {
      "epoch": 0.019,
      "grad_norm": 0.38831931352615356,
      "learning_rate": 8.185836427410754e-06,
      "loss": 0.1377,
      "step": 13180
    },
    {
      "epoch": 0.0195,
      "grad_norm": 0.39621996879577637,
      "learning_rate": 8.164316665798005e-06,
      "loss": 0.1334,
      "step": 13190
    },
    {
      "step": 13200,
      "wer/bud500": 0.0593884292688631
    },
    {
      "step": 13200,
      "wer/private": 0.3190045248868778
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4134114682674408,
      "learning_rate": 8.142814646585176e-06,
      "loss": 0.1295,
      "step": 13200
    },
    {
      "epoch": 0.02,
      "eval_loss": 0.0821203738451004,
      "eval_runtime": 215.1589,
      "eval_samples_per_second": 34.858,
      "eval_steps_per_second": 0.274,
      "step": 13200
    },
    {
      "epoch": 0.0205,
      "grad_norm": 0.6109045743942261,
      "learning_rate": 8.12133042558198e-06,
      "loss": 0.1277,
      "step": 13210
    },
    {
      "epoch": 0.021,
      "grad_norm": 0.3665473163127899,
      "learning_rate": 8.09986405855191e-06,
      "loss": 0.133,
      "step": 13220
    },
    {
      "epoch": 0.0215,
      "grad_norm": 0.5906411409378052,
      "learning_rate": 8.07841560121213e-06,
      "loss": 0.1505,
      "step": 13230
    },
    {
      "epoch": 0.022,
      "grad_norm": 0.45357924699783325,
      "learning_rate": 8.05698510923332e-06,
      "loss": 0.1354,
      "step": 13240
    },
    {
      "step": 13250,
      "wer/bud500": 0.059461513725260914
    },
    {
      "step": 13250,
      "wer/private": 0.32918552036199095
    },
    {
      "epoch": 0.0225,
      "grad_norm": 0.41315990686416626,
      "learning_rate": 8.035572638239512e-06,
      "loss": 0.1359,
      "step": 13250
    },
    {
      "epoch": 0.023,
      "grad_norm": 0.49866151809692383,
      "learning_rate": 8.014178243807983e-06,
      "loss": 0.1364,
      "step": 13260
    },
    {
      "epoch": 0.0235,
      "grad_norm": 0.42855238914489746,
      "learning_rate": 7.992801981469094e-06,
      "loss": 0.1442,
      "step": 13270
    },
    {
      "epoch": 0.024,
      "grad_norm": 0.4569448232650757,
      "learning_rate": 7.971443906706123e-06,
      "loss": 0.1462,
      "step": 13280
    },
    {
      "epoch": 0.0245,
      "grad_norm": 0.35836634039878845,
      "learning_rate": 7.950104074955161e-06,
      "loss": 0.1381,
      "step": 13290
    },
    {
      "step": 13300,
      "wer/bud500": 0.05902300698687403
    },
    {
      "step": 13300,
      "wer/private": 0.3246606334841629
    },
    {
      "epoch": 0.025,
      "grad_norm": 0.3499501347541809,
      "learning_rate": 7.928782541604935e-06,
      "loss": 0.1357,
      "step": 13300
    },
    {
      "epoch": 0.025,
      "eval_loss": 0.08220650255680084,
      "eval_runtime": 208.7291,
      "eval_samples_per_second": 35.932,
      "eval_steps_per_second": 0.283,
      "step": 13300
    },
    {
      "epoch": 0.0255,
      "grad_norm": 0.3161756992340088,
      "learning_rate": 7.907479361996677e-06,
      "loss": 0.1249,
      "step": 13310
    },
    {
      "epoch": 0.026,
      "grad_norm": 0.4143288731575012,
      "learning_rate": 7.886194591423997e-06,
      "loss": 0.1314,
      "step": 13320
    },
    {
      "epoch": 0.0265,
      "grad_norm": 0.5100864171981812,
      "learning_rate": 7.864928285132701e-06,
      "loss": 0.1452,
      "step": 13330
    },
    {
      "epoch": 0.027,
      "grad_norm": 0.5569455027580261,
      "learning_rate": 7.84368049832069e-06,
      "loss": 0.1331,
      "step": 13340
    },
    {
      "step": 13350,
      "wer/bud500": 0.05918379279094922
    },
    {
      "step": 13350,
      "wer/private": 0.3223981900452489
    },
    {
      "epoch": 0.0275,
      "grad_norm": 0.33010050654411316,
      "learning_rate": 7.822451286137787e-06,
      "loss": 0.1351,
      "step": 13350
    },
    {
      "epoch": 0.028,
      "grad_norm": 0.40289199352264404,
      "learning_rate": 7.801240703685594e-06,
      "loss": 0.137,
      "step": 13360
    },
    {
      "epoch": 0.0285,
      "grad_norm": 0.7243614196777344,
      "learning_rate": 7.780048806017377e-06,
      "loss": 0.1293,
      "step": 13370
    },
    {
      "epoch": 0.029,
      "grad_norm": 0.39225220680236816,
      "learning_rate": 7.7588756481379e-06,
      "loss": 0.1288,
      "step": 13380
    },
    {
      "epoch": 0.0295,
      "grad_norm": 0.5122717022895813,
      "learning_rate": 7.737721285003274e-06,
      "loss": 0.1332,
      "step": 13390
    },
    {
      "step": 13400,
      "wer/bud500": 0.05944689683398135
    },
    {
      "step": 13400,
      "wer/private": 0.3246606334841629
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.3806608319282532,
      "learning_rate": 7.716585771520845e-06,
      "loss": 0.1282,
      "step": 13400
    },
    {
      "epoch": 0.03,
      "eval_loss": 0.08198796957731247,
      "eval_runtime": 209.2273,
      "eval_samples_per_second": 35.846,
      "eval_steps_per_second": 0.282,
      "step": 13400
    },
    {
      "epoch": 0.0305,
      "grad_norm": 0.43306267261505127,
      "learning_rate": 7.695469162549022e-06,
      "loss": 0.1515,
      "step": 13410
    },
    {
      "epoch": 0.031,
      "grad_norm": 0.39399653673171997,
      "learning_rate": 7.674371512897145e-06,
      "loss": 0.1268,
      "step": 13420
    },
    {
      "epoch": 0.0315,
      "grad_norm": 0.5034177303314209,
      "learning_rate": 7.653292877325356e-06,
      "loss": 0.1273,
      "step": 13430
    },
    {
      "epoch": 0.032,
      "grad_norm": 0.3791651427745819,
      "learning_rate": 7.632233310544426e-06,
      "loss": 0.1356,
      "step": 13440
    },
    {
      "step": 13450,
      "wer/bud500": 0.059286111029906156
    },
    {
      "step": 13450,
      "wer/private": 0.3156108597285068
    },
    {
      "epoch": 0.0325,
      "grad_norm": 0.4766610264778137,
      "learning_rate": 7.611192867215659e-06,
      "loss": 0.1412,
      "step": 13450
    },
    {
      "epoch": 0.033,
      "grad_norm": 0.3566725552082062,
      "learning_rate": 7.590171601950696e-06,
      "loss": 0.144,
      "step": 13460
    },
    {
      "epoch": 0.0335,
      "grad_norm": 0.3880019187927246,
      "learning_rate": 7.569169569311409e-06,
      "loss": 0.1376,
      "step": 13470
    },
    {
      "epoch": 0.034,
      "grad_norm": 0.39499443769454956,
      "learning_rate": 7.548186823809756e-06,
      "loss": 0.1379,
      "step": 13480
    },
    {
      "epoch": 0.0345,
      "grad_norm": 0.5599567294120789,
      "learning_rate": 7.527223419907638e-06,
      "loss": 0.146,
      "step": 13490
    },
    {
      "step": 13500,
      "wer/bud500": 0.05912532522583097
    },
    {
      "step": 13500,
      "wer/private": 0.3246606334841629
    },
    {
      "epoch": 0.035,
      "grad_norm": 0.401215136051178,
      "learning_rate": 7.506279412016743e-06,
      "loss": 0.1367,
      "step": 13500
    },
    {
      "epoch": 0.035,
      "eval_loss": 0.0819748267531395,
      "eval_runtime": 209.2706,
      "eval_samples_per_second": 35.839,
      "eval_steps_per_second": 0.282,
      "step": 13500
    },
    {
      "epoch": 0.0355,
      "grad_norm": 0.36490926146507263,
      "learning_rate": 7.485354854498414e-06,
      "loss": 0.1462,
      "step": 13510
    },
    {
      "epoch": 0.036,
      "grad_norm": 0.45188695192337036,
      "learning_rate": 7.464449801663523e-06,
      "loss": 0.1358,
      "step": 13520
    },
    {
      "epoch": 0.0365,
      "grad_norm": 0.4004768133163452,
      "learning_rate": 7.4435643077723005e-06,
      "loss": 0.1496,
      "step": 13530
    },
    {
      "epoch": 0.037,
      "grad_norm": 0.4672852158546448,
      "learning_rate": 7.4226984270342206e-06,
      "loss": 0.1405,
      "step": 13540
    },
    {
      "step": 13550,
      "wer/bud500": 0.05908147455199228
    },
    {
      "step": 13550,
      "wer/private": 0.3257918552036199
    },
    {
      "epoch": 0.0375,
      "grad_norm": 0.4725862145423889,
      "learning_rate": 7.401852213607858e-06,
      "loss": 0.1396,
      "step": 13550
    },
    {
      "epoch": 0.038,
      "grad_norm": 0.3562013804912567,
      "learning_rate": 7.381025721600722e-06,
      "loss": 0.1291,
      "step": 13560
    },
    {
      "epoch": 0.0385,
      "grad_norm": 0.42795392870903015,
      "learning_rate": 7.360219005069139e-06,
      "loss": 0.1367,
      "step": 13570
    },
    {
      "epoch": 0.039,
      "grad_norm": 0.3742218613624573,
      "learning_rate": 7.339432118018119e-06,
      "loss": 0.1466,
      "step": 13580
    },
    {
      "epoch": 0.0395,
      "grad_norm": 0.5288768410682678,
      "learning_rate": 7.318665114401182e-06,
      "loss": 0.1392,
      "step": 13590
    },
    {
      "step": 13600,
      "wer/bud500": 0.058979156313035346
    },
    {
      "step": 13600,
      "wer/private": 0.3246606334841629
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.33126601576805115,
      "learning_rate": 7.297918048120267e-06,
      "loss": 0.1294,
      "step": 13600
    },
    {
      "epoch": 0.04,
      "eval_loss": 0.08204317092895508,
      "eval_runtime": 208.947,
      "eval_samples_per_second": 35.894,
      "eval_steps_per_second": 0.282,
      "step": 13600
    },
    {
      "epoch": 0.0405,
      "grad_norm": 0.33197230100631714,
      "learning_rate": 7.277190973025541e-06,
      "loss": 0.147,
      "step": 13610
    },
    {
      "epoch": 0.041,
      "grad_norm": 0.4726065397262573,
      "learning_rate": 7.256483942915289e-06,
      "loss": 0.1319,
      "step": 13620
    },
    {
      "epoch": 0.0415,
      "grad_norm": 0.37082529067993164,
      "learning_rate": 7.235797011535777e-06,
      "loss": 0.1374,
      "step": 13630
    },
    {
      "epoch": 0.042,
      "grad_norm": 0.5241588950157166,
      "learning_rate": 7.215130232581089e-06,
      "loss": 0.1379,
      "step": 13640
    },
    {
      "step": 13650,
      "wer/bud500": 0.059534598181658724
    },
    {
      "step": 13650,
      "wer/private": 0.3427601809954751
    },
    {
      "epoch": 0.0425,
      "grad_norm": 0.3720340430736542,
      "learning_rate": 7.194483659693015e-06,
      "loss": 0.1261,
      "step": 13650
    },
    {
      "epoch": 0.043,
      "grad_norm": 0.45083221793174744,
      "learning_rate": 7.1738573464608995e-06,
      "loss": 0.1527,
      "step": 13660
    },
    {
      "epoch": 0.0435,
      "grad_norm": 0.3790634870529175,
      "learning_rate": 7.153251346421491e-06,
      "loss": 0.1239,
      "step": 13670
    },
    {
      "epoch": 0.044,
      "grad_norm": 0.3932901918888092,
      "learning_rate": 7.132665713058815e-06,
      "loss": 0.1414,
      "step": 13680
    },
    {
      "epoch": 0.0445,
      "grad_norm": 0.40013256669044495,
      "learning_rate": 7.11210049980405e-06,
      "loss": 0.1395,
      "step": 13690
    },
    {
      "step": 13700,
      "wer/bud500": 0.059227643464787906
    },
    {
      "step": 13700,
      "wer/private": 0.3223981900452489
    },
    {
      "epoch": 0.045,
      "grad_norm": 0.45452645421028137,
      "learning_rate": 7.091555760035349e-06,
      "loss": 0.1415,
      "step": 13700
    },
    {
      "epoch": 0.045,
      "eval_loss": 0.08196187019348145,
      "eval_runtime": 208.9494,
      "eval_samples_per_second": 35.894,
      "eval_steps_per_second": 0.282,
      "step": 13700
    },
    {
      "epoch": 0.0455,
      "grad_norm": 0.434541255235672,
      "learning_rate": 7.071031547077751e-06,
      "loss": 0.1305,
      "step": 13710
    },
    {
      "epoch": 0.046,
      "grad_norm": 0.45299649238586426,
      "learning_rate": 7.050527914202996e-06,
      "loss": 0.1358,
      "step": 13720
    },
    {
      "epoch": 0.0465,
      "grad_norm": 0.3811693787574768,
      "learning_rate": 7.0300449146294095e-06,
      "loss": 0.1449,
      "step": 13730
    },
    {
      "epoch": 0.047,
      "grad_norm": 0.48326703906059265,
      "learning_rate": 7.009582601521779e-06,
      "loss": 0.1351,
      "step": 13740
    },
    {
      "step": 13750,
      "wer/bud500": 0.05919840968222878
    },
    {
      "step": 13750,
      "wer/private": 0.3201357466063348
    },
    {
      "epoch": 0.0475,
      "grad_norm": 0.4345889389514923,
      "learning_rate": 6.989141027991173e-06,
      "loss": 0.136,
      "step": 13750
    },
    {
      "epoch": 0.048,
      "grad_norm": 0.4852656424045563,
      "learning_rate": 6.968720247094853e-06,
      "loss": 0.1575,
      "step": 13760
    },
    {
      "epoch": 0.0485,
      "grad_norm": 0.4139150083065033,
      "learning_rate": 6.948320311836106e-06,
      "loss": 0.1358,
      "step": 13770
    },
    {
      "epoch": 0.049,
      "grad_norm": 0.40055570006370544,
      "learning_rate": 6.9279412751641026e-06,
      "loss": 0.132,
      "step": 13780
    },
    {
      "epoch": 0.0495,
      "grad_norm": 0.48424032330513,
      "learning_rate": 6.907583189973775e-06,
      "loss": 0.1136,
      "step": 13790
    },
    {
      "step": 13800,
      "wer/bud500": 0.05908147455199228
    },
    {
      "step": 13800,
      "wer/private": 0.31334841628959276
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.45055466890335083,
      "learning_rate": 6.887246109105683e-06,
      "loss": 0.1414,
      "step": 13800
    },
    {
      "epoch": 0.05,
      "eval_loss": 0.08188672363758087,
      "eval_runtime": 208.7548,
      "eval_samples_per_second": 35.927,
      "eval_steps_per_second": 0.283,
      "step": 13800
    },
    {
      "epoch": 0.0505,
      "grad_norm": 0.37656667828559875,
      "learning_rate": 6.866930085345854e-06,
      "loss": 0.1359,
      "step": 13810
    },
    {
      "epoch": 0.051,
      "grad_norm": 0.42618441581726074,
      "learning_rate": 6.846635171425679e-06,
      "loss": 0.153,
      "step": 13820
    },
    {
      "epoch": 0.0515,
      "grad_norm": 0.43671730160713196,
      "learning_rate": 6.82636142002174e-06,
      "loss": 0.1376,
      "step": 13830
    },
    {
      "epoch": 0.052,
      "grad_norm": 0.49750328063964844,
      "learning_rate": 6.806108883755693e-06,
      "loss": 0.1263,
      "step": 13840
    },
    {
      "step": 13850,
      "wer/bud500": 0.05934457859502441
    },
    {
      "step": 13850,
      "wer/private": 0.3178733031674208
    },
    {
      "epoch": 0.0525,
      "grad_norm": 0.36873528361320496,
      "learning_rate": 6.7858776151941445e-06,
      "loss": 0.148,
      "step": 13850
    },
    {
      "epoch": 0.053,
      "grad_norm": 0.46372783184051514,
      "learning_rate": 6.765667666848474e-06,
      "loss": 0.1496,
      "step": 13860
    },
    {
      "epoch": 0.0535,
      "grad_norm": 0.3965974748134613,
      "learning_rate": 6.745479091174745e-06,
      "loss": 0.1523,
      "step": 13870
    },
    {
      "epoch": 0.054,
      "grad_norm": 0.44916725158691406,
      "learning_rate": 6.7253119405735475e-06,
      "loss": 0.1397,
      "step": 13880
    },
    {
      "epoch": 0.0545,
      "grad_norm": 0.48095792531967163,
      "learning_rate": 6.705166267389842e-06,
      "loss": 0.1367,
      "step": 13890
    },
    {
      "step": 13900,
      "wer/bud500": 0.05918379279094922
    },
    {
      "step": 13900,
      "wer/private": 0.3212669683257919
    },
    {
      "epoch": 0.055,
      "grad_norm": 0.3514467179775238,
      "learning_rate": 6.6850421239128525e-06,
      "loss": 0.1412,
      "step": 13900
    },
    {
      "epoch": 0.055,
      "eval_loss": 0.08201834559440613,
      "eval_runtime": 209.7905,
      "eval_samples_per_second": 35.75,
      "eval_steps_per_second": 0.281,
      "step": 13900
    },
    {
      "epoch": 0.0555,
      "grad_norm": 0.41089069843292236,
      "learning_rate": 6.664939562375935e-06,
      "loss": 0.1337,
      "step": 13910
    },
    {
      "epoch": 0.056,
      "grad_norm": 0.5329530835151672,
      "learning_rate": 6.644858634956404e-06,
      "loss": 0.1528,
      "step": 13920
    },
    {
      "epoch": 0.0565,
      "grad_norm": 0.4611120820045471,
      "learning_rate": 6.624799393775445e-06,
      "loss": 0.1445,
      "step": 13930
    },
    {
      "epoch": 0.057,
      "grad_norm": 0.36598965525627136,
      "learning_rate": 6.60476189089794e-06,
      "loss": 0.1377,
      "step": 13940
    },
    {
      "step": 13950,
      "wer/bud500": 0.0593884292688631
    },
    {
      "step": 13950,
      "wer/private": 0.3416289592760181
    },
    {
      "epoch": 0.0575,
      "grad_norm": 0.4290069341659546,
      "learning_rate": 6.584746178332349e-06,
      "loss": 0.136,
      "step": 13950
    },
    {
      "epoch": 0.058,
      "grad_norm": 0.41693317890167236,
      "learning_rate": 6.564752308030585e-06,
      "loss": 0.122,
      "step": 13960
    },
    {
      "epoch": 0.0585,
      "grad_norm": 0.4132329821586609,
      "learning_rate": 6.5447803318878535e-06,
      "loss": 0.1299,
      "step": 13970
    },
    {
      "epoch": 0.059,
      "grad_norm": 0.5215750336647034,
      "learning_rate": 6.524830301742545e-06,
      "loss": 0.1411,
      "step": 13980
    },
    {
      "epoch": 0.0595,
      "grad_norm": 0.45501774549484253,
      "learning_rate": 6.504902269376093e-06,
      "loss": 0.1365,
      "step": 13990
    },
    {
      "step": 14000,
      "wer/bud500": 0.05900839009559447
    },
    {
      "step": 14000,
      "wer/private": 0.3156108597285068
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.38379520177841187,
      "learning_rate": 6.484996286512802e-06,
      "loss": 0.1447,
      "step": 14000
    },
    {
      "epoch": 0.06,
      "eval_loss": 0.08179736137390137,
      "eval_runtime": 210.4437,
      "eval_samples_per_second": 35.639,
      "eval_steps_per_second": 0.28,
      "step": 14000
    },
    {
      "epoch": 0.0605,
      "grad_norm": 0.41232824325561523,
      "learning_rate": 6.465112404819781e-06,
      "loss": 0.1475,
      "step": 14010
    },
    {
      "epoch": 0.061,
      "grad_norm": 0.4952182471752167,
      "learning_rate": 6.445250675906767e-06,
      "loss": 0.1471,
      "step": 14020
    },
    {
      "epoch": 0.0615,
      "grad_norm": 0.4398129880428314,
      "learning_rate": 6.425411151325979e-06,
      "loss": 0.1339,
      "step": 14030
    },
    {
      "epoch": 0.062,
      "grad_norm": 0.4371061325073242,
      "learning_rate": 6.405593882572031e-06,
      "loss": 0.135,
      "step": 14040
    },
    {
      "step": 14050,
      "wer/bud500": 0.058862221182798845
    },
    {
      "step": 14050,
      "wer/private": 0.3246606334841629
    },
    {
      "epoch": 0.0625,
      "grad_norm": 0.5599185228347778,
      "learning_rate": 6.38579892108175e-06,
      "loss": 0.1343,
      "step": 14050
    },
    {
      "epoch": 0.063,
      "grad_norm": 0.517616868019104,
      "learning_rate": 6.366026318234064e-06,
      "loss": 0.1246,
      "step": 14060
    },
    {
      "epoch": 0.0635,
      "grad_norm": 0.48823171854019165,
      "learning_rate": 6.3462761253498875e-06,
      "loss": 0.1322,
      "step": 14070
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.46224913001060486,
      "learning_rate": 6.3265483936919395e-06,
      "loss": 0.144,
      "step": 14080
    },
    {
      "epoch": 0.0645,
      "grad_norm": 0.45759356021881104,
      "learning_rate": 6.306843174464666e-06,
      "loss": 0.1436,
      "step": 14090
    },
    {
      "step": 14100,
      "wer/bud500": 0.05930072792118572
    },
    {
      "step": 14100,
      "wer/private": 0.3257918552036199
    },
    {
      "epoch": 0.065,
      "grad_norm": 0.44416543841362,
      "learning_rate": 6.287160518814071e-06,
      "loss": 0.1438,
      "step": 14100
    },
    {
      "epoch": 0.065,
      "eval_loss": 0.08195459097623825,
      "eval_runtime": 210.1274,
      "eval_samples_per_second": 35.693,
      "eval_steps_per_second": 0.281,
      "step": 14100
    },
    {
      "epoch": 0.0655,
      "grad_norm": 0.4146212041378021,
      "learning_rate": 6.26750047782759e-06,
      "loss": 0.1412,
      "step": 14110
    },
    {
      "epoch": 0.066,
      "grad_norm": 0.4682933986186981,
      "learning_rate": 6.247863102533959e-06,
      "loss": 0.1427,
      "step": 14120
    },
    {
      "epoch": 0.0665,
      "grad_norm": 0.37107381224632263,
      "learning_rate": 6.228248443903094e-06,
      "loss": 0.128,
      "step": 14130
    },
    {
      "epoch": 0.067,
      "grad_norm": 0.37101271748542786,
      "learning_rate": 6.208656552845936e-06,
      "loss": 0.1397,
      "step": 14140
    },
    {
      "step": 14150,
      "wer/bud500": 0.05918379279094922
    },
    {
      "step": 14150,
      "wer/private": 0.3382352941176471
    },
    {
      "epoch": 0.0675,
      "grad_norm": 0.3958965539932251,
      "learning_rate": 6.189087480214342e-06,
      "loss": 0.1351,
      "step": 14150
    },
    {
      "epoch": 0.068,
      "grad_norm": 0.5697753429412842,
      "learning_rate": 6.16954127680095e-06,
      "loss": 0.1434,
      "step": 14160
    },
    {
      "epoch": 0.0685,
      "grad_norm": 0.5075253844261169,
      "learning_rate": 6.15001799333901e-06,
      "loss": 0.1514,
      "step": 14170
    },
    {
      "epoch": 0.069,
      "grad_norm": 0.4280305504798889,
      "learning_rate": 6.130517680502306e-06,
      "loss": 0.1313,
      "step": 14180
    },
    {
      "epoch": 0.0695,
      "grad_norm": 0.5078684091567993,
      "learning_rate": 6.1110403889050056e-06,
      "loss": 0.1325,
      "step": 14190
    },
    {
      "step": 14200,
      "wer/bud500": 0.05956383196421785
    },
    {
      "step": 14200,
      "wer/private": 0.34728506787330315
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.41979679465293884,
      "learning_rate": 6.091586169101498e-06,
      "loss": 0.1552,
      "step": 14200
    },
    {
      "epoch": 0.07,
      "eval_loss": 0.08203724026679993,
      "eval_runtime": 211.1222,
      "eval_samples_per_second": 35.524,
      "eval_steps_per_second": 0.279,
      "step": 14200
    },
    {
      "epoch": 0.0705,
      "grad_norm": 0.43771979212760925,
      "learning_rate": 6.072155071586315e-06,
      "loss": 0.1439,
      "step": 14210
    },
    {
      "epoch": 0.071,
      "grad_norm": 0.3724207878112793,
      "learning_rate": 6.052747146793956e-06,
      "loss": 0.1382,
      "step": 14220
    },
    {
      "epoch": 0.0715,
      "grad_norm": 0.46505165100097656,
      "learning_rate": 6.033362445098776e-06,
      "loss": 0.1391,
      "step": 14230
    },
    {
      "epoch": 0.072,
      "grad_norm": 0.5832257270812988,
      "learning_rate": 6.014001016814863e-06,
      "loss": 0.1358,
      "step": 14240
    },
    {
      "step": 14250,
      "wer/bud500": 0.0591545590083901
    },
    {
      "step": 14250,
      "wer/private": 0.33144796380090497
    },
    {
      "epoch": 0.0725,
      "grad_norm": 0.4999768137931824,
      "learning_rate": 5.994662912195886e-06,
      "loss": 0.1502,
      "step": 14250
    },
    {
      "epoch": 0.073,
      "grad_norm": 0.4116207957267761,
      "learning_rate": 5.975348181434982e-06,
      "loss": 0.1441,
      "step": 14260
    },
    {
      "epoch": 0.0735,
      "grad_norm": 0.37984833121299744,
      "learning_rate": 5.956056874664633e-06,
      "loss": 0.1501,
      "step": 14270
    },
    {
      "epoch": 0.074,
      "grad_norm": 0.3953680396080017,
      "learning_rate": 5.936789041956488e-06,
      "loss": 0.1312,
      "step": 14280
    },
    {
      "epoch": 0.0745,
      "grad_norm": 0.40687933564186096,
      "learning_rate": 5.917544733321297e-06,
      "loss": 0.1486,
      "step": 14290
    },
    {
      "step": 14300,
      "wer/bud500": 0.05966615020317479
    },
    {
      "step": 14300,
      "wer/private": 0.3416289592760181
    },
    {
      "epoch": 0.075,
      "grad_norm": 0.4417093098163605,
      "learning_rate": 5.8983239987087505e-06,
      "loss": 0.142,
      "step": 14300
    },
    {
      "epoch": 0.075,
      "eval_loss": 0.08207260072231293,
      "eval_runtime": 208.9844,
      "eval_samples_per_second": 35.888,
      "eval_steps_per_second": 0.282,
      "step": 14300
    },
    {
      "epoch": 0.0755,
      "grad_norm": 0.3462493121623993,
      "learning_rate": 5.879126888007333e-06,
      "loss": 0.1349,
      "step": 14310
    },
    {
      "epoch": 0.076,
      "grad_norm": 0.3854076564311981,
      "learning_rate": 5.859953451044234e-06,
      "loss": 0.1375,
      "step": 14320
    },
    {
      "epoch": 0.0765,
      "grad_norm": 0.39978763461112976,
      "learning_rate": 5.8408037375851816e-06,
      "loss": 0.1477,
      "step": 14330
    },
    {
      "epoch": 0.077,
      "grad_norm": 0.4768078327178955,
      "learning_rate": 5.821677797334325e-06,
      "loss": 0.1368,
      "step": 14340
    },
    {
      "step": 14350,
      "wer/bud500": 0.0592714941386266
    },
    {
      "step": 14350,
      "wer/private": 0.33144796380090497
    },
    {
      "epoch": 0.0775,
      "grad_norm": 0.42562663555145264,
      "learning_rate": 5.802575679934129e-06,
      "loss": 0.1313,
      "step": 14350
    },
    {
      "epoch": 0.078,
      "grad_norm": 0.4488045573234558,
      "learning_rate": 5.7834974349651995e-06,
      "loss": 0.1369,
      "step": 14360
    },
    {
      "epoch": 0.0785,
      "grad_norm": 0.4819650948047638,
      "learning_rate": 5.764443111946199e-06,
      "loss": 0.1439,
      "step": 14370
    },
    {
      "epoch": 0.079,
      "grad_norm": 0.6132129430770874,
      "learning_rate": 5.745412760333703e-06,
      "loss": 0.1493,
      "step": 14380
    },
    {
      "epoch": 0.0795,
      "grad_norm": 0.5105416774749756,
      "learning_rate": 5.726406429522036e-06,
      "loss": 0.1316,
      "step": 14390
    },
    {
      "step": 14400,
      "wer/bud500": 0.05912532522583097
    },
    {
      "step": 14400,
      "wer/private": 0.3393665158371041
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4625459909439087,
      "learning_rate": 5.707424168843209e-06,
      "loss": 0.1415,
      "step": 14400
    },
    {
      "epoch": 0.08,
      "eval_loss": 0.08184733241796494,
      "eval_runtime": 210.2844,
      "eval_samples_per_second": 35.666,
      "eval_steps_per_second": 0.281,
      "step": 14400
    },
    {
      "epoch": 0.0805,
      "grad_norm": 0.45605048537254333,
      "learning_rate": 5.68846602756675e-06,
      "loss": 0.1438,
      "step": 14410
    },
    {
      "epoch": 0.081,
      "grad_norm": 0.4140607416629791,
      "learning_rate": 5.669532054899567e-06,
      "loss": 0.1353,
      "step": 14420
    },
    {
      "epoch": 0.0815,
      "grad_norm": 0.44072556495666504,
      "learning_rate": 5.650622299985861e-06,
      "loss": 0.1277,
      "step": 14430
    },
    {
      "epoch": 0.082,
      "grad_norm": 0.5783316493034363,
      "learning_rate": 5.6317368119069584e-06,
      "loss": 0.152,
      "step": 14440
    },
    {
      "step": 14450,
      "wer/bud500": 0.059578448855497415
    },
    {
      "step": 14450,
      "wer/private": 0.3382352941176471
    },
    {
      "epoch": 0.0825,
      "grad_norm": 0.4286392629146576,
      "learning_rate": 5.612875639681199e-06,
      "loss": 0.144,
      "step": 14450
    },
    {
      "epoch": 0.083,
      "grad_norm": 0.45669305324554443,
      "learning_rate": 5.5940388322638215e-06,
      "loss": 0.1541,
      "step": 14460
    },
    {
      "epoch": 0.0835,
      "grad_norm": 0.626476526260376,
      "learning_rate": 5.5752264385468106e-06,
      "loss": 0.1497,
      "step": 14470
    },
    {
      "epoch": 0.084,
      "grad_norm": 0.43276622891426086,
      "learning_rate": 5.556438507358799e-06,
      "loss": 0.1364,
      "step": 14480
    },
    {
      "epoch": 0.0845,
      "grad_norm": 0.44339922070503235,
      "learning_rate": 5.537675087464913e-06,
      "loss": 0.1445,
      "step": 14490
    },
    {
      "step": 14500,
      "wer/bud500": 0.0592714941386266
    },
    {
      "step": 14500,
      "wer/private": 0.3404977375565611
    },
    {
      "epoch": 0.085,
      "grad_norm": 0.4828164577484131,
      "learning_rate": 5.518936227566654e-06,
      "loss": 0.1379,
      "step": 14500
    },
    {
      "epoch": 0.085,
      "eval_loss": 0.08207695931196213,
      "eval_runtime": 208.4214,
      "eval_samples_per_second": 35.985,
      "eval_steps_per_second": 0.283,
      "step": 14500
    },
    {
      "epoch": 0.0855,
      "grad_norm": 0.3578919470310211,
      "learning_rate": 5.5002219763017965e-06,
      "loss": 0.1373,
      "step": 14510
    },
    {
      "epoch": 0.086,
      "grad_norm": 0.42342644929885864,
      "learning_rate": 5.48153238224423e-06,
      "loss": 0.1451,
      "step": 14520
    },
    {
      "epoch": 0.0865,
      "grad_norm": 0.4676647484302521,
      "learning_rate": 5.462867493903838e-06,
      "loss": 0.136,
      "step": 14530
    },
    {
      "epoch": 0.087,
      "grad_norm": 0.4107072353363037,
      "learning_rate": 5.444227359726396e-06,
      "loss": 0.1453,
      "step": 14540
    },
    {
      "step": 14550,
      "wer/bud500": 0.059169175899669656
    },
    {
      "step": 14550,
      "wer/private": 0.33710407239819007
    },
    {
      "epoch": 0.0875,
      "grad_norm": 0.44089576601982117,
      "learning_rate": 5.425612028093413e-06,
      "loss": 0.1473,
      "step": 14550
    },
    {
      "epoch": 0.088,
      "grad_norm": 0.3815634846687317,
      "learning_rate": 5.407021547322021e-06,
      "loss": 0.1408,
      "step": 14560
    },
    {
      "epoch": 0.0885,
      "grad_norm": 0.604278028011322,
      "learning_rate": 5.388455965664871e-06,
      "loss": 0.1402,
      "step": 14570
    },
    {
      "epoch": 0.089,
      "grad_norm": 0.42198044061660767,
      "learning_rate": 5.369915331309959e-06,
      "loss": 0.1312,
      "step": 14580
    },
    {
      "epoch": 0.0895,
      "grad_norm": 0.4314744472503662,
      "learning_rate": 5.351399692380554e-06,
      "loss": 0.138,
      "step": 14590
    },
    {
      "step": 14600,
      "wer/bud500": 0.05919840968222878
    },
    {
      "step": 14600,
      "wer/private": 0.332579185520362
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4846765995025635,
      "learning_rate": 5.332909096935034e-06,
      "loss": 0.143,
      "step": 14600
    },
    {
      "epoch": 0.09,
      "eval_loss": 0.08194530010223389,
      "eval_runtime": 209.6622,
      "eval_samples_per_second": 35.772,
      "eval_steps_per_second": 0.281,
      "step": 14600
    },
    {
      "epoch": 0.0905,
      "grad_norm": 0.41549918055534363,
      "learning_rate": 5.314443592966767e-06,
      "loss": 0.133,
      "step": 14610
    },
    {
      "epoch": 0.091,
      "grad_norm": 0.38902926445007324,
      "learning_rate": 5.296003228404015e-06,
      "loss": 0.1397,
      "step": 14620
    },
    {
      "epoch": 0.0915,
      "grad_norm": 0.5196802020072937,
      "learning_rate": 5.277588051109783e-06,
      "loss": 0.1489,
      "step": 14630
    },
    {
      "epoch": 0.092,
      "grad_norm": 0.6304386258125305,
      "learning_rate": 5.259198108881688e-06,
      "loss": 0.1346,
      "step": 14640
    },
    {
      "step": 14650,
      "wer/bud500": 0.05925687724734703
    },
    {
      "step": 14650,
      "wer/private": 0.3235294117647059
    },
    {
      "epoch": 0.0925,
      "grad_norm": 0.4275490641593933,
      "learning_rate": 5.240833449451868e-06,
      "loss": 0.1413,
      "step": 14650
    },
    {
      "epoch": 0.093,
      "grad_norm": 0.488932341337204,
      "learning_rate": 5.222494120486821e-06,
      "loss": 0.1439,
      "step": 14660
    },
    {
      "epoch": 0.0935,
      "grad_norm": 0.453174889087677,
      "learning_rate": 5.204180169587304e-06,
      "loss": 0.1384,
      "step": 14670
    },
    {
      "epoch": 0.094,
      "grad_norm": 0.41312986612319946,
      "learning_rate": 5.18589164428821e-06,
      "loss": 0.1405,
      "step": 14680
    },
    {
      "epoch": 0.0945,
      "grad_norm": 0.4267049729824066,
      "learning_rate": 5.167628592058429e-06,
      "loss": 0.1474,
      "step": 14690
    },
    {
      "step": 14700,
      "wer/bud500": 0.05932996170374485
    },
    {
      "step": 14700,
      "wer/private": 0.33144796380090497
    },
    {
      "epoch": 0.095,
      "grad_norm": 0.4693373143672943,
      "learning_rate": 5.149391060300743e-06,
      "loss": 0.1346,
      "step": 14700
    },
    {
      "epoch": 0.095,
      "eval_loss": 0.08192945271730423,
      "eval_runtime": 208.3635,
      "eval_samples_per_second": 35.995,
      "eval_steps_per_second": 0.283,
      "step": 14700
    },
    {
      "epoch": 0.0955,
      "grad_norm": 0.43926629424095154,
      "learning_rate": 5.131179096351682e-06,
      "loss": 0.1424,
      "step": 14710
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.4403594434261322,
      "learning_rate": 5.112992747481431e-06,
      "loss": 0.1402,
      "step": 14720
    },
    {
      "epoch": 0.0965,
      "grad_norm": 0.43096330761909485,
      "learning_rate": 5.09483206089367e-06,
      "loss": 0.1372,
      "step": 14730
    },
    {
      "epoch": 0.097,
      "grad_norm": 0.46903613209724426,
      "learning_rate": 5.076697083725492e-06,
      "loss": 0.1555,
      "step": 14740
    },
    {
      "step": 14750,
      "wer/bud500": 0.058803753617680594
    },
    {
      "step": 14750,
      "wer/private": 0.3404977375565611
    },
    {
      "epoch": 0.0975,
      "grad_norm": 0.5563995838165283,
      "learning_rate": 5.058587863047237e-06,
      "loss": 0.1374,
      "step": 14750
    },
    {
      "epoch": 0.098,
      "grad_norm": 0.4609720706939697,
      "learning_rate": 5.040504445862413e-06,
      "loss": 0.1386,
      "step": 14760
    },
    {
      "epoch": 0.0985,
      "grad_norm": 0.4358113408088684,
      "learning_rate": 5.022446879107542e-06,
      "loss": 0.153,
      "step": 14770
    },
    {
      "epoch": 0.099,
      "grad_norm": 0.3950529992580414,
      "learning_rate": 5.0044152096520454e-06,
      "loss": 0.1411,
      "step": 14780
    },
    {
      "epoch": 0.0995,
      "grad_norm": 0.48407357931137085,
      "learning_rate": 4.9864094842981415e-06,
      "loss": 0.131,
      "step": 14790
    },
    {
      "step": 14800,
      "wer/bud500": 0.059052240769433155
    },
    {
      "step": 14800,
      "wer/private": 0.334841628959276
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4419054388999939,
      "learning_rate": 4.968429749780704e-06,
      "loss": 0.1289,
      "step": 14800
    },
    {
      "epoch": 0.1,
      "eval_loss": 0.08187612146139145,
      "eval_runtime": 208.5861,
      "eval_samples_per_second": 35.956,
      "eval_steps_per_second": 0.283,
      "step": 14800
    },
    {
      "epoch": 0.1005,
      "grad_norm": 0.4250337481498718,
      "learning_rate": 4.950476052767139e-06,
      "loss": 0.1392,
      "step": 14810
    },
    {
      "epoch": 0.101,
      "grad_norm": 0.467935174703598,
      "learning_rate": 4.932548439857272e-06,
      "loss": 0.1387,
      "step": 14820
    },
    {
      "epoch": 0.1015,
      "grad_norm": 0.3892872929573059,
      "learning_rate": 4.914646957583236e-06,
      "loss": 0.1365,
      "step": 14830
    },
    {
      "epoch": 0.102,
      "grad_norm": 0.39638814330101013,
      "learning_rate": 4.896771652409326e-06,
      "loss": 0.1367,
      "step": 14840
    },
    {
      "step": 14850,
      "wer/bud500": 0.059052240769433155
    },
    {
      "step": 14850,
      "wer/private": 0.35294117647058826
    },
    {
      "epoch": 0.1025,
      "grad_norm": 0.3574909567832947,
      "learning_rate": 4.878922570731909e-06,
      "loss": 0.1388,
      "step": 14850
    },
    {
      "epoch": 0.103,
      "grad_norm": 0.4339357614517212,
      "learning_rate": 4.861099758879269e-06,
      "loss": 0.1372,
      "step": 14860
    },
    {
      "epoch": 0.1035,
      "grad_norm": 0.5642929077148438,
      "learning_rate": 4.843303263111522e-06,
      "loss": 0.1496,
      "step": 14870
    },
    {
      "epoch": 0.104,
      "grad_norm": 0.5159318447113037,
      "learning_rate": 4.825533129620474e-06,
      "loss": 0.1238,
      "step": 14880
    },
    {
      "epoch": 0.1045,
      "grad_norm": 0.4316929876804352,
      "learning_rate": 4.807789404529495e-06,
      "loss": 0.1388,
      "step": 14890
    },
    {
      "step": 14900,
      "wer/bud500": 0.05944689683398135
    },
    {
      "step": 14900,
      "wer/private": 0.3382352941176471
    },
    {
      "epoch": 0.105,
      "grad_norm": 0.44847944378852844,
      "learning_rate": 4.790072133893424e-06,
      "loss": 0.1611,
      "step": 14900
    },
    {
      "epoch": 0.105,
      "eval_loss": 0.0817490741610527,
      "eval_runtime": 208.6506,
      "eval_samples_per_second": 35.945,
      "eval_steps_per_second": 0.283,
      "step": 14900
    },
    {
      "epoch": 0.1055,
      "grad_norm": 0.4731704294681549,
      "learning_rate": 4.772381363698437e-06,
      "loss": 0.1395,
      "step": 14910
    },
    {
      "epoch": 0.106,
      "grad_norm": 0.4357360899448395,
      "learning_rate": 4.754717139861919e-06,
      "loss": 0.1454,
      "step": 14920
    },
    {
      "epoch": 0.1065,
      "grad_norm": 0.46159136295318604,
      "learning_rate": 4.738842073440735e-06,
      "loss": 0.1507,
      "step": 14930
    },
    {
      "epoch": 0.107,
      "grad_norm": 0.5537223219871521,
      "learning_rate": 4.721228413940836e-06,
      "loss": 0.1435,
      "step": 14940
    },
    {
      "step": 14950,
      "wer/bud500": 0.05925687724734703
    },
    {
      "step": 14950,
      "wer/private": 0.34502262443438914
    },
    {
      "epoch": 0.1075,
      "grad_norm": 0.36445698142051697,
      "learning_rate": 4.703641433569754e-06,
      "loss": 0.1309,
      "step": 14950
    },
    {
      "epoch": 0.108,
      "grad_norm": 0.395214706659317,
      "learning_rate": 4.68608117797549e-06,
      "loss": 0.1379,
      "step": 14960
    },
    {
      "epoch": 0.1085,
      "grad_norm": 0.39894041419029236,
      "learning_rate": 4.668547692736674e-06,
      "loss": 0.1393,
      "step": 14970
    },
    {
      "epoch": 0.109,
      "grad_norm": 0.3598499298095703,
      "learning_rate": 4.651041023362443e-06,
      "loss": 0.1293,
      "step": 14980
    },
    {
      "epoch": 0.1095,
      "grad_norm": 0.537544310092926,
      "learning_rate": 4.633561215292346e-06,
      "loss": 0.1386,
      "step": 14990
    },
    {
      "step": 15000,
      "wer/bud500": 0.05919840968222878
    },
    {
      "step": 15000,
      "wer/private": 0.3427601809954751
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3713046610355377,
      "learning_rate": 4.6161083138962105e-06,
      "loss": 0.1478,
      "step": 15000
    },
    {
      "epoch": 0.11,
      "eval_loss": 0.08185119926929474,
      "eval_runtime": 208.2927,
      "eval_samples_per_second": 36.007,
      "eval_steps_per_second": 0.283,
      "step": 15000
    },
    {
      "epoch": 0.1105,
      "grad_norm": 0.6065582633018494,
      "learning_rate": 4.59868236447402e-06,
      "loss": 0.1413,
      "step": 15010
    },
    {
      "epoch": 0.111,
      "grad_norm": 0.49450716376304626,
      "learning_rate": 4.5812834122557955e-06,
      "loss": 0.155,
      "step": 15020
    },
    {
      "epoch": 0.1115,
      "grad_norm": 0.3910495638847351,
      "learning_rate": 4.563911502401508e-06,
      "loss": 0.1331,
      "step": 15030
    },
    {
      "epoch": 0.112,
      "grad_norm": 0.5573459267616272,
      "learning_rate": 4.546566680000915e-06,
      "loss": 0.146,
      "step": 15040
    },
    {
      "step": 15050,
      "wer/bud500": 0.05900839009559447
    },
    {
      "step": 15050,
      "wer/private": 0.32805429864253394
    },
    {
      "epoch": 0.1125,
      "grad_norm": 0.3601655662059784,
      "learning_rate": 4.529248990073483e-06,
      "loss": 0.1263,
      "step": 15050
    },
    {
      "epoch": 0.113,
      "grad_norm": 0.4738416373729706,
      "learning_rate": 4.511958477568243e-06,
      "loss": 0.1377,
      "step": 15060
    },
    {
      "epoch": 0.1135,
      "grad_norm": 0.45944297313690186,
      "learning_rate": 4.4946951873637e-06,
      "loss": 0.1389,
      "step": 15070
    },
    {
      "epoch": 0.114,
      "grad_norm": 0.3475699722766876,
      "learning_rate": 4.477459164267681e-06,
      "loss": 0.1428,
      "step": 15080
    },
    {
      "epoch": 0.1145,
      "grad_norm": 0.4500635862350464,
      "learning_rate": 4.460250453017264e-06,
      "loss": 0.1287,
      "step": 15090
    },
    {
      "step": 15100,
      "wer/bud500": 0.059227643464787906
    },
    {
      "step": 15100,
      "wer/private": 0.32918552036199095
    },
    {
      "epoch": 0.115,
      "grad_norm": 0.43698447942733765,
      "learning_rate": 4.443069098278614e-06,
      "loss": 0.1342,
      "step": 15100
    },
    {
      "epoch": 0.115,
      "eval_loss": 0.0816870853304863,
      "eval_runtime": 208.7563,
      "eval_samples_per_second": 35.927,
      "eval_steps_per_second": 0.283,
      "step": 15100
    },
    {
      "epoch": 0.1155,
      "grad_norm": 0.3865965008735657,
      "learning_rate": 4.425915144646913e-06,
      "loss": 0.1349,
      "step": 15110
    },
    {
      "epoch": 0.116,
      "grad_norm": 0.337698757648468,
      "learning_rate": 4.408788636646206e-06,
      "loss": 0.1246,
      "step": 15120
    },
    {
      "epoch": 0.1165,
      "grad_norm": 0.44427603483200073,
      "learning_rate": 4.391689618729301e-06,
      "loss": 0.1246,
      "step": 15130
    },
    {
      "epoch": 0.117,
      "grad_norm": 0.45696866512298584,
      "learning_rate": 4.374618135277668e-06,
      "loss": 0.1387,
      "step": 15140
    },
    {
      "step": 15150,
      "wer/bud500": 0.05921302657350835
    },
    {
      "step": 15150,
      "wer/private": 0.34615384615384615
    },
    {
      "epoch": 0.1175,
      "grad_norm": 0.7619701027870178,
      "learning_rate": 4.357574230601292e-06,
      "loss": 0.1344,
      "step": 15150
    },
    {
      "epoch": 0.118,
      "grad_norm": 0.4519362151622772,
      "learning_rate": 4.3405579489385895e-06,
      "loss": 0.1279,
      "step": 15160
    },
    {
      "epoch": 0.1185,
      "grad_norm": 0.4673554301261902,
      "learning_rate": 4.323569334456278e-06,
      "loss": 0.1471,
      "step": 15170
    },
    {
      "epoch": 0.119,
      "grad_norm": 0.4368395507335663,
      "learning_rate": 4.30660843124926e-06,
      "loss": 0.1364,
      "step": 15180
    },
    {
      "epoch": 0.1195,
      "grad_norm": 0.5580637454986572,
      "learning_rate": 4.289675283340503e-06,
      "loss": 0.1404,
      "step": 15190
    },
    {
      "step": 15200,
      "wer/bud500": 0.058920688747917095
    },
    {
      "step": 15200,
      "wer/private": 0.3552036199095023
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5816850066184998,
      "learning_rate": 4.272769934680955e-06,
      "loss": 0.1385,
      "step": 15200
    },
    {
      "epoch": 0.12,
      "eval_loss": 0.08180253952741623,
      "eval_runtime": 208.6411,
      "eval_samples_per_second": 35.947,
      "eval_steps_per_second": 0.283,
      "step": 15200
    },
    {
      "epoch": 0.1205,
      "grad_norm": 0.38746801018714905,
      "learning_rate": 4.2558924291493875e-06,
      "loss": 0.1453,
      "step": 15210
    },
    {
      "epoch": 0.121,
      "grad_norm": 0.4071447253227234,
      "learning_rate": 4.239042810552323e-06,
      "loss": 0.1293,
      "step": 15220
    },
    {
      "epoch": 0.1215,
      "grad_norm": 0.5811150670051575,
      "learning_rate": 4.222221122623887e-06,
      "loss": 0.1437,
      "step": 15230
    },
    {
      "epoch": 0.122,
      "grad_norm": 0.3548012375831604,
      "learning_rate": 4.205427409025714e-06,
      "loss": 0.1381,
      "step": 15240
    },
    {
      "step": 15250,
      "wer/bud500": 0.058876838074078404
    },
    {
      "step": 15250,
      "wer/private": 0.32918552036199095
    },
    {
      "epoch": 0.1225,
      "grad_norm": 0.41343408823013306,
      "learning_rate": 4.188661713346837e-06,
      "loss": 0.1414,
      "step": 15250
    },
    {
      "epoch": 0.123,
      "grad_norm": 0.4469398856163025,
      "learning_rate": 4.171924079103551e-06,
      "loss": 0.1368,
      "step": 15260
    },
    {
      "epoch": 0.1235,
      "grad_norm": 0.4658419191837311,
      "learning_rate": 4.155214549739332e-06,
      "loss": 0.1603,
      "step": 15270
    },
    {
      "epoch": 0.124,
      "grad_norm": 0.3921947777271271,
      "learning_rate": 4.138533168624706e-06,
      "loss": 0.1362,
      "step": 15280
    },
    {
      "epoch": 0.1245,
      "grad_norm": 0.46612873673439026,
      "learning_rate": 4.121879979057128e-06,
      "loss": 0.1535,
      "step": 15290
    },
    {
      "step": 15300,
      "wer/bud500": 0.0593884292688631
    },
    {
      "step": 15300,
      "wer/private": 0.333710407239819
    },
    {
      "epoch": 0.125,
      "grad_norm": 0.40192314982414246,
      "learning_rate": 4.105255024260883e-06,
      "loss": 0.1419,
      "step": 15300
    },
    {
      "epoch": 0.125,
      "eval_loss": 0.08195652812719345,
      "eval_runtime": 208.7378,
      "eval_samples_per_second": 35.93,
      "eval_steps_per_second": 0.283,
      "step": 15300
    },
    {
      "epoch": 0.1255,
      "grad_norm": 0.43240734934806824,
      "learning_rate": 4.088658347386986e-06,
      "loss": 0.1436,
      "step": 15310
    },
    {
      "epoch": 0.126,
      "grad_norm": 0.41840073466300964,
      "learning_rate": 4.072089991513031e-06,
      "loss": 0.1476,
      "step": 15320
    },
    {
      "epoch": 0.1265,
      "grad_norm": 0.4818785488605499,
      "learning_rate": 4.055549999643127e-06,
      "loss": 0.1483,
      "step": 15330
    },
    {
      "epoch": 0.127,
      "grad_norm": 0.4683396816253662,
      "learning_rate": 4.039038414707748e-06,
      "loss": 0.1251,
      "step": 15340
    },
    {
      "step": 15350,
      "wer/bud500": 0.058803753617680594
    },
    {
      "step": 15350,
      "wer/private": 0.35407239819004527
    },
    {
      "epoch": 0.1275,
      "grad_norm": 0.3832493722438812,
      "learning_rate": 4.022555279563633e-06,
      "loss": 0.1348,
      "step": 15350
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.36796700954437256,
      "learning_rate": 4.006100636993697e-06,
      "loss": 0.1396,
      "step": 15360
    },
    {
      "epoch": 0.1285,
      "grad_norm": 0.373053640127182,
      "learning_rate": 3.989674529706876e-06,
      "loss": 0.1487,
      "step": 15370
    },
    {
      "epoch": 0.129,
      "grad_norm": 0.37775325775146484,
      "learning_rate": 3.973277000338061e-06,
      "loss": 0.1426,
      "step": 15380
    },
    {
      "epoch": 0.1295,
      "grad_norm": 0.4612155556678772,
      "learning_rate": 3.9569080914479635e-06,
      "loss": 0.1403,
      "step": 15390
    },
    {
      "step": 15400,
      "wer/bud500": 0.059096091443271846
    },
    {
      "step": 15400,
      "wer/private": 0.33031674208144796
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.45005854964256287,
      "learning_rate": 3.940567845523002e-06,
      "loss": 0.1465,
      "step": 15400
    },
    {
      "epoch": 0.13,
      "eval_loss": 0.08183539658784866,
      "eval_runtime": 209.3665,
      "eval_samples_per_second": 35.822,
      "eval_steps_per_second": 0.282,
      "step": 15400
    },
    {
      "epoch": 0.0005,
      "grad_norm": 0.5624626278877258,
      "learning_rate": 3.924256304975196e-06,
      "loss": 0.1313,
      "step": 15410
    },
    {
      "epoch": 0.001,
      "grad_norm": 0.3937038481235504,
      "learning_rate": 3.907973512142077e-06,
      "loss": 0.1405,
      "step": 15420
    },
    {
      "epoch": 0.0015,
      "grad_norm": 0.4512272775173187,
      "learning_rate": 3.891719509286537e-06,
      "loss": 0.1382,
      "step": 15430
    },
    {
      "epoch": 0.002,
      "grad_norm": 0.4131503701210022,
      "learning_rate": 3.875494338596762e-06,
      "loss": 0.1324,
      "step": 15440
    },
    {
      "step": 15450,
      "wer/bud500": 0.05932996170374485
    },
    {
      "step": 15450,
      "wer/private": 0.33031674208144796
    },
    {
      "epoch": 0.0025,
      "grad_norm": 0.5037463903427124,
      "learning_rate": 3.859298042186089e-06,
      "loss": 0.1295,
      "step": 15450
    },
    {
      "epoch": 0.003,
      "grad_norm": 0.4228619635105133,
      "learning_rate": 3.843130662092912e-06,
      "loss": 0.137,
      "step": 15460
    },
    {
      "epoch": 0.0035,
      "grad_norm": 0.5026863813400269,
      "learning_rate": 3.826992240280581e-06,
      "loss": 0.1443,
      "step": 15470
    },
    {
      "epoch": 0.004,
      "grad_norm": 0.38726651668548584,
      "learning_rate": 3.8108828186372686e-06,
      "loss": 0.1226,
      "step": 15480
    },
    {
      "epoch": 0.0045,
      "grad_norm": 0.4521128237247467,
      "learning_rate": 3.794802438975887e-06,
      "loss": 0.1417,
      "step": 15490
    },
    {
      "step": 15500,
      "wer/bud500": 0.06242874265501213
    },
    {
      "step": 15500,
      "wer/private": 0.32805429864253394
    },
    {
      "epoch": 0.005,
      "grad_norm": 0.4524000585079193,
      "learning_rate": 3.778751143033973e-06,
      "loss": 0.1471,
      "step": 15500
    },
    {
      "epoch": 0.005,
      "eval_loss": 0.08169446140527725,
      "eval_runtime": 199.4077,
      "eval_samples_per_second": 37.611,
      "eval_steps_per_second": 0.296,
      "step": 15500
    },
    {
      "epoch": 0.0055,
      "grad_norm": 0.43732577562332153,
      "learning_rate": 3.7627289724735486e-06,
      "loss": 0.1323,
      "step": 15510
    },
    {
      "epoch": 0.006,
      "grad_norm": 0.46358251571655273,
      "learning_rate": 3.7467359688810655e-06,
      "loss": 0.1346,
      "step": 15520
    },
    {
      "epoch": 0.0065,
      "grad_norm": 0.4135412871837616,
      "learning_rate": 3.7307721737672696e-06,
      "loss": 0.1419,
      "step": 15530
    },
    {
      "epoch": 0.007,
      "grad_norm": 0.45256516337394714,
      "learning_rate": 3.7148376285670764e-06,
      "loss": 0.1284,
      "step": 15540
    },
    {
      "step": 15550,
      "wer/bud500": 0.058979156313035346
    },
    {
      "step": 15550,
      "wer/private": 0.3246606334841629
    },
    {
      "epoch": 0.0075,
      "grad_norm": 0.4177090525627136,
      "learning_rate": 3.6989323746395024e-06,
      "loss": 0.1337,
      "step": 15550
    },
    {
      "epoch": 0.008,
      "grad_norm": 0.47241732478141785,
      "learning_rate": 3.6830564532675233e-06,
      "loss": 0.1509,
      "step": 15560
    },
    {
      "epoch": 0.0085,
      "grad_norm": 0.5232701301574707,
      "learning_rate": 3.6672099056579795e-06,
      "loss": 0.1434,
      "step": 15570
    },
    {
      "epoch": 0.009,
      "grad_norm": 0.40807658433914185,
      "learning_rate": 3.651392772941482e-06,
      "loss": 0.1309,
      "step": 15580
    },
    {
      "epoch": 0.0095,
      "grad_norm": 0.3918151259422302,
      "learning_rate": 3.6356050961722825e-06,
      "loss": 0.1465,
      "step": 15590
    },
    {
      "step": 15600,
      "wer/bud500": 0.05902300698687403
    },
    {
      "step": 15600,
      "wer/private": 0.3404977375565611
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.625434935092926,
      "learning_rate": 3.619846916328182e-06,
      "loss": 0.1332,
      "step": 15600
    },
    {
      "epoch": 0.01,
      "eval_loss": 0.08172987401485443,
      "eval_runtime": 199.3498,
      "eval_samples_per_second": 37.622,
      "eval_steps_per_second": 0.296,
      "step": 15600
    },
    {
      "epoch": 0.0105,
      "grad_norm": 0.47202470898628235,
      "learning_rate": 3.604118274310435e-06,
      "loss": 0.1405,
      "step": 15610
    },
    {
      "epoch": 0.011,
      "grad_norm": 0.3517603278160095,
      "learning_rate": 3.5884192109435933e-06,
      "loss": 0.1241,
      "step": 15620
    },
    {
      "epoch": 0.0115,
      "grad_norm": 0.5010287165641785,
      "learning_rate": 3.5727497669754664e-06,
      "loss": 0.1343,
      "step": 15630
    },
    {
      "epoch": 0.012,
      "grad_norm": 0.4319533407688141,
      "learning_rate": 3.557109983076984e-06,
      "loss": 0.1479,
      "step": 15640
    },
    {
      "step": 15650,
      "wer/bud500": 0.05937381237758354
    },
    {
      "step": 15650,
      "wer/private": 0.34841628959276016
    },
    {
      "epoch": 0.0125,
      "grad_norm": 0.41559022665023804,
      "learning_rate": 3.541499899842071e-06,
      "loss": 0.1369,
      "step": 15650
    },
    {
      "epoch": 0.013,
      "grad_norm": 0.4139329493045807,
      "learning_rate": 3.525919557787587e-06,
      "loss": 0.1501,
      "step": 15660
    },
    {
      "epoch": 0.0135,
      "grad_norm": 0.3956088125705719,
      "learning_rate": 3.510368997353176e-06,
      "loss": 0.1398,
      "step": 15670
    },
    {
      "epoch": 0.014,
      "grad_norm": 0.5166798233985901,
      "learning_rate": 3.4948482589011905e-06,
      "loss": 0.1336,
      "step": 15680
    },
    {
      "epoch": 0.0145,
      "grad_norm": 0.45148417353630066,
      "learning_rate": 3.4793573827165804e-06,
      "loss": 0.1349,
      "step": 15690
    },
    {
      "step": 15700,
      "wer/bud500": 0.0591545590083901
    },
    {
      "step": 15700,
      "wer/private": 0.3235294117647059
    },
    {
      "epoch": 0.015,
      "grad_norm": 0.5917596817016602,
      "learning_rate": 3.46389640900679e-06,
      "loss": 0.1372,
      "step": 15700
    },
    {
      "epoch": 0.015,
      "eval_loss": 0.0817231684923172,
      "eval_runtime": 203.7372,
      "eval_samples_per_second": 36.812,
      "eval_steps_per_second": 0.29,
      "step": 15700
    },
    {
      "epoch": 0.0155,
      "grad_norm": 0.43397438526153564,
      "learning_rate": 3.448465377901635e-06,
      "loss": 0.1428,
      "step": 15710
    },
    {
      "epoch": 0.016,
      "grad_norm": 0.35495808720588684,
      "learning_rate": 3.4330643294532345e-06,
      "loss": 0.1249,
      "step": 15720
    },
    {
      "epoch": 0.0165,
      "grad_norm": 0.39685720205307007,
      "learning_rate": 3.4176933036358683e-06,
      "loss": 0.1394,
      "step": 15730
    },
    {
      "epoch": 0.017,
      "grad_norm": 0.35355138778686523,
      "learning_rate": 3.402352340345891e-06,
      "loss": 0.1293,
      "step": 15740
    },
    {
      "step": 15750,
      "wer/bud500": 0.05935919548630397
    },
    {
      "step": 15750,
      "wer/private": 0.33144796380090497
    },
    {
      "epoch": 0.0175,
      "grad_norm": 0.5611170530319214,
      "learning_rate": 3.387041479401647e-06,
      "loss": 0.1386,
      "step": 15750
    },
    {
      "epoch": 0.018,
      "grad_norm": 0.5260940790176392,
      "learning_rate": 3.3717607605433234e-06,
      "loss": 0.1357,
      "step": 15760
    },
    {
      "epoch": 0.0185,
      "grad_norm": 0.6482295393943787,
      "learning_rate": 3.3565102234328905e-06,
      "loss": 0.1357,
      "step": 15770
    },
    {
      "epoch": 0.019,
      "grad_norm": 0.383197546005249,
      "learning_rate": 3.3412899076539797e-06,
      "loss": 0.139,
      "step": 15780
    },
    {
      "epoch": 0.0195,
      "grad_norm": 0.42970919609069824,
      "learning_rate": 3.326099852711761e-06,
      "loss": 0.1509,
      "step": 15790
    },
    {
      "step": 15800,
      "wer/bud500": 0.059096091443271846
    },
    {
      "step": 15800,
      "wer/private": 0.3438914027149321
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.45624879002571106,
      "learning_rate": 3.3109400980328834e-06,
      "loss": 0.1411,
      "step": 15800
    },
    {
      "epoch": 0.02,
      "eval_loss": 0.08184002339839935,
      "eval_runtime": 198.8598,
      "eval_samples_per_second": 37.715,
      "eval_steps_per_second": 0.297,
      "step": 15800
    },
    {
      "epoch": 0.0205,
      "grad_norm": 0.5119611620903015,
      "learning_rate": 3.295810682965343e-06,
      "loss": 0.1368,
      "step": 15810
    },
    {
      "epoch": 0.021,
      "grad_norm": 0.4238370358943939,
      "learning_rate": 3.28071164677838e-06,
      "loss": 0.1342,
      "step": 15820
    },
    {
      "epoch": 0.0215,
      "grad_norm": 0.48247700929641724,
      "learning_rate": 3.2656430286623988e-06,
      "loss": 0.1585,
      "step": 15830
    },
    {
      "epoch": 0.022,
      "grad_norm": 0.4436226487159729,
      "learning_rate": 3.2506048677288374e-06,
      "loss": 0.1346,
      "step": 15840
    },
    {
      "step": 15850,
      "wer/bud500": 0.058993773204314905
    },
    {
      "step": 15850,
      "wer/private": 0.32805429864253394
    },
    {
      "epoch": 0.0225,
      "grad_norm": 0.3893525302410126,
      "learning_rate": 3.235597203010086e-06,
      "loss": 0.1307,
      "step": 15850
    },
    {
      "epoch": 0.023,
      "grad_norm": 0.41653865575790405,
      "learning_rate": 3.2206200734593887e-06,
      "loss": 0.1356,
      "step": 15860
    },
    {
      "epoch": 0.0235,
      "grad_norm": 0.38353973627090454,
      "learning_rate": 3.205673517950716e-06,
      "loss": 0.1361,
      "step": 15870
    },
    {
      "epoch": 0.024,
      "grad_norm": 0.43586039543151855,
      "learning_rate": 3.1907575752786975e-06,
      "loss": 0.1396,
      "step": 15880
    },
    {
      "epoch": 0.0245,
      "grad_norm": 0.4567120373249054,
      "learning_rate": 3.1758722841585093e-06,
      "loss": 0.1381,
      "step": 15890
    },
    {
      "step": 15900,
      "wer/bud500": 0.05884760429151928
    },
    {
      "step": 15900,
      "wer/private": 0.33031674208144796
    },
    {
      "epoch": 0.025,
      "grad_norm": 0.388570636510849,
      "learning_rate": 3.161017683225742e-06,
      "loss": 0.1326,
      "step": 15900
    },
    {
      "epoch": 0.025,
      "eval_loss": 0.08178702741861343,
      "eval_runtime": 206.1757,
      "eval_samples_per_second": 36.377,
      "eval_steps_per_second": 0.286,
      "step": 15900
    },
    {
      "epoch": 0.0255,
      "grad_norm": 0.35868120193481445,
      "learning_rate": 3.146193811036355e-06,
      "loss": 0.1232,
      "step": 15910
    },
    {
      "epoch": 0.026,
      "grad_norm": 0.41841861605644226,
      "learning_rate": 3.1314007060665446e-06,
      "loss": 0.1322,
      "step": 15920
    },
    {
      "epoch": 0.0265,
      "grad_norm": 0.35269343852996826,
      "learning_rate": 3.116638406712639e-06,
      "loss": 0.1358,
      "step": 15930
    },
    {
      "epoch": 0.027,
      "grad_norm": 0.4220100939273834,
      "learning_rate": 3.101906951291022e-06,
      "loss": 0.1415,
      "step": 15940
    },
    {
      "step": 15950,
      "wer/bud500": 0.059096091443271846
    },
    {
      "step": 15950,
      "wer/private": 0.32805429864253394
    },
    {
      "epoch": 0.0275,
      "grad_norm": 0.3756410479545593,
      "learning_rate": 3.087206378038009e-06,
      "loss": 0.1405,
      "step": 15950
    },
    {
      "epoch": 0.028,
      "grad_norm": 0.5216554403305054,
      "learning_rate": 3.0725367251097597e-06,
      "loss": 0.1425,
      "step": 15960
    },
    {
      "epoch": 0.0285,
      "grad_norm": 0.48597103357315063,
      "learning_rate": 3.05789803058219e-06,
      "loss": 0.1287,
      "step": 15970
    },
    {
      "epoch": 0.029,
      "grad_norm": 0.44312483072280884,
      "learning_rate": 3.043290332450847e-06,
      "loss": 0.1376,
      "step": 15980
    },
    {
      "epoch": 0.0295,
      "grad_norm": 0.6661017537117004,
      "learning_rate": 3.028713668630838e-06,
      "loss": 0.134,
      "step": 15990
    },
    {
      "step": 16000,
      "wer/bud500": 0.05908147455199228
    },
    {
      "step": 16000,
      "wer/private": 0.32805429864253394
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.3960268497467041,
      "learning_rate": 3.014168076956707e-06,
      "loss": 0.1398,
      "step": 16000
    },
    {
      "epoch": 0.03,
      "eval_loss": 0.08164564520120621,
      "eval_runtime": 198.9131,
      "eval_samples_per_second": 37.705,
      "eval_steps_per_second": 0.297,
      "step": 16000
    },
    {
      "epoch": 0.0305,
      "grad_norm": 0.4351373314857483,
      "learning_rate": 2.9996535951823524e-06,
      "loss": 0.1451,
      "step": 16010
    },
    {
      "epoch": 0.031,
      "grad_norm": 0.48996978998184204,
      "learning_rate": 2.98517026098093e-06,
      "loss": 0.1265,
      "step": 16020
    },
    {
      "epoch": 0.0315,
      "grad_norm": 0.4512403905391693,
      "learning_rate": 2.9707181119447496e-06,
      "loss": 0.1243,
      "step": 16030
    },
    {
      "epoch": 0.032,
      "grad_norm": 0.39529111981391907,
      "learning_rate": 2.95629718558517e-06,
      "loss": 0.1444,
      "step": 16040
    },
    {
      "step": 16050,
      "wer/bud500": 0.05870143537872365
    },
    {
      "step": 16050,
      "wer/private": 0.33597285067873306
    },
    {
      "epoch": 0.0325,
      "grad_norm": 0.46384045481681824,
      "learning_rate": 2.941907519332522e-06,
      "loss": 0.1427,
      "step": 16050
    },
    {
      "epoch": 0.033,
      "grad_norm": 0.4440225660800934,
      "learning_rate": 2.927549150535987e-06,
      "loss": 0.1427,
      "step": 16060
    },
    {
      "epoch": 0.0335,
      "grad_norm": 0.4526575803756714,
      "learning_rate": 2.913222116463516e-06,
      "loss": 0.1459,
      "step": 16070
    },
    {
      "epoch": 0.034,
      "grad_norm": 0.41575711965560913,
      "learning_rate": 2.8989264543017376e-06,
      "loss": 0.1331,
      "step": 16080
    },
    {
      "epoch": 0.0345,
      "grad_norm": 0.5673736333847046,
      "learning_rate": 2.8846622011558355e-06,
      "loss": 0.1412,
      "step": 16090
    },
    {
      "step": 16100,
      "wer/bud500": 0.05912532522583097
    },
    {
      "step": 16100,
      "wer/private": 0.3269230769230769
    },
    {
      "epoch": 0.035,
      "grad_norm": 0.4442341923713684,
      "learning_rate": 2.8704293940494906e-06,
      "loss": 0.1362,
      "step": 16100
    },
    {
      "epoch": 0.035,
      "eval_loss": 0.08175881952047348,
      "eval_runtime": 199.461,
      "eval_samples_per_second": 37.601,
      "eval_steps_per_second": 0.296,
      "step": 16100
    },
    {
      "epoch": 0.0355,
      "grad_norm": 0.4311847984790802,
      "learning_rate": 2.8562280699247477e-06,
      "loss": 0.1396,
      "step": 16110
    },
    {
      "epoch": 0.036,
      "grad_norm": 0.6222431063652039,
      "learning_rate": 2.842058265641938e-06,
      "loss": 0.1364,
      "step": 16120
    },
    {
      "epoch": 0.0365,
      "grad_norm": 0.4122510850429535,
      "learning_rate": 2.8279200179795866e-06,
      "loss": 0.1466,
      "step": 16130
    },
    {
      "epoch": 0.037,
      "grad_norm": 0.4866871237754822,
      "learning_rate": 2.813813363634313e-06,
      "loss": 0.1305,
      "step": 16140
    },
    {
      "step": 16150,
      "wer/bud500": 0.05924226035606747
    },
    {
      "step": 16150,
      "wer/private": 0.3585972850678733
    },
    {
      "epoch": 0.0375,
      "grad_norm": 0.42786914110183716,
      "learning_rate": 2.7997383392207244e-06,
      "loss": 0.1314,
      "step": 16150
    },
    {
      "epoch": 0.038,
      "grad_norm": 0.42915594577789307,
      "learning_rate": 2.7856949812713434e-06,
      "loss": 0.1428,
      "step": 16160
    },
    {
      "epoch": 0.0385,
      "grad_norm": 0.41542771458625793,
      "learning_rate": 2.771683326236493e-06,
      "loss": 0.1422,
      "step": 16170
    },
    {
      "epoch": 0.039,
      "grad_norm": 0.46570661664009094,
      "learning_rate": 2.7577034104842023e-06,
      "loss": 0.1342,
      "step": 16180
    },
    {
      "epoch": 0.0395,
      "grad_norm": 0.4544122517108917,
      "learning_rate": 2.743755270300139e-06,
      "loss": 0.1251,
      "step": 16190
    },
    {
      "step": 16200,
      "wer/bud500": 0.059169175899669656
    },
    {
      "step": 16200,
      "wer/private": 0.34728506787330315
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3485797941684723,
      "learning_rate": 2.7298389418874743e-06,
      "loss": 0.123,
      "step": 16200
    },
    {
      "epoch": 0.04,
      "eval_loss": 0.08168994635343552,
      "eval_runtime": 199.6054,
      "eval_samples_per_second": 37.574,
      "eval_steps_per_second": 0.296,
      "step": 16200
    },
    {
      "epoch": 0.0405,
      "grad_norm": 0.3639132082462311,
      "learning_rate": 2.715954461366828e-06,
      "loss": 0.1366,
      "step": 16210
    },
    {
      "epoch": 0.041,
      "grad_norm": 0.4453226625919342,
      "learning_rate": 2.7021018647761464e-06,
      "loss": 0.1244,
      "step": 16220
    },
    {
      "epoch": 0.0415,
      "grad_norm": 0.3428463339805603,
      "learning_rate": 2.688281188070618e-06,
      "loss": 0.1244,
      "step": 16230
    },
    {
      "epoch": 0.042,
      "grad_norm": 0.5826036930084229,
      "learning_rate": 2.6744924671225867e-06,
      "loss": 0.1622,
      "step": 16240
    },
    {
      "step": 16250,
      "wer/bud500": 0.05918379279094922
    },
    {
      "step": 16250,
      "wer/private": 0.32805429864253394
    },
    {
      "epoch": 0.0425,
      "grad_norm": 0.3467760384082794,
      "learning_rate": 2.6607357377214588e-06,
      "loss": 0.1293,
      "step": 16250
    },
    {
      "epoch": 0.043,
      "grad_norm": 0.47285449504852295,
      "learning_rate": 2.6470110355735884e-06,
      "loss": 0.1407,
      "step": 16260
    },
    {
      "epoch": 0.0435,
      "grad_norm": 0.4092331528663635,
      "learning_rate": 2.6333183963022185e-06,
      "loss": 0.1433,
      "step": 16270
    },
    {
      "epoch": 0.044,
      "grad_norm": 0.4524373710155487,
      "learning_rate": 2.619657855447358e-06,
      "loss": 0.1454,
      "step": 16280
    },
    {
      "epoch": 0.0445,
      "grad_norm": 0.46159490942955017,
      "learning_rate": 2.606029448465707e-06,
      "loss": 0.1419,
      "step": 16290
    },
    {
      "step": 16300,
      "wer/bud500": 0.059096091443271846
    },
    {
      "step": 16300,
      "wer/private": 0.3257918552036199
    },
    {
      "epoch": 0.045,
      "grad_norm": 0.4687940180301666,
      "learning_rate": 2.592433210730564e-06,
      "loss": 0.1376,
      "step": 16300
    },
    {
      "epoch": 0.045,
      "eval_loss": 0.08167481422424316,
      "eval_runtime": 198.5874,
      "eval_samples_per_second": 37.767,
      "eval_steps_per_second": 0.297,
      "step": 16300
    },
    {
      "epoch": 0.0455,
      "grad_norm": 0.42700234055519104,
      "learning_rate": 2.578869177531729e-06,
      "loss": 0.128,
      "step": 16310
    },
    {
      "epoch": 0.046,
      "grad_norm": 0.45112040638923645,
      "learning_rate": 2.5653373840754112e-06,
      "loss": 0.1285,
      "step": 16320
    },
    {
      "epoch": 0.0465,
      "grad_norm": 0.3538378179073334,
      "learning_rate": 2.551837865484134e-06,
      "loss": 0.1385,
      "step": 16330
    },
    {
      "epoch": 0.047,
      "grad_norm": 0.39704418182373047,
      "learning_rate": 2.538370656796666e-06,
      "loss": 0.1427,
      "step": 16340
    },
    {
      "step": 16350,
      "wer/bud500": 0.0587599029438419
    },
    {
      "step": 16350,
      "wer/private": 0.32805429864253394
    },
    {
      "epoch": 0.0475,
      "grad_norm": 0.5078231692314148,
      "learning_rate": 2.5249357929678923e-06,
      "loss": 0.1406,
      "step": 16350
    },
    {
      "epoch": 0.048,
      "grad_norm": 0.49894168972969055,
      "learning_rate": 2.511533308868768e-06,
      "loss": 0.1438,
      "step": 16360
    },
    {
      "epoch": 0.0485,
      "grad_norm": 0.3826325237751007,
      "learning_rate": 2.498163239286183e-06,
      "loss": 0.1436,
      "step": 16370
    },
    {
      "epoch": 0.049,
      "grad_norm": 0.44226956367492676,
      "learning_rate": 2.4848256189229113e-06,
      "loss": 0.1309,
      "step": 16380
    },
    {
      "epoch": 0.0495,
      "grad_norm": 0.49136364459991455,
      "learning_rate": 2.471520482397494e-06,
      "loss": 0.1275,
      "step": 16390
    },
    {
      "step": 16400,
      "wer/bud500": 0.05883298740023972
    },
    {
      "step": 16400,
      "wer/private": 0.32805429864253394
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.40249887108802795,
      "learning_rate": 2.4582478642441534e-06,
      "loss": 0.1393,
      "step": 16400
    },
    {
      "epoch": 0.05,
      "eval_loss": 0.08154041320085526,
      "eval_runtime": 199.1493,
      "eval_samples_per_second": 37.66,
      "eval_steps_per_second": 0.296,
      "step": 16400
    },
    {
      "epoch": 0.0505,
      "grad_norm": 0.3344736695289612,
      "learning_rate": 2.4450077989127195e-06,
      "loss": 0.1415,
      "step": 16410
    },
    {
      "epoch": 0.051,
      "grad_norm": 0.4692215323448181,
      "learning_rate": 2.431800320768531e-06,
      "loss": 0.145,
      "step": 16420
    },
    {
      "epoch": 0.0515,
      "grad_norm": 0.3755786716938019,
      "learning_rate": 2.418625464092334e-06,
      "loss": 0.1376,
      "step": 16430
    },
    {
      "epoch": 0.052,
      "grad_norm": 0.5006893277168274,
      "learning_rate": 2.4054832630802048e-06,
      "loss": 0.1229,
      "step": 16440
    },
    {
      "step": 16450,
      "wer/bud500": 0.058993773204314905
    },
    {
      "step": 16450,
      "wer/private": 0.34728506787330315
    },
    {
      "epoch": 0.0525,
      "grad_norm": 0.39804860949516296,
      "learning_rate": 2.3923737518434707e-06,
      "loss": 0.1535,
      "step": 16450
    },
    {
      "epoch": 0.053,
      "grad_norm": 0.4251348078250885,
      "learning_rate": 2.3792969644086e-06,
      "loss": 0.1548,
      "step": 16460
    },
    {
      "epoch": 0.0535,
      "grad_norm": 0.42002007365226746,
      "learning_rate": 2.366252934717132e-06,
      "loss": 0.1415,
      "step": 16470
    },
    {
      "epoch": 0.054,
      "grad_norm": 0.4618057608604431,
      "learning_rate": 2.3532416966255777e-06,
      "loss": 0.1389,
      "step": 16480
    },
    {
      "epoch": 0.0545,
      "grad_norm": 0.45118090510368347,
      "learning_rate": 2.340263283905331e-06,
      "loss": 0.1402,
      "step": 16490
    },
    {
      "step": 16500,
      "wer/bud500": 0.058818370508960154
    },
    {
      "step": 16500,
      "wer/private": 0.3404977375565611
    },
    {
      "epoch": 0.055,
      "grad_norm": 0.3441125154495239,
      "learning_rate": 2.3273177302425994e-06,
      "loss": 0.1405,
      "step": 16500
    },
    {
      "epoch": 0.055,
      "eval_loss": 0.08154145628213882,
      "eval_runtime": 199.6432,
      "eval_samples_per_second": 37.567,
      "eval_steps_per_second": 0.296,
      "step": 16500
    },
    {
      "epoch": 0.0555,
      "grad_norm": 0.40282440185546875,
      "learning_rate": 2.3144050692382868e-06,
      "loss": 0.1316,
      "step": 16510
    },
    {
      "epoch": 0.056,
      "grad_norm": 0.4399257302284241,
      "learning_rate": 2.301525334407931e-06,
      "loss": 0.1369,
      "step": 16520
    },
    {
      "epoch": 0.0565,
      "grad_norm": 0.40792930126190186,
      "learning_rate": 2.288678559181615e-06,
      "loss": 0.1463,
      "step": 16530
    },
    {
      "epoch": 0.057,
      "grad_norm": 0.3969045579433441,
      "learning_rate": 2.2758647769038572e-06,
      "loss": 0.1386,
      "step": 16540
    },
    {
      "step": 16550,
      "wer/bud500": 0.059037623878153596
    },
    {
      "step": 16550,
      "wer/private": 0.34728506787330315
    },
    {
      "epoch": 0.0575,
      "grad_norm": 0.39618799090385437,
      "learning_rate": 2.263084020833548e-06,
      "loss": 0.1338,
      "step": 16550
    },
    {
      "epoch": 0.058,
      "grad_norm": 0.4600697159767151,
      "learning_rate": 2.250336324143865e-06,
      "loss": 0.1249,
      "step": 16560
    },
    {
      "epoch": 0.0585,
      "grad_norm": 0.44783487915992737,
      "learning_rate": 2.2376217199221615e-06,
      "loss": 0.1325,
      "step": 16570
    },
    {
      "epoch": 0.059,
      "grad_norm": 0.48485544323921204,
      "learning_rate": 2.2249402411699155e-06,
      "loss": 0.1435,
      "step": 16580
    },
    {
      "epoch": 0.0595,
      "grad_norm": 0.5066445469856262,
      "learning_rate": 2.2122919208026136e-06,
      "loss": 0.1424,
      "step": 16590
    },
    {
      "step": 16600,
      "wer/bud500": 0.0591545590083901
    },
    {
      "step": 16600,
      "wer/private": 0.333710407239819
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.48167404532432556,
      "learning_rate": 2.1996767916496773e-06,
      "loss": 0.1424,
      "step": 16600
    },
    {
      "epoch": 0.06,
      "eval_loss": 0.08156473189592361,
      "eval_runtime": 199.4897,
      "eval_samples_per_second": 37.596,
      "eval_steps_per_second": 0.296,
      "step": 16600
    },
    {
      "epoch": 0.0605,
      "grad_norm": 0.5199468731880188,
      "learning_rate": 2.187094886454389e-06,
      "loss": 0.1418,
      "step": 16610
    },
    {
      "epoch": 0.061,
      "grad_norm": 0.4667356610298157,
      "learning_rate": 2.1745462378737852e-06,
      "loss": 0.1332,
      "step": 16620
    },
    {
      "epoch": 0.0615,
      "grad_norm": 0.4519345164299011,
      "learning_rate": 2.1620308784785908e-06,
      "loss": 0.1529,
      "step": 16630
    },
    {
      "epoch": 0.062,
      "grad_norm": 0.5268685817718506,
      "learning_rate": 2.1495488407531267e-06,
      "loss": 0.1332,
      "step": 16640
    },
    {
      "step": 16650,
      "wer/bud500": 0.0591545590083901
    },
    {
      "step": 16650,
      "wer/private": 0.3269230769230769
    },
    {
      "epoch": 0.0625,
      "grad_norm": 0.49337777495384216,
      "learning_rate": 2.1371001570952187e-06,
      "loss": 0.1377,
      "step": 16650
    },
    {
      "epoch": 0.063,
      "grad_norm": 0.4541933536529541,
      "learning_rate": 2.1246848598161205e-06,
      "loss": 0.1317,
      "step": 16660
    },
    {
      "epoch": 0.0635,
      "grad_norm": 0.546055018901825,
      "learning_rate": 2.112302981140442e-06,
      "loss": 0.1368,
      "step": 16670
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.41813454031944275,
      "learning_rate": 2.099954553206037e-06,
      "loss": 0.1428,
      "step": 16680
    },
    {
      "epoch": 0.0645,
      "grad_norm": 0.4554421901702881,
      "learning_rate": 2.087639608063951e-06,
      "loss": 0.139,
      "step": 16690
    },
    {
      "step": 16700,
      "wer/bud500": 0.058979156313035346
    },
    {
      "step": 16700,
      "wer/private": 0.3416289592760181
    },
    {
      "epoch": 0.065,
      "grad_norm": 0.45195716619491577,
      "learning_rate": 2.0753581776783115e-06,
      "loss": 0.144,
      "step": 16700
    },
    {
      "epoch": 0.065,
      "eval_loss": 0.08144643157720566,
      "eval_runtime": 199.2579,
      "eval_samples_per_second": 37.64,
      "eval_steps_per_second": 0.296,
      "step": 16700
    },
    {
      "epoch": 0.0655,
      "grad_norm": 0.42484188079833984,
      "learning_rate": 2.0631102939262565e-06,
      "loss": 0.1333,
      "step": 16710
    },
    {
      "epoch": 0.066,
      "grad_norm": 0.5890836715698242,
      "learning_rate": 2.0508959885978646e-06,
      "loss": 0.1322,
      "step": 16720
    },
    {
      "epoch": 0.0665,
      "grad_norm": 0.39565062522888184,
      "learning_rate": 2.038715293396043e-06,
      "loss": 0.1346,
      "step": 16730
    },
    {
      "epoch": 0.067,
      "grad_norm": 0.387591689825058,
      "learning_rate": 2.026568239936473e-06,
      "loss": 0.1408,
      "step": 16740
    },
    {
      "step": 16750,
      "wer/bud500": 0.05883298740023972
    },
    {
      "step": 16750,
      "wer/private": 0.3223981900452489
    },
    {
      "epoch": 0.0675,
      "grad_norm": 0.4419110417366028,
      "learning_rate": 2.0144548597475186e-06,
      "loss": 0.146,
      "step": 16750
    },
    {
      "epoch": 0.068,
      "grad_norm": 0.5386338829994202,
      "learning_rate": 2.0023751842701343e-06,
      "loss": 0.1326,
      "step": 16760
    },
    {
      "epoch": 0.0685,
      "grad_norm": 0.4792843163013458,
      "learning_rate": 1.9903292448577932e-06,
      "loss": 0.1418,
      "step": 16770
    },
    {
      "epoch": 0.069,
      "grad_norm": 0.42138805985450745,
      "learning_rate": 1.978317072776413e-06,
      "loss": 0.1448,
      "step": 16780
    },
    {
      "epoch": 0.0695,
      "grad_norm": 0.4532555639743805,
      "learning_rate": 1.9663386992042565e-06,
      "loss": 0.1291,
      "step": 16790
    },
    {
      "step": 16800,
      "wer/bud500": 0.05896453942175578
    },
    {
      "step": 16800,
      "wer/private": 0.3438914027149321
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4602344334125519,
      "learning_rate": 1.9543941552318693e-06,
      "loss": 0.1511,
      "step": 16800
    },
    {
      "epoch": 0.07,
      "eval_loss": 0.08164100348949432,
      "eval_runtime": 200.6942,
      "eval_samples_per_second": 37.37,
      "eval_steps_per_second": 0.294,
      "step": 16800
    },
    {
      "epoch": 0.0705,
      "grad_norm": 0.47992101311683655,
      "learning_rate": 1.9424834718619826e-06,
      "loss": 0.1473,
      "step": 16810
    },
    {
      "epoch": 0.071,
      "grad_norm": 0.4063290059566498,
      "learning_rate": 1.9306066800094417e-06,
      "loss": 0.1487,
      "step": 16820
    },
    {
      "epoch": 0.0715,
      "grad_norm": 0.5177678465843201,
      "learning_rate": 1.9187638105011347e-06,
      "loss": 0.1415,
      "step": 16830
    },
    {
      "epoch": 0.072,
      "grad_norm": 0.5352146029472351,
      "learning_rate": 1.9069548940758842e-06,
      "loss": 0.1444,
      "step": 16840
    },
    {
      "step": 16850,
      "wer/bud500": 0.0592714941386266
    },
    {
      "step": 16850,
      "wer/private": 0.32918552036199095
    },
    {
      "epoch": 0.0725,
      "grad_norm": 0.47866490483283997,
      "learning_rate": 1.8951799613844023e-06,
      "loss": 0.1342,
      "step": 16850
    },
    {
      "epoch": 0.073,
      "grad_norm": 0.41769710183143616,
      "learning_rate": 1.8834390429891884e-06,
      "loss": 0.1437,
      "step": 16860
    },
    {
      "epoch": 0.0735,
      "grad_norm": 0.3758358061313629,
      "learning_rate": 1.8717321693644558e-06,
      "loss": 0.1424,
      "step": 16870
    },
    {
      "epoch": 0.074,
      "grad_norm": 0.44293010234832764,
      "learning_rate": 1.860059370896046e-06,
      "loss": 0.1355,
      "step": 16880
    },
    {
      "epoch": 0.0745,
      "grad_norm": 0.5046011209487915,
      "learning_rate": 1.8484206778813711e-06,
      "loss": 0.1424,
      "step": 16890
    },
    {
      "step": 16900,
      "wer/bud500": 0.05870143537872365
    },
    {
      "step": 16900,
      "wer/private": 0.34728506787330315
    },
    {
      "epoch": 0.075,
      "grad_norm": 0.49778714776039124,
      "learning_rate": 1.8368161205293043e-06,
      "loss": 0.1423,
      "step": 16900
    },
    {
      "epoch": 0.075,
      "eval_loss": 0.08157408982515335,
      "eval_runtime": 200.404,
      "eval_samples_per_second": 37.424,
      "eval_steps_per_second": 0.294,
      "step": 16900
    },
    {
      "epoch": 0.0755,
      "grad_norm": 0.34431830048561096,
      "learning_rate": 1.8252457289601338e-06,
      "loss": 0.1395,
      "step": 16910
    },
    {
      "epoch": 0.076,
      "grad_norm": 0.41875702142715454,
      "learning_rate": 1.8137095332054583e-06,
      "loss": 0.1375,
      "step": 16920
    },
    {
      "epoch": 0.0765,
      "grad_norm": 0.36158183217048645,
      "learning_rate": 1.8022075632081159e-06,
      "loss": 0.1386,
      "step": 16930
    },
    {
      "epoch": 0.077,
      "grad_norm": 0.47814249992370605,
      "learning_rate": 1.7907398488221194e-06,
      "loss": 0.1394,
      "step": 16940
    },
    {
      "step": 16950,
      "wer/bud500": 0.059110708334551405
    },
    {
      "step": 16950,
      "wer/private": 0.332579185520362
    },
    {
      "epoch": 0.0775,
      "grad_norm": 0.5778689980506897,
      "learning_rate": 1.7793064198125692e-06,
      "loss": 0.1344,
      "step": 16950
    },
    {
      "epoch": 0.078,
      "grad_norm": 0.45824089646339417,
      "learning_rate": 1.7679073058555668e-06,
      "loss": 0.1336,
      "step": 16960
    },
    {
      "epoch": 0.0785,
      "grad_norm": 0.5713459849357605,
      "learning_rate": 1.7565425365381566e-06,
      "loss": 0.146,
      "step": 16970
    },
    {
      "epoch": 0.079,
      "grad_norm": 0.40413498878479004,
      "learning_rate": 1.7452121413582345e-06,
      "loss": 0.1478,
      "step": 16980
    },
    {
      "epoch": 0.0795,
      "grad_norm": 0.5169541835784912,
      "learning_rate": 1.7339161497244726e-06,
      "loss": 0.1373,
      "step": 16990
    },
    {
      "step": 17000,
      "wer/bud500": 0.05871605227000322
    },
    {
      "step": 17000,
      "wer/private": 0.32805429864253394
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4202563762664795,
      "learning_rate": 1.7226545909562596e-06,
      "loss": 0.1397,
      "step": 17000
    },
    {
      "epoch": 0.08,
      "eval_loss": 0.08159410208463669,
      "eval_runtime": 200.7345,
      "eval_samples_per_second": 37.363,
      "eval_steps_per_second": 0.294,
      "step": 17000
    },
    {
      "epoch": 0.0805,
      "grad_norm": 0.42792776226997375,
      "learning_rate": 1.7114274942835973e-06,
      "loss": 0.1407,
      "step": 17010
    },
    {
      "epoch": 0.081,
      "grad_norm": 0.39359545707702637,
      "learning_rate": 1.7002348888470454e-06,
      "loss": 0.1319,
      "step": 17020
    },
    {
      "epoch": 0.0815,
      "grad_norm": 0.3651849925518036,
      "learning_rate": 1.6890768036976505e-06,
      "loss": 0.1352,
      "step": 17030
    },
    {
      "epoch": 0.082,
      "grad_norm": 0.5870427489280701,
      "learning_rate": 1.677953267796833e-06,
      "loss": 0.1516,
      "step": 17040
    },
    {
      "step": 17050,
      "wer/bud500": 0.05912532522583097
    },
    {
      "step": 17050,
      "wer/private": 0.34502262443438914
    },
    {
      "epoch": 0.0825,
      "grad_norm": 0.3977659344673157,
      "learning_rate": 1.6668643100163638e-06,
      "loss": 0.1525,
      "step": 17050
    },
    {
      "epoch": 0.083,
      "grad_norm": 0.52769935131073,
      "learning_rate": 1.6558099591382569e-06,
      "loss": 0.143,
      "step": 17060
    },
    {
      "epoch": 0.0835,
      "grad_norm": 0.4228019118309021,
      "learning_rate": 1.6447902438546958e-06,
      "loss": 0.1437,
      "step": 17070
    },
    {
      "epoch": 0.084,
      "grad_norm": 0.3792698085308075,
      "learning_rate": 1.6338051927679742e-06,
      "loss": 0.1349,
      "step": 17080
    },
    {
      "epoch": 0.0845,
      "grad_norm": 0.4186464548110962,
      "learning_rate": 1.6228548343904098e-06,
      "loss": 0.1366,
      "step": 17090
    },
    {
      "step": 17100,
      "wer/bud500": 0.058993773204314905
    },
    {
      "step": 17100,
      "wer/private": 0.334841628959276
    },
    {
      "epoch": 0.085,
      "grad_norm": 0.5396271347999573,
      "learning_rate": 1.6119391971442653e-06,
      "loss": 0.136,
      "step": 17100
    },
    {
      "epoch": 0.085,
      "eval_loss": 0.08168274909257889,
      "eval_runtime": 199.0209,
      "eval_samples_per_second": 37.684,
      "eval_steps_per_second": 0.296,
      "step": 17100
    },
    {
      "epoch": 0.0855,
      "grad_norm": 0.41316890716552734,
      "learning_rate": 1.6010583093616992e-06,
      "loss": 0.1351,
      "step": 17110
    },
    {
      "epoch": 0.086,
      "grad_norm": 0.44012388586997986,
      "learning_rate": 1.5902121992846602e-06,
      "loss": 0.1323,
      "step": 17120
    },
    {
      "epoch": 0.0865,
      "grad_norm": 0.38606032729148865,
      "learning_rate": 1.5794008950648374e-06,
      "loss": 0.141,
      "step": 17130
    },
    {
      "epoch": 0.087,
      "grad_norm": 0.4583083689212799,
      "learning_rate": 1.5686244247635862e-06,
      "loss": 0.1408,
      "step": 17140
    },
    {
      "step": 17150,
      "wer/bud500": 0.0591545590083901
    },
    {
      "step": 17150,
      "wer/private": 0.33597285067873306
    },
    {
      "epoch": 0.0875,
      "grad_norm": 0.5787043571472168,
      "learning_rate": 1.5578828163518266e-06,
      "loss": 0.1414,
      "step": 17150
    },
    {
      "epoch": 0.088,
      "grad_norm": 0.35849207639694214,
      "learning_rate": 1.5471760977100135e-06,
      "loss": 0.1473,
      "step": 17160
    },
    {
      "epoch": 0.0885,
      "grad_norm": 0.4193483293056488,
      "learning_rate": 1.5365042966280374e-06,
      "loss": 0.1368,
      "step": 17170
    },
    {
      "epoch": 0.089,
      "grad_norm": 0.43161359429359436,
      "learning_rate": 1.5258674408051543e-06,
      "loss": 0.1295,
      "step": 17180
    },
    {
      "epoch": 0.0895,
      "grad_norm": 0.3928442597389221,
      "learning_rate": 1.5152655578499247e-06,
      "loss": 0.1244,
      "step": 17190
    },
    {
      "step": 17200,
      "wer/bud500": 0.05900839009559447
    },
    {
      "step": 17200,
      "wer/private": 0.3257918552036199
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4341435134410858,
      "learning_rate": 1.50469867528013e-06,
      "loss": 0.1494,
      "step": 17200
    },
    {
      "epoch": 0.09,
      "eval_loss": 0.08165978640317917,
      "eval_runtime": 200.0539,
      "eval_samples_per_second": 37.49,
      "eval_steps_per_second": 0.295,
      "step": 17200
    },
    {
      "epoch": 0.0905,
      "grad_norm": 0.43351978063583374,
      "learning_rate": 1.494166820522701e-06,
      "loss": 0.1387,
      "step": 17210
    },
    {
      "epoch": 0.091,
      "grad_norm": 0.35257473587989807,
      "learning_rate": 1.483670020913666e-06,
      "loss": 0.1391,
      "step": 17220
    },
    {
      "epoch": 0.0915,
      "grad_norm": 0.519032895565033,
      "learning_rate": 1.473208303698053e-06,
      "loss": 0.1519,
      "step": 17230
    },
    {
      "epoch": 0.092,
      "grad_norm": 0.5877243280410767,
      "learning_rate": 1.4627816960298379e-06,
      "loss": 0.1227,
      "step": 17240
    },
    {
      "step": 17250,
      "wer/bud500": 0.05894992253047622
    },
    {
      "step": 17250,
      "wer/private": 0.3257918552036199
    },
    {
      "epoch": 0.0925,
      "grad_norm": 0.46680933237075806,
      "learning_rate": 1.452390224971874e-06,
      "loss": 0.1459,
      "step": 17250
    },
    {
      "epoch": 0.093,
      "grad_norm": 0.48368149995803833,
      "learning_rate": 1.442033917495793e-06,
      "loss": 0.1412,
      "step": 17260
    },
    {
      "epoch": 0.0935,
      "grad_norm": 0.41503801941871643,
      "learning_rate": 1.4317128004819813e-06,
      "loss": 0.1348,
      "step": 17270
    },
    {
      "epoch": 0.094,
      "grad_norm": 0.6174643635749817,
      "learning_rate": 1.421426900719478e-06,
      "loss": 0.1425,
      "step": 17280
    },
    {
      "epoch": 0.0945,
      "grad_norm": 0.4588194489479065,
      "learning_rate": 1.4111762449059108e-06,
      "loss": 0.14,
      "step": 17290
    },
    {
      "step": 17300,
      "wer/bud500": 0.06250182711140995
    },
    {
      "step": 17300,
      "wer/private": 0.34502262443438914
    },
    {
      "epoch": 0.095,
      "grad_norm": 0.4349522888660431,
      "learning_rate": 1.400960859647435e-06,
      "loss": 0.1303,
      "step": 17300
    },
    {
      "epoch": 0.095,
      "eval_loss": 0.0815735012292862,
      "eval_runtime": 199.9129,
      "eval_samples_per_second": 37.516,
      "eval_steps_per_second": 0.295,
      "step": 17300
    },
    {
      "epoch": 0.0955,
      "grad_norm": 0.44678086042404175,
      "learning_rate": 1.3907807714586562e-06,
      "loss": 0.1369,
      "step": 17310
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.564490795135498,
      "learning_rate": 1.3806360067625617e-06,
      "loss": 0.1463,
      "step": 17320
    },
    {
      "epoch": 0.0965,
      "grad_norm": 0.39230287075042725,
      "learning_rate": 1.3705265918904619e-06,
      "loss": 0.1361,
      "step": 17330
    },
    {
      "epoch": 0.097,
      "grad_norm": 0.4266797602176666,
      "learning_rate": 1.3604525530819073e-06,
      "loss": 0.1453,
      "step": 17340
    },
    {
      "step": 17350,
      "wer/bud500": 0.05894992253047622
    },
    {
      "step": 17350,
      "wer/private": 0.333710407239819
    },
    {
      "epoch": 0.0975,
      "grad_norm": 0.41992127895355225,
      "learning_rate": 1.350413916484632e-06,
      "loss": 0.1362,
      "step": 17350
    },
    {
      "epoch": 0.098,
      "grad_norm": 0.48408693075180054,
      "learning_rate": 1.340410708154488e-06,
      "loss": 0.1384,
      "step": 17360
    },
    {
      "epoch": 0.0985,
      "grad_norm": 0.431144118309021,
      "learning_rate": 1.3304429540553536e-06,
      "loss": 0.1425,
      "step": 17370
    },
    {
      "epoch": 0.099,
      "grad_norm": 0.396365225315094,
      "learning_rate": 1.3205106800590982e-06,
      "loss": 0.154,
      "step": 17380
    },
    {
      "epoch": 0.0995,
      "grad_norm": 0.4638849198818207,
      "learning_rate": 1.3106139119455003e-06,
      "loss": 0.14,
      "step": 17390
    },
    {
      "step": 17400,
      "wer/bud500": 0.059096091443271846
    },
    {
      "step": 17400,
      "wer/private": 0.3382352941176471
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.44875720143318176,
      "learning_rate": 1.3007526754021732e-06,
      "loss": 0.1306,
      "step": 17400
    },
    {
      "epoch": 0.1,
      "eval_loss": 0.08162498474121094,
      "eval_runtime": 203.1791,
      "eval_samples_per_second": 36.913,
      "eval_steps_per_second": 0.29,
      "step": 17400
    },
    {
      "epoch": 0.1005,
      "grad_norm": 0.48181936144828796,
      "learning_rate": 1.2909269960245113e-06,
      "loss": 0.139,
      "step": 17410
    },
    {
      "epoch": 0.101,
      "grad_norm": 0.41176238656044006,
      "learning_rate": 1.2811368993156191e-06,
      "loss": 0.1349,
      "step": 17420
    },
    {
      "epoch": 0.1015,
      "grad_norm": 0.3759947717189789,
      "learning_rate": 1.271382410686237e-06,
      "loss": 0.13,
      "step": 17430
    },
    {
      "epoch": 0.102,
      "grad_norm": 0.44952845573425293,
      "learning_rate": 1.261663555454694e-06,
      "loss": 0.1398,
      "step": 17440
    },
    {
      "step": 17450,
      "wer/bud500": 0.05924226035606747
    },
    {
      "step": 17450,
      "wer/private": 0.3416289592760181
    },
    {
      "epoch": 0.1025,
      "grad_norm": 0.39382633566856384,
      "learning_rate": 1.2519803588468199e-06,
      "loss": 0.1306,
      "step": 17450
    },
    {
      "epoch": 0.103,
      "grad_norm": 0.38047677278518677,
      "learning_rate": 1.2423328459958966e-06,
      "loss": 0.1395,
      "step": 17460
    },
    {
      "epoch": 0.1035,
      "grad_norm": 0.6595961451530457,
      "learning_rate": 1.2327210419425904e-06,
      "loss": 0.1542,
      "step": 17470
    },
    {
      "epoch": 0.104,
      "grad_norm": 0.46339693665504456,
      "learning_rate": 1.2231449716348702e-06,
      "loss": 0.1351,
      "step": 17480
    },
    {
      "epoch": 0.1045,
      "grad_norm": 0.44993120431900024,
      "learning_rate": 1.2136046599279688e-06,
      "loss": 0.1448,
      "step": 17490
    },
    {
      "step": 17500,
      "wer/bud500": 0.05908147455199228
    },
    {
      "step": 17500,
      "wer/private": 0.33144796380090497
    },
    {
      "epoch": 0.105,
      "grad_norm": 0.3912886679172516,
      "learning_rate": 1.2041001315843015e-06,
      "loss": 0.1408,
      "step": 17500
    },
    {
      "epoch": 0.105,
      "eval_loss": 0.08150120079517365,
      "eval_runtime": 199.7506,
      "eval_samples_per_second": 37.547,
      "eval_steps_per_second": 0.295,
      "step": 17500
    },
    {
      "epoch": 0.1055,
      "grad_norm": 0.43344488739967346,
      "learning_rate": 1.1946314112734014e-06,
      "loss": 0.1363,
      "step": 17510
    },
    {
      "epoch": 0.106,
      "grad_norm": 0.48648083209991455,
      "learning_rate": 1.1851985235718694e-06,
      "loss": 0.1344,
      "step": 17520
    },
    {
      "epoch": 0.1065,
      "grad_norm": 0.4386769235134125,
      "learning_rate": 1.1758014929632922e-06,
      "loss": 0.1517,
      "step": 17530
    },
    {
      "epoch": 0.107,
      "grad_norm": 0.4274841547012329,
      "learning_rate": 1.1664403438381877e-06,
      "loss": 0.138,
      "step": 17540
    },
    {
      "step": 17550,
      "wer/bud500": 0.059096091443271846
    },
    {
      "step": 17550,
      "wer/private": 0.3223981900452489
    },
    {
      "epoch": 0.1075,
      "grad_norm": 0.4412008821964264,
      "learning_rate": 1.1571151004939484e-06,
      "loss": 0.1501,
      "step": 17550
    },
    {
      "epoch": 0.108,
      "grad_norm": 0.4028162956237793,
      "learning_rate": 1.1478257871347664e-06,
      "loss": 0.1401,
      "step": 17560
    },
    {
      "epoch": 0.1085,
      "grad_norm": 0.4191785156726837,
      "learning_rate": 1.1385724278715747e-06,
      "loss": 0.131,
      "step": 17570
    },
    {
      "epoch": 0.109,
      "grad_norm": 0.39339306950569153,
      "learning_rate": 1.129355046721985e-06,
      "loss": 0.1259,
      "step": 17580
    },
    {
      "epoch": 0.1095,
      "grad_norm": 0.4937504529953003,
      "learning_rate": 1.1201736676102343e-06,
      "loss": 0.1383,
      "step": 17590
    },
    {
      "step": 17600,
      "wer/bud500": 0.05913994211711053
    },
    {
      "step": 17600,
      "wer/private": 0.34615384615384615
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3882085382938385,
      "learning_rate": 1.1110283143670984e-06,
      "loss": 0.1399,
      "step": 17600
    },
    {
      "epoch": 0.11,
      "eval_loss": 0.08154024183750153,
      "eval_runtime": 202.514,
      "eval_samples_per_second": 37.034,
      "eval_steps_per_second": 0.291,
      "step": 17600
    },
    {
      "epoch": 0.1105,
      "grad_norm": 0.4548739790916443,
      "learning_rate": 1.1019190107298632e-06,
      "loss": 0.1315,
      "step": 17610
    },
    {
      "epoch": 0.111,
      "grad_norm": 0.478809118270874,
      "learning_rate": 1.0928457803422337e-06,
      "loss": 0.1513,
      "step": 17620
    },
    {
      "epoch": 0.1115,
      "grad_norm": 0.4232006371021271,
      "learning_rate": 1.0838086467542902e-06,
      "loss": 0.1214,
      "step": 17630
    },
    {
      "epoch": 0.112,
      "grad_norm": 0.4682060182094574,
      "learning_rate": 1.074807633422421e-06,
      "loss": 0.1337,
      "step": 17640
    },
    {
      "step": 17650,
      "wer/bud500": 0.05867220159616453
    },
    {
      "step": 17650,
      "wer/private": 0.32918552036199095
    },
    {
      "epoch": 0.1125,
      "grad_norm": 0.38933220505714417,
      "learning_rate": 1.0658427637092582e-06,
      "loss": 0.1275,
      "step": 17650
    },
    {
      "epoch": 0.113,
      "grad_norm": 0.4368017911911011,
      "learning_rate": 1.056914060883627e-06,
      "loss": 0.133,
      "step": 17660
    },
    {
      "epoch": 0.1135,
      "grad_norm": 0.4350563585758209,
      "learning_rate": 1.0480215481204792e-06,
      "loss": 0.1316,
      "step": 17670
    },
    {
      "epoch": 0.114,
      "grad_norm": 0.43387570977211,
      "learning_rate": 1.0391652485008284e-06,
      "loss": 0.143,
      "step": 17680
    },
    {
      "epoch": 0.1145,
      "grad_norm": 0.44363948702812195,
      "learning_rate": 1.0303451850116956e-06,
      "loss": 0.1388,
      "step": 17690
    },
    {
      "step": 17700,
      "wer/bud500": 0.0591545590083901
    },
    {
      "step": 17700,
      "wer/private": 0.3404977375565611
    },
    {
      "epoch": 0.115,
      "grad_norm": 0.356534481048584,
      "learning_rate": 1.0215613805460567e-06,
      "loss": 0.1362,
      "step": 17700
    },
    {
      "epoch": 0.115,
      "eval_loss": 0.08144626766443253,
      "eval_runtime": 199.1024,
      "eval_samples_per_second": 37.669,
      "eval_steps_per_second": 0.296,
      "step": 17700
    },
    {
      "epoch": 0.1155,
      "grad_norm": 0.43310922384262085,
      "learning_rate": 1.0128138579027625e-06,
      "loss": 0.1421,
      "step": 17710
    },
    {
      "epoch": 0.116,
      "grad_norm": 0.3729465901851654,
      "learning_rate": 1.0041026397865044e-06,
      "loss": 0.1367,
      "step": 17720
    },
    {
      "epoch": 0.1165,
      "grad_norm": 0.4440514147281647,
      "learning_rate": 9.954277488077328e-07,
      "loss": 0.134,
      "step": 17730
    },
    {
      "epoch": 0.117,
      "grad_norm": 0.38887834548950195,
      "learning_rate": 9.867892074826217e-07,
      "loss": 0.1349,
      "step": 17740
    },
    {
      "step": 17750,
      "wer/bud500": 0.05883298740023972
    },
    {
      "step": 17750,
      "wer/private": 0.34502262443438914
    },
    {
      "epoch": 0.1175,
      "grad_norm": 0.5449454188346863,
      "learning_rate": 9.781870382329872e-07,
      "loss": 0.1338,
      "step": 17750
    },
    {
      "epoch": 0.118,
      "grad_norm": 0.5088211297988892,
      "learning_rate": 9.69621263386239e-07,
      "loss": 0.1245,
      "step": 17760
    },
    {
      "epoch": 0.1185,
      "grad_norm": 0.5236010551452637,
      "learning_rate": 9.610919051753275e-07,
      "loss": 0.1431,
      "step": 17770
    },
    {
      "epoch": 0.119,
      "grad_norm": 0.4123004972934723,
      "learning_rate": 9.525989857386874e-07,
      "loss": 0.1313,
      "step": 17780
    },
    {
      "epoch": 0.1195,
      "grad_norm": 0.4021531045436859,
      "learning_rate": 9.44142527120162e-07,
      "loss": 0.125,
      "step": 17790
    },
    {
      "step": 17800,
      "wer/bud500": 0.058993773204314905
    },
    {
      "step": 17800,
      "wer/private": 0.333710407239819
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4167170226573944,
      "learning_rate": 9.357225512689637e-07,
      "loss": 0.1432,
      "step": 17800
    },
    {
      "epoch": 0.12,
      "eval_loss": 0.08147987723350525,
      "eval_runtime": 200.6891,
      "eval_samples_per_second": 37.371,
      "eval_steps_per_second": 0.294,
      "step": 17800
    },
    {
      "epoch": 0.1205,
      "grad_norm": 0.3672153055667877,
      "learning_rate": 9.273390800396175e-07,
      "loss": 0.1332,
      "step": 17810
    },
    {
      "epoch": 0.121,
      "grad_norm": 0.5152767896652222,
      "learning_rate": 9.189921351918889e-07,
      "loss": 0.1457,
      "step": 17820
    },
    {
      "epoch": 0.1215,
      "grad_norm": 0.5699465870857239,
      "learning_rate": 9.106817383907462e-07,
      "loss": 0.1381,
      "step": 17830
    },
    {
      "epoch": 0.122,
      "grad_norm": 0.38180771470069885,
      "learning_rate": 9.024079112062867e-07,
      "loss": 0.1301,
      "step": 17840
    },
    {
      "step": 17850,
      "wer/bud500": 0.059286111029906156
    },
    {
      "step": 17850,
      "wer/private": 0.32805429864253394
    },
    {
      "epoch": 0.1225,
      "grad_norm": 0.5073257088661194,
      "learning_rate": 8.941706751136969e-07,
      "loss": 0.1301,
      "step": 17850
    },
    {
      "epoch": 0.123,
      "grad_norm": 0.4895513653755188,
      "learning_rate": 8.859700514931846e-07,
      "loss": 0.1468,
      "step": 17860
    },
    {
      "epoch": 0.1235,
      "grad_norm": 0.48456698656082153,
      "learning_rate": 8.778060616299266e-07,
      "loss": 0.1466,
      "step": 17870
    },
    {
      "epoch": 0.124,
      "grad_norm": 0.39690741896629333,
      "learning_rate": 8.696787267140194e-07,
      "loss": 0.1311,
      "step": 17880
    },
    {
      "epoch": 0.1245,
      "grad_norm": 0.5045332908630371,
      "learning_rate": 8.61588067840417e-07,
      "loss": 0.1464,
      "step": 17890
    },
    {
      "step": 17900,
      "wer/bud500": 0.05884760429151928
    },
    {
      "step": 17900,
      "wer/private": 0.332579185520362
    },
    {
      "epoch": 0.125,
      "grad_norm": 0.4394564926624298,
      "learning_rate": 8.535341060088797e-07,
      "loss": 0.1383,
      "step": 17900
    },
    {
      "epoch": 0.125,
      "eval_loss": 0.08153853565454483,
      "eval_runtime": 198.8132,
      "eval_samples_per_second": 37.724,
      "eval_steps_per_second": 0.297,
      "step": 17900
    },
    {
      "epoch": 0.1255,
      "grad_norm": 0.420902818441391,
      "learning_rate": 8.455168621239157e-07,
      "loss": 0.1399,
      "step": 17910
    },
    {
      "epoch": 0.126,
      "grad_norm": 0.5237538814544678,
      "learning_rate": 8.375363569947325e-07,
      "loss": 0.1448,
      "step": 17920
    },
    {
      "epoch": 0.1265,
      "grad_norm": 0.4877059757709503,
      "learning_rate": 8.295926113351777e-07,
      "loss": 0.1576,
      "step": 17930
    },
    {
      "epoch": 0.127,
      "grad_norm": 0.34051021933555603,
      "learning_rate": 8.216856457636929e-07,
      "loss": 0.1255,
      "step": 17940
    },
    {
      "step": 17950,
      "wer/bud500": 0.05883298740023972
    },
    {
      "step": 17950,
      "wer/private": 0.33031674208144796
    },
    {
      "epoch": 0.1275,
      "grad_norm": 0.36276352405548096,
      "learning_rate": 8.138154808032483e-07,
      "loss": 0.1318,
      "step": 17950
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.37570619583129883,
      "learning_rate": 8.059821368813003e-07,
      "loss": 0.1355,
      "step": 17960
    },
    {
      "epoch": 0.1285,
      "grad_norm": 0.4176463484764099,
      "learning_rate": 7.981856343297317e-07,
      "loss": 0.1409,
      "step": 17970
    },
    {
      "epoch": 0.129,
      "grad_norm": 0.4105963408946991,
      "learning_rate": 7.904259933848035e-07,
      "loss": 0.1436,
      "step": 17980
    },
    {
      "epoch": 0.1295,
      "grad_norm": 0.4777938425540924,
      "learning_rate": 7.827032341870983e-07,
      "loss": 0.1271,
      "step": 17990
    },
    {
      "step": 18000,
      "wer/bud500": 0.058920688747917095
    },
    {
      "step": 18000,
      "wer/private": 0.33710407239819007
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5127959847450256,
      "learning_rate": 7.750173767814734e-07,
      "loss": 0.1448,
      "step": 18000
    },
    {
      "epoch": 0.13,
      "eval_loss": 0.08148647844791412,
      "eval_runtime": 198.3857,
      "eval_samples_per_second": 37.805,
      "eval_steps_per_second": 0.297,
      "step": 18000
    },
    {
      "epoch": 0.00025,
      "grad_norm": 0.5099536776542664,
      "learning_rate": 1.7662924380205018e-05,
      "loss": 0.1328,
      "step": 18010
    },
    {
      "epoch": 0.0005,
      "grad_norm": 0.47216102480888367,
      "learning_rate": 1.765118294182076e-05,
      "loss": 0.1494,
      "step": 18020
    },
    {
      "epoch": 0.00075,
      "grad_norm": 0.448875367641449,
      "learning_rate": 1.7639439826389527e-05,
      "loss": 0.1342,
      "step": 18030
    },
    {
      "epoch": 0.001,
      "grad_norm": 0.39731818437576294,
      "learning_rate": 1.7627695041339606e-05,
      "loss": 0.1247,
      "step": 18040
    },
    {
      "step": 18050,
      "wer/bud500": 0.05871605227000322
    },
    {
      "step": 18050,
      "wer/private": 0.3269230769230769
    },
    {
      "epoch": 0.00125,
      "grad_norm": 0.42088183760643005,
      "learning_rate": 1.761594859410034e-05,
      "loss": 0.137,
      "step": 18050
    },
    {
      "epoch": 0.0015,
      "grad_norm": 0.4636615514755249,
      "learning_rate": 1.7604200492102137e-05,
      "loss": 0.1458,
      "step": 18060
    },
    {
      "epoch": 0.00175,
      "grad_norm": 0.7408149838447571,
      "learning_rate": 1.7592450742776437e-05,
      "loss": 0.1455,
      "step": 18070
    },
    {
      "epoch": 0.002,
      "grad_norm": 0.4372638761997223,
      "learning_rate": 1.7580699353555726e-05,
      "loss": 0.1395,
      "step": 18080
    },
    {
      "epoch": 0.00225,
      "grad_norm": 0.48084455728530884,
      "learning_rate": 1.7568946331873522e-05,
      "loss": 0.1444,
      "step": 18090
    },
    {
      "step": 18100,
      "wer/bud500": 0.05930072792118572
    },
    {
      "step": 18100,
      "wer/private": 0.332579185520362
    },
    {
      "epoch": 0.0025,
      "grad_norm": 0.3889298737049103,
      "learning_rate": 1.7557191685164393e-05,
      "loss": 0.1374,
      "step": 18100
    },
    {
      "epoch": 0.0025,
      "eval_loss": 0.08172000199556351,
      "eval_runtime": 214.7244,
      "eval_samples_per_second": 34.928,
      "eval_steps_per_second": 0.275,
      "step": 18100
    },
    {
      "epoch": 0.00275,
      "grad_norm": 0.4518800973892212,
      "learning_rate": 1.7545435420863918e-05,
      "loss": 0.1323,
      "step": 18110
    },
    {
      "epoch": 0.003,
      "grad_norm": 0.481907457113266,
      "learning_rate": 1.7533677546408704e-05,
      "loss": 0.1237,
      "step": 18120
    },
    {
      "epoch": 0.00325,
      "grad_norm": 0.47891494631767273,
      "learning_rate": 1.7521918069236373e-05,
      "loss": 0.1607,
      "step": 18130
    },
    {
      "epoch": 0.0035,
      "grad_norm": 0.4266197979450226,
      "learning_rate": 1.7510156996785574e-05,
      "loss": 0.1373,
      "step": 18140
    },
    {
      "step": 18150,
      "wer/bud500": 0.05871605227000322
    },
    {
      "step": 18150,
      "wer/private": 0.3427601809954751
    },
    {
      "epoch": 0.00375,
      "grad_norm": 0.44942328333854675,
      "learning_rate": 1.7498394336495953e-05,
      "loss": 0.1306,
      "step": 18150
    },
    {
      "epoch": 0.004,
      "grad_norm": 0.44216006994247437,
      "learning_rate": 1.748663009580816e-05,
      "loss": 0.1427,
      "step": 18160
    },
    {
      "epoch": 0.00425,
      "grad_norm": 0.47111427783966064,
      "learning_rate": 1.747486428216385e-05,
      "loss": 0.1453,
      "step": 18170
    },
    {
      "epoch": 0.0045,
      "grad_norm": 0.4022250473499298,
      "learning_rate": 1.7463096903005672e-05,
      "loss": 0.1426,
      "step": 18180
    },
    {
      "epoch": 0.00475,
      "grad_norm": 0.4077517092227936,
      "learning_rate": 1.745132796577727e-05,
      "loss": 0.1362,
      "step": 18190
    },
    {
      "step": 18200,
      "wer/bud500": 0.058979156313035346
    },
    {
      "step": 18200,
      "wer/private": 0.3608597285067873
    },
    {
      "epoch": 0.005,
      "grad_norm": 0.38342025876045227,
      "learning_rate": 1.7439557477923257e-05,
      "loss": 0.1305,
      "step": 18200
    },
    {
      "epoch": 0.005,
      "eval_loss": 0.08172933012247086,
      "eval_runtime": 214.8943,
      "eval_samples_per_second": 34.901,
      "eval_steps_per_second": 0.275,
      "step": 18200
    },
    {
      "epoch": 0.00525,
      "grad_norm": 0.45392680168151855,
      "learning_rate": 1.7427785446889245e-05,
      "loss": 0.1374,
      "step": 18210
    },
    {
      "epoch": 0.0055,
      "grad_norm": 0.4179592430591583,
      "learning_rate": 1.7416011880121812e-05,
      "loss": 0.1252,
      "step": 18220
    },
    {
      "epoch": 0.00575,
      "grad_norm": 0.4045114815235138,
      "learning_rate": 1.7404236785068517e-05,
      "loss": 0.135,
      "step": 18230
    },
    {
      "epoch": 0.006,
      "grad_norm": 0.4498737156391144,
      "learning_rate": 1.7392460169177878e-05,
      "loss": 0.1422,
      "step": 18240
    },
    {
      "step": 18250,
      "wer/bud500": 0.05906685766071272
    },
    {
      "step": 18250,
      "wer/private": 0.34502262443438914
    },
    {
      "epoch": 0.00625,
      "grad_norm": 0.4476884603500366,
      "learning_rate": 1.7380682039899364e-05,
      "loss": 0.1399,
      "step": 18250
    },
    {
      "epoch": 0.0065,
      "grad_norm": 0.5070583820343018,
      "learning_rate": 1.7368902404683432e-05,
      "loss": 0.1462,
      "step": 18260
    },
    {
      "epoch": 0.00675,
      "grad_norm": 0.4047779142856598,
      "learning_rate": 1.735712127098146e-05,
      "loss": 0.1397,
      "step": 18270
    },
    {
      "epoch": 0.007,
      "grad_norm": 0.4756258428096771,
      "learning_rate": 1.7345338646245795e-05,
      "loss": 0.1238,
      "step": 18280
    },
    {
      "epoch": 0.00725,
      "grad_norm": 0.4661312401294708,
      "learning_rate": 1.7333554537929714e-05,
      "loss": 0.1418,
      "step": 18290
    },
    {
      "step": 18300,
      "wer/bud500": 0.059110708334551405
    },
    {
      "step": 18300,
      "wer/private": 0.3223981900452489
    },
    {
      "epoch": 0.0075,
      "grad_norm": 0.43883654475212097,
      "learning_rate": 1.7321768953487435e-05,
      "loss": 0.146,
      "step": 18300
    },
    {
      "epoch": 0.0075,
      "eval_loss": 0.08140602707862854,
      "eval_runtime": 215.2901,
      "eval_samples_per_second": 34.837,
      "eval_steps_per_second": 0.274,
      "step": 18300
    },
    {
      "epoch": 0.00775,
      "grad_norm": 0.4315374195575714,
      "learning_rate": 1.730998190037413e-05,
      "loss": 0.1364,
      "step": 18310
    },
    {
      "epoch": 0.008,
      "grad_norm": 0.4563857316970825,
      "learning_rate": 1.729819338604586e-05,
      "loss": 0.1376,
      "step": 18320
    },
    {
      "epoch": 0.00825,
      "grad_norm": 0.36788633465766907,
      "learning_rate": 1.7286403417959645e-05,
      "loss": 0.1349,
      "step": 18330
    },
    {
      "epoch": 0.0085,
      "grad_norm": 0.3961437940597534,
      "learning_rate": 1.7274612003573417e-05,
      "loss": 0.1304,
      "step": 18340
    },
    {
      "step": 18350,
      "wer/bud500": 0.058818370508960154
    },
    {
      "step": 18350,
      "wer/private": 0.3257918552036199
    },
    {
      "epoch": 0.00875,
      "grad_norm": 0.5422341823577881,
      "learning_rate": 1.726281915034601e-05,
      "loss": 0.141,
      "step": 18350
    },
    {
      "epoch": 0.009,
      "grad_norm": 0.5825538635253906,
      "learning_rate": 1.7251024865737177e-05,
      "loss": 0.1291,
      "step": 18360
    },
    {
      "epoch": 0.00925,
      "grad_norm": 0.5669077634811401,
      "learning_rate": 1.7239229157207575e-05,
      "loss": 0.1224,
      "step": 18370
    },
    {
      "epoch": 0.0095,
      "grad_norm": 0.4093775749206543,
      "learning_rate": 1.722743203221877e-05,
      "loss": 0.1391,
      "step": 18380
    },
    {
      "epoch": 0.00975,
      "grad_norm": 0.4267030358314514,
      "learning_rate": 1.7215633498233215e-05,
      "loss": 0.1381,
      "step": 18390
    },
    {
      "step": 18400,
      "wer/bud500": 0.05913994211711053
    },
    {
      "step": 18400,
      "wer/private": 0.36538461538461536
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.39914149045944214,
      "learning_rate": 1.7203833562714246e-05,
      "loss": 0.1386,
      "step": 18400
    },
    {
      "epoch": 0.01,
      "eval_loss": 0.08194704353809357,
      "eval_runtime": 213.2112,
      "eval_samples_per_second": 35.176,
      "eval_steps_per_second": 0.277,
      "step": 18400
    },
    {
      "epoch": 0.01025,
      "grad_norm": 0.4759214222431183,
      "learning_rate": 1.719203223312611e-05,
      "loss": 0.1289,
      "step": 18410
    },
    {
      "epoch": 0.0105,
      "grad_norm": 0.41773557662963867,
      "learning_rate": 1.7180229516933916e-05,
      "loss": 0.1319,
      "step": 18420
    },
    {
      "epoch": 0.01075,
      "grad_norm": 0.5375595092773438,
      "learning_rate": 1.716842542160365e-05,
      "loss": 0.1621,
      "step": 18430
    },
    {
      "epoch": 0.011,
      "grad_norm": 0.45226964354515076,
      "learning_rate": 1.715661995460218e-05,
      "loss": 0.1392,
      "step": 18440
    },
    {
      "step": 18450,
      "wer/bud500": 0.058979156313035346
    },
    {
      "step": 18450,
      "wer/private": 0.3201357466063348
    },
    {
      "epoch": 0.01125,
      "grad_norm": 0.40871429443359375,
      "learning_rate": 1.7144813123397238e-05,
      "loss": 0.1385,
      "step": 18450
    },
    {
      "epoch": 0.0115,
      "grad_norm": 0.4133869707584381,
      "learning_rate": 1.7133004935457418e-05,
      "loss": 0.1375,
      "step": 18460
    },
    {
      "epoch": 0.01175,
      "grad_norm": 0.40997838973999023,
      "learning_rate": 1.712119539825218e-05,
      "loss": 0.1473,
      "step": 18470
    },
    {
      "epoch": 0.012,
      "grad_norm": 0.46457502245903015,
      "learning_rate": 1.7109384519251816e-05,
      "loss": 0.1487,
      "step": 18480
    },
    {
      "epoch": 0.01225,
      "grad_norm": 0.3605928421020508,
      "learning_rate": 1.709757230592749e-05,
      "loss": 0.1266,
      "step": 18490
    },
    {
      "step": 18500,
      "wer/bud500": 0.059169175899669656
    },
    {
      "step": 18500,
      "wer/private": 0.32918552036199095
    },
    {
      "epoch": 0.0125,
      "grad_norm": 0.36915919184684753,
      "learning_rate": 1.7085758765751205e-05,
      "loss": 0.1421,
      "step": 18500
    },
    {
      "epoch": 0.0125,
      "eval_loss": 0.08138824254274368,
      "eval_runtime": 215.0359,
      "eval_samples_per_second": 34.878,
      "eval_steps_per_second": 0.274,
      "step": 18500
    },
    {
      "epoch": 0.01275,
      "grad_norm": 0.3261886239051819,
      "learning_rate": 1.707394390619579e-05,
      "loss": 0.1289,
      "step": 18510
    },
    {
      "epoch": 0.013,
      "grad_norm": 0.39732322096824646,
      "learning_rate": 1.7062127734734923e-05,
      "loss": 0.1294,
      "step": 18520
    },
    {
      "epoch": 0.01325,
      "grad_norm": 0.3765816390514374,
      "learning_rate": 1.7050310258843103e-05,
      "loss": 0.145,
      "step": 18530
    },
    {
      "epoch": 0.0135,
      "grad_norm": 0.47842374444007874,
      "learning_rate": 1.7038491485995665e-05,
      "loss": 0.1484,
      "step": 18540
    },
    {
      "step": 18550,
      "wer/bud500": 0.05883298740023972
    },
    {
      "step": 18550,
      "wer/private": 0.3257918552036199
    },
    {
      "epoch": 0.01375,
      "grad_norm": 0.4175087809562683,
      "learning_rate": 1.7026671423668755e-05,
      "loss": 0.1312,
      "step": 18550
    },
    {
      "epoch": 0.014,
      "grad_norm": 0.4084261357784271,
      "learning_rate": 1.7014850079339332e-05,
      "loss": 0.1254,
      "step": 18560
    },
    {
      "epoch": 0.01425,
      "grad_norm": 0.5017150044441223,
      "learning_rate": 1.7003027460485176e-05,
      "loss": 0.1363,
      "step": 18570
    },
    {
      "epoch": 0.0145,
      "grad_norm": 0.404841810464859,
      "learning_rate": 1.699120357458487e-05,
      "loss": 0.1374,
      "step": 18580
    },
    {
      "epoch": 0.01475,
      "grad_norm": 0.5472692251205444,
      "learning_rate": 1.6979378429117796e-05,
      "loss": 0.1353,
      "step": 18590
    },
    {
      "step": 18600,
      "wer/bud500": 0.059037623878153596
    },
    {
      "step": 18600,
      "wer/private": 0.33144796380090497
    },
    {
      "epoch": 0.015,
      "grad_norm": 0.4209418296813965,
      "learning_rate": 1.6967552031564126e-05,
      "loss": 0.1417,
      "step": 18600
    },
    {
      "epoch": 0.015,
      "eval_loss": 0.08146972209215164,
      "eval_runtime": 214.9369,
      "eval_samples_per_second": 34.894,
      "eval_steps_per_second": 0.274,
      "step": 18600
    },
    {
      "epoch": 0.01525,
      "grad_norm": 0.43377095460891724,
      "learning_rate": 1.6955724389404834e-05,
      "loss": 0.1442,
      "step": 18610
    },
    {
      "epoch": 0.0155,
      "grad_norm": 0.4094018042087555,
      "learning_rate": 1.694389551012169e-05,
      "loss": 0.114,
      "step": 18620
    },
    {
      "epoch": 0.01575,
      "grad_norm": 0.48615434765815735,
      "learning_rate": 1.6932065401197224e-05,
      "loss": 0.1307,
      "step": 18630
    },
    {
      "epoch": 0.016,
      "grad_norm": 0.4109220802783966,
      "learning_rate": 1.692023407011476e-05,
      "loss": 0.1152,
      "step": 18640
    },
    {
      "step": 18650,
      "wer/bud500": 0.05918379279094922
    },
    {
      "step": 18650,
      "wer/private": 0.33031674208144796
    },
    {
      "epoch": 0.01625,
      "grad_norm": 0.7088841795921326,
      "learning_rate": 1.690840152435839e-05,
      "loss": 0.1475,
      "step": 18650
    },
    {
      "epoch": 0.0165,
      "grad_norm": 0.35642391443252563,
      "learning_rate": 1.6896567771412973e-05,
      "loss": 0.1401,
      "step": 18660
    },
    {
      "epoch": 0.01675,
      "grad_norm": 0.4153648018836975,
      "learning_rate": 1.6884732818764136e-05,
      "loss": 0.135,
      "step": 18670
    },
    {
      "epoch": 0.017,
      "grad_norm": 0.43465277552604675,
      "learning_rate": 1.687289667389826e-05,
      "loss": 0.1347,
      "step": 18680
    },
    {
      "epoch": 0.01725,
      "grad_norm": 0.468757688999176,
      "learning_rate": 1.686105934430248e-05,
      "loss": 0.1507,
      "step": 18690
    },
    {
      "step": 18700,
      "wer/bud500": 0.05908147455199228
    },
    {
      "step": 18700,
      "wer/private": 0.3212669683257919
    },
    {
      "epoch": 0.0175,
      "grad_norm": 0.48539605736732483,
      "learning_rate": 1.6849220837464686e-05,
      "loss": 0.138,
      "step": 18700
    },
    {
      "epoch": 0.0175,
      "eval_loss": 0.08131725341081619,
      "eval_runtime": 214.7097,
      "eval_samples_per_second": 34.931,
      "eval_steps_per_second": 0.275,
      "step": 18700
    },
    {
      "epoch": 0.01775,
      "grad_norm": 0.4900396764278412,
      "learning_rate": 1.6837381160873512e-05,
      "loss": 0.14,
      "step": 18710
    },
    {
      "epoch": 0.018,
      "grad_norm": 0.38058096170425415,
      "learning_rate": 1.6825540322018324e-05,
      "loss": 0.1425,
      "step": 18720
    },
    {
      "epoch": 0.01825,
      "grad_norm": 0.39818528294563293,
      "learning_rate": 1.681369832838923e-05,
      "loss": 0.1357,
      "step": 18730
    },
    {
      "epoch": 0.0185,
      "grad_norm": 0.5354865789413452,
      "learning_rate": 1.6801855187477075e-05,
      "loss": 0.1354,
      "step": 18740
    },
    {
      "step": 18750,
      "wer/bud500": 0.059476130616540474
    },
    {
      "step": 18750,
      "wer/private": 0.3223981900452489
    },
    {
      "epoch": 0.01875,
      "grad_norm": 0.45171400904655457,
      "learning_rate": 1.6790010906773413e-05,
      "loss": 0.1429,
      "step": 18750
    },
    {
      "epoch": 0.019,
      "grad_norm": 0.40762796998023987,
      "learning_rate": 1.6778165493770524e-05,
      "loss": 0.1503,
      "step": 18760
    },
    {
      "epoch": 0.01925,
      "grad_norm": 0.4116610884666443,
      "learning_rate": 1.6766318955961427e-05,
      "loss": 0.1286,
      "step": 18770
    },
    {
      "epoch": 0.0195,
      "grad_norm": 0.39546483755111694,
      "learning_rate": 1.675447130083981e-05,
      "loss": 0.1432,
      "step": 18780
    },
    {
      "epoch": 0.01975,
      "grad_norm": 0.4467220604419708,
      "learning_rate": 1.6742622535900105e-05,
      "loss": 0.1305,
      "step": 18790
    },
    {
      "step": 18800,
      "wer/bud500": 0.05918379279094922
    },
    {
      "step": 18800,
      "wer/private": 0.3269230769230769
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.3872315585613251,
      "learning_rate": 1.6730772668637433e-05,
      "loss": 0.1301,
      "step": 18800
    },
    {
      "epoch": 0.02,
      "eval_loss": 0.08165586739778519,
      "eval_runtime": 214.7563,
      "eval_samples_per_second": 34.923,
      "eval_steps_per_second": 0.275,
      "step": 18800
    },
    {
      "epoch": 0.02025,
      "grad_norm": 0.3895999491214752,
      "learning_rate": 1.6718921706547604e-05,
      "loss": 0.1312,
      "step": 18810
    },
    {
      "epoch": 0.0205,
      "grad_norm": 0.5007812976837158,
      "learning_rate": 1.6707069657127134e-05,
      "loss": 0.1361,
      "step": 18820
    },
    {
      "epoch": 0.02075,
      "grad_norm": 0.3661775588989258,
      "learning_rate": 1.6695216527873223e-05,
      "loss": 0.1304,
      "step": 18830
    },
    {
      "epoch": 0.021,
      "grad_norm": 0.4661142826080322,
      "learning_rate": 1.6683362326283745e-05,
      "loss": 0.1474,
      "step": 18840
    },
    {
      "step": 18850,
      "wer/bud500": 0.05932996170374485
    },
    {
      "step": 18850,
      "wer/private": 0.3269230769230769
    },
    {
      "epoch": 0.02125,
      "grad_norm": 0.3996341824531555,
      "learning_rate": 1.6671507059857264e-05,
      "loss": 0.1375,
      "step": 18850
    },
    {
      "epoch": 0.0215,
      "grad_norm": 0.5235641598701477,
      "learning_rate": 1.6659650736093013e-05,
      "loss": 0.1377,
      "step": 18860
    },
    {
      "epoch": 0.02175,
      "grad_norm": 0.36821022629737854,
      "learning_rate": 1.6647793362490895e-05,
      "loss": 0.13,
      "step": 18870
    },
    {
      "epoch": 0.022,
      "grad_norm": 0.5086722373962402,
      "learning_rate": 1.6635934946551472e-05,
      "loss": 0.1484,
      "step": 18880
    },
    {
      "epoch": 0.02225,
      "grad_norm": 0.40788453817367554,
      "learning_rate": 1.662407549577597e-05,
      "loss": 0.1406,
      "step": 18890
    },
    {
      "step": 18900,
      "wer/bud500": 0.05873066916128278
    },
    {
      "step": 18900,
      "wer/private": 0.3212669683257919
    },
    {
      "epoch": 0.0225,
      "grad_norm": 0.4980223476886749,
      "learning_rate": 1.661221501766628e-05,
      "loss": 0.1302,
      "step": 18900
    },
    {
      "epoch": 0.0225,
      "eval_loss": 0.08157870173454285,
      "eval_runtime": 215.1938,
      "eval_samples_per_second": 34.852,
      "eval_steps_per_second": 0.274,
      "step": 18900
    },
    {
      "epoch": 0.02275,
      "grad_norm": 0.45251354575157166,
      "learning_rate": 1.660035351972491e-05,
      "loss": 0.1322,
      "step": 18910
    },
    {
      "epoch": 0.023,
      "grad_norm": 0.4138983190059662,
      "learning_rate": 1.6588491009455054e-05,
      "loss": 0.133,
      "step": 18920
    },
    {
      "epoch": 0.02325,
      "grad_norm": 0.42496028542518616,
      "learning_rate": 1.6576627494360517e-05,
      "loss": 0.1466,
      "step": 18930
    },
    {
      "epoch": 0.0235,
      "grad_norm": 0.35277268290519714,
      "learning_rate": 1.6564762981945757e-05,
      "loss": 0.134,
      "step": 18940
    },
    {
      "step": 18950,
      "wer/bud500": 0.05846756511825065
    },
    {
      "step": 18950,
      "wer/private": 0.3212669683257919
    },
    {
      "epoch": 0.02375,
      "grad_norm": 0.5085467100143433,
      "learning_rate": 1.6552897479715853e-05,
      "loss": 0.1404,
      "step": 18950
    },
    {
      "epoch": 0.024,
      "grad_norm": 0.43703824281692505,
      "learning_rate": 1.6541030995176504e-05,
      "loss": 0.1442,
      "step": 18960
    },
    {
      "epoch": 0.02425,
      "grad_norm": 0.39945292472839355,
      "learning_rate": 1.6529163535834052e-05,
      "loss": 0.1424,
      "step": 18970
    },
    {
      "epoch": 0.0245,
      "grad_norm": 0.42674192786216736,
      "learning_rate": 1.6517295109195444e-05,
      "loss": 0.1283,
      "step": 18980
    },
    {
      "epoch": 0.02475,
      "grad_norm": 0.5566567182540894,
      "learning_rate": 1.650542572276822e-05,
      "loss": 0.1319,
      "step": 18990
    },
    {
      "step": 19000,
      "wer/bud500": 0.05865758470488496
    },
    {
      "step": 19000,
      "wer/private": 0.3416289592760181
    },
    {
      "epoch": 0.025,
      "grad_norm": 0.53135746717453,
      "learning_rate": 1.6493555384060565e-05,
      "loss": 0.1426,
      "step": 19000
    },
    {
      "epoch": 0.025,
      "eval_loss": 0.08156517893075943,
      "eval_runtime": 219.7538,
      "eval_samples_per_second": 34.129,
      "eval_steps_per_second": 0.268,
      "step": 19000
    },
    {
      "epoch": 0.02525,
      "grad_norm": 0.37829238176345825,
      "learning_rate": 1.6481684100581237e-05,
      "loss": 0.1336,
      "step": 19010
    },
    {
      "epoch": 0.0255,
      "grad_norm": 0.46123743057250977,
      "learning_rate": 1.64698118798396e-05,
      "loss": 0.1394,
      "step": 19020
    },
    {
      "epoch": 0.02575,
      "grad_norm": 0.48333072662353516,
      "learning_rate": 1.6457938729345615e-05,
      "loss": 0.1397,
      "step": 19030
    },
    {
      "epoch": 0.026,
      "grad_norm": 0.4189828634262085,
      "learning_rate": 1.6446064656609827e-05,
      "loss": 0.1243,
      "step": 19040
    },
    {
      "step": 19050,
      "wer/bud500": 0.05861373403104628
    },
    {
      "step": 19050,
      "wer/private": 0.32918552036199095
    },
    {
      "epoch": 0.02625,
      "grad_norm": 0.46860912442207336,
      "learning_rate": 1.643418966914336e-05,
      "loss": 0.1428,
      "step": 19050
    },
    {
      "epoch": 0.0265,
      "grad_norm": 0.4692303240299225,
      "learning_rate": 1.6422313774457934e-05,
      "loss": 0.1488,
      "step": 19060
    },
    {
      "epoch": 0.02675,
      "grad_norm": 0.47194528579711914,
      "learning_rate": 1.6410436980065814e-05,
      "loss": 0.1382,
      "step": 19070
    },
    {
      "epoch": 0.027,
      "grad_norm": 0.3837478756904602,
      "learning_rate": 1.6399747102073057e-05,
      "loss": 0.1248,
      "step": 19080
    },
    {
      "epoch": 0.02725,
      "grad_norm": 0.4923778176307678,
      "learning_rate": 1.638786861893661e-05,
      "loss": 0.1423,
      "step": 19090
    },
    {
      "step": 19100,
      "wer/bud500": 0.05870143537872365
    },
    {
      "step": 19100,
      "wer/private": 0.33144796380090497
    },
    {
      "epoch": 0.0275,
      "grad_norm": 0.4260939061641693,
      "learning_rate": 1.6375989257882298e-05,
      "loss": 0.1413,
      "step": 19100
    },
    {
      "epoch": 0.0275,
      "eval_loss": 0.08111520111560822,
      "eval_runtime": 214.4683,
      "eval_samples_per_second": 34.97,
      "eval_steps_per_second": 0.275,
      "step": 19100
    },
    {
      "epoch": 0.02775,
      "grad_norm": 0.4465072751045227,
      "learning_rate": 1.6364109026424595e-05,
      "loss": 0.1327,
      "step": 19110
    },
    {
      "epoch": 0.028,
      "grad_norm": 0.4129193425178528,
      "learning_rate": 1.6352227932078528e-05,
      "loss": 0.1389,
      "step": 19120
    },
    {
      "epoch": 0.02825,
      "grad_norm": 0.43754392862319946,
      "learning_rate": 1.6340345982359657e-05,
      "loss": 0.1496,
      "step": 19130
    },
    {
      "epoch": 0.0285,
      "grad_norm": 0.4391268789768219,
      "learning_rate": 1.6328463184784107e-05,
      "loss": 0.1446,
      "step": 19140
    },
    {
      "step": 19150,
      "wer/bud500": 0.05878913672640103
    },
    {
      "step": 19150,
      "wer/private": 0.3223981900452489
    },
    {
      "epoch": 0.02875,
      "grad_norm": 0.42872264981269836,
      "learning_rate": 1.6316579546868528e-05,
      "loss": 0.1376,
      "step": 19150
    },
    {
      "epoch": 0.029,
      "grad_norm": 0.3887803256511688,
      "learning_rate": 1.6304695076130084e-05,
      "loss": 0.1274,
      "step": 19160
    },
    {
      "epoch": 0.02925,
      "grad_norm": 0.35843074321746826,
      "learning_rate": 1.6292809780086494e-05,
      "loss": 0.1266,
      "step": 19170
    },
    {
      "epoch": 0.0295,
      "grad_norm": 0.46659785509109497,
      "learning_rate": 1.628092366625598e-05,
      "loss": 0.1377,
      "step": 19180
    },
    {
      "epoch": 0.02975,
      "grad_norm": 0.4622960090637207,
      "learning_rate": 1.62690367421573e-05,
      "loss": 0.1413,
      "step": 19190
    },
    {
      "step": 19200,
      "wer/bud500": 0.05858450024848715
    },
    {
      "step": 19200,
      "wer/private": 0.33144796380090497
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4965042471885681,
      "learning_rate": 1.6257149015309705e-05,
      "loss": 0.1443,
      "step": 19200
    },
    {
      "epoch": 0.03,
      "eval_loss": 0.08126692473888397,
      "eval_runtime": 214.6823,
      "eval_samples_per_second": 34.935,
      "eval_steps_per_second": 0.275,
      "step": 19200
    },
    {
      "epoch": 0.03025,
      "grad_norm": 0.5067917704582214,
      "learning_rate": 1.6245260493232946e-05,
      "loss": 0.1447,
      "step": 19210
    },
    {
      "epoch": 0.0305,
      "grad_norm": 0.5166449546813965,
      "learning_rate": 1.6233371183447323e-05,
      "loss": 0.1395,
      "step": 19220
    },
    {
      "epoch": 0.03075,
      "grad_norm": 0.44124463200569153,
      "learning_rate": 1.6221481093473584e-05,
      "loss": 0.1366,
      "step": 19230
    },
    {
      "epoch": 0.031,
      "grad_norm": 0.4675871431827545,
      "learning_rate": 1.620959023083299e-05,
      "loss": 0.1279,
      "step": 19240
    },
    {
      "step": 19250,
      "wer/bud500": 0.05890607185663753
    },
    {
      "step": 19250,
      "wer/private": 0.3212669683257919
    },
    {
      "epoch": 0.03125,
      "grad_norm": 0.5212311148643494,
      "learning_rate": 1.6197698603047296e-05,
      "loss": 0.1373,
      "step": 19250
    },
    {
      "epoch": 0.0315,
      "grad_norm": 0.48211851716041565,
      "learning_rate": 1.6185806217638736e-05,
      "loss": 0.1268,
      "step": 19260
    },
    {
      "epoch": 0.03175,
      "grad_norm": 0.5132243633270264,
      "learning_rate": 1.6173913082130022e-05,
      "loss": 0.1412,
      "step": 19270
    },
    {
      "epoch": 0.032,
      "grad_norm": 0.44897961616516113,
      "learning_rate": 1.6162019204044346e-05,
      "loss": 0.1371,
      "step": 19280
    },
    {
      "epoch": 0.03225,
      "grad_norm": 0.44296643137931824,
      "learning_rate": 1.6150124590905355e-05,
      "loss": 0.1408,
      "step": 19290
    },
    {
      "step": 19300,
      "wer/bud500": 0.05894992253047622
    },
    {
      "step": 19300,
      "wer/private": 0.3223981900452489
    },
    {
      "epoch": 0.0325,
      "grad_norm": 0.5020045638084412,
      "learning_rate": 1.6138229250237185e-05,
      "loss": 0.1471,
      "step": 19300
    },
    {
      "epoch": 0.0325,
      "eval_loss": 0.08125212788581848,
      "eval_runtime": 215.8254,
      "eval_samples_per_second": 34.75,
      "eval_steps_per_second": 0.273,
      "step": 19300
    },
    {
      "epoch": 0.03275,
      "grad_norm": 0.4389316141605377,
      "learning_rate": 1.6126333189564407e-05,
      "loss": 0.1371,
      "step": 19310
    },
    {
      "epoch": 0.033,
      "grad_norm": 0.47259411215782166,
      "learning_rate": 1.6114436416412067e-05,
      "loss": 0.136,
      "step": 19320
    },
    {
      "epoch": 0.03325,
      "grad_norm": 0.40308889746665955,
      "learning_rate": 1.6102538938305644e-05,
      "loss": 0.1309,
      "step": 19330
    },
    {
      "epoch": 0.0335,
      "grad_norm": 0.4034695327281952,
      "learning_rate": 1.6090640762771083e-05,
      "loss": 0.1259,
      "step": 19340
    },
    {
      "step": 19350,
      "wer/bud500": 0.05883298740023972
    },
    {
      "step": 19350,
      "wer/private": 0.3269230769230769
    },
    {
      "epoch": 0.03375,
      "grad_norm": 0.45767420530319214,
      "learning_rate": 1.607874189733476e-05,
      "loss": 0.1434,
      "step": 19350
    },
    {
      "epoch": 0.034,
      "grad_norm": 0.4109691381454468,
      "learning_rate": 1.6066842349523475e-05,
      "loss": 0.1419,
      "step": 19360
    },
    {
      "epoch": 0.03425,
      "grad_norm": 0.5042696595191956,
      "learning_rate": 1.6054942126864484e-05,
      "loss": 0.1335,
      "step": 19370
    },
    {
      "epoch": 0.0345,
      "grad_norm": 0.42818522453308105,
      "learning_rate": 1.6043041236885457e-05,
      "loss": 0.1367,
      "step": 19380
    },
    {
      "epoch": 0.03475,
      "grad_norm": 0.4640502631664276,
      "learning_rate": 1.603113968711448e-05,
      "loss": 0.1223,
      "step": 19390
    },
    {
      "step": 19400,
      "wer/bud500": 0.0585260326833689
    },
    {
      "step": 19400,
      "wer/private": 0.3178733031674208
    },
    {
      "epoch": 0.035,
      "grad_norm": 0.43053606152534485,
      "learning_rate": 1.601923748508007e-05,
      "loss": 0.1444,
      "step": 19400
    },
    {
      "epoch": 0.035,
      "eval_loss": 0.08121130615472794,
      "eval_runtime": 214.8787,
      "eval_samples_per_second": 34.903,
      "eval_steps_per_second": 0.275,
      "step": 19400
    },
    {
      "epoch": 0.03525,
      "grad_norm": 0.48499536514282227,
      "learning_rate": 1.6007334638311145e-05,
      "loss": 0.1415,
      "step": 19410
    },
    {
      "epoch": 0.0355,
      "grad_norm": 0.44810348749160767,
      "learning_rate": 1.5995431154337034e-05,
      "loss": 0.1479,
      "step": 19420
    },
    {
      "epoch": 0.03575,
      "grad_norm": 0.4537268280982971,
      "learning_rate": 1.5983527040687483e-05,
      "loss": 0.1417,
      "step": 19430
    },
    {
      "epoch": 0.036,
      "grad_norm": 0.48975473642349243,
      "learning_rate": 1.597162230489261e-05,
      "loss": 0.14,
      "step": 19440
    },
    {
      "step": 19450,
      "wer/bud500": 0.05896453942175578
    },
    {
      "step": 19450,
      "wer/private": 0.3065610859728507
    },
    {
      "epoch": 0.03625,
      "grad_norm": 0.45474982261657715,
      "learning_rate": 1.5959716954482945e-05,
      "loss": 0.1347,
      "step": 19450
    },
    {
      "epoch": 0.0365,
      "grad_norm": 0.437430202960968,
      "learning_rate": 1.594781099698941e-05,
      "loss": 0.138,
      "step": 19460
    },
    {
      "epoch": 0.03675,
      "grad_norm": 0.3726610541343689,
      "learning_rate": 1.5935904439943294e-05,
      "loss": 0.1361,
      "step": 19470
    },
    {
      "epoch": 0.037,
      "grad_norm": 0.4119448661804199,
      "learning_rate": 1.5923997290876278e-05,
      "loss": 0.1313,
      "step": 19480
    },
    {
      "epoch": 0.03725,
      "grad_norm": 0.4595460295677185,
      "learning_rate": 1.591208955732041e-05,
      "loss": 0.1435,
      "step": 19490
    },
    {
      "step": 19500,
      "wer/bud500": 0.05865758470488496
    },
    {
      "step": 19500,
      "wer/private": 0.3178733031674208
    },
    {
      "epoch": 0.0375,
      "grad_norm": 0.4971861243247986,
      "learning_rate": 1.590018124680812e-05,
      "loss": 0.1392,
      "step": 19500
    },
    {
      "epoch": 0.0375,
      "eval_loss": 0.08123450726270676,
      "eval_runtime": 217.3201,
      "eval_samples_per_second": 34.511,
      "eval_steps_per_second": 0.271,
      "step": 19500
    },
    {
      "epoch": 0.03775,
      "grad_norm": 0.3444761335849762,
      "learning_rate": 1.5888272366872194e-05,
      "loss": 0.1407,
      "step": 19510
    },
    {
      "epoch": 0.038,
      "grad_norm": 0.4879971742630005,
      "learning_rate": 1.5876362925045775e-05,
      "loss": 0.1406,
      "step": 19520
    },
    {
      "epoch": 0.03825,
      "grad_norm": 0.3388258218765259,
      "learning_rate": 1.586445292886236e-05,
      "loss": 0.1355,
      "step": 19530
    },
    {
      "epoch": 0.0385,
      "grad_norm": 0.4582117795944214,
      "learning_rate": 1.585254238585582e-05,
      "loss": 0.1458,
      "step": 19540
    },
    {
      "step": 19550,
      "wer/bud500": 0.05877451983512147
    },
    {
      "step": 19550,
      "wer/private": 0.3438914027149321
    },
    {
      "epoch": 0.03875,
      "grad_norm": 0.39892834424972534,
      "learning_rate": 1.5840631303560332e-05,
      "loss": 0.1327,
      "step": 19550
    },
    {
      "epoch": 0.039,
      "grad_norm": 0.5728124976158142,
      "learning_rate": 1.5828719689510455e-05,
      "loss": 0.1295,
      "step": 19560
    },
    {
      "epoch": 0.03925,
      "grad_norm": 0.5671640634536743,
      "learning_rate": 1.5816807551241056e-05,
      "loss": 0.149,
      "step": 19570
    },
    {
      "epoch": 0.0395,
      "grad_norm": 0.44571560621261597,
      "learning_rate": 1.580489489628734e-05,
      "loss": 0.1504,
      "step": 19580
    },
    {
      "epoch": 0.03975,
      "grad_norm": 0.476070761680603,
      "learning_rate": 1.5792981732184852e-05,
      "loss": 0.1309,
      "step": 19590
    },
    {
      "step": 19600,
      "wer/bud500": 0.05902300698687403
    },
    {
      "step": 19600,
      "wer/private": 0.3393665158371041
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4272719919681549,
      "learning_rate": 1.5781068066469443e-05,
      "loss": 0.1356,
      "step": 19600
    },
    {
      "epoch": 0.04,
      "eval_loss": 0.08138459175825119,
      "eval_runtime": 215.2419,
      "eval_samples_per_second": 34.845,
      "eval_steps_per_second": 0.274,
      "step": 19600
    },
    {
      "epoch": 0.04025,
      "grad_norm": 0.5151489973068237,
      "learning_rate": 1.5769153906677287e-05,
      "loss": 0.1238,
      "step": 19610
    },
    {
      "epoch": 0.0405,
      "grad_norm": 0.4687056541442871,
      "learning_rate": 1.5757239260344876e-05,
      "loss": 0.1413,
      "step": 19620
    },
    {
      "epoch": 0.04075,
      "grad_norm": 0.3626600205898285,
      "learning_rate": 1.5745324135008997e-05,
      "loss": 0.1236,
      "step": 19630
    },
    {
      "epoch": 0.041,
      "grad_norm": 0.5716000199317932,
      "learning_rate": 1.5733408538206757e-05,
      "loss": 0.1403,
      "step": 19640
    },
    {
      "step": 19650,
      "wer/bud500": 0.05878913672640103
    },
    {
      "step": 19650,
      "wer/private": 0.32805429864253394
    },
    {
      "epoch": 0.04125,
      "grad_norm": 0.38225677609443665,
      "learning_rate": 1.5721492477475545e-05,
      "loss": 0.1467,
      "step": 19650
    },
    {
      "epoch": 0.0415,
      "grad_norm": 0.38770899176597595,
      "learning_rate": 1.570957596035305e-05,
      "loss": 0.1431,
      "step": 19660
    },
    {
      "epoch": 0.04175,
      "grad_norm": 0.4992160201072693,
      "learning_rate": 1.5697658994377258e-05,
      "loss": 0.1365,
      "step": 19670
    },
    {
      "epoch": 0.042,
      "grad_norm": 0.4203382134437561,
      "learning_rate": 1.568574158708642e-05,
      "loss": 0.1312,
      "step": 19680
    },
    {
      "epoch": 0.04225,
      "grad_norm": 0.45363596081733704,
      "learning_rate": 1.5673823746019083e-05,
      "loss": 0.141,
      "step": 19690
    },
    {
      "step": 19700,
      "wer/bud500": 0.058745286052562344
    },
    {
      "step": 19700,
      "wer/private": 0.3156108597285068
    },
    {
      "epoch": 0.0425,
      "grad_norm": 0.43645381927490234,
      "learning_rate": 1.5661905478714067e-05,
      "loss": 0.1357,
      "step": 19700
    },
    {
      "epoch": 0.0425,
      "eval_loss": 0.08118661493062973,
      "eval_runtime": 211.2351,
      "eval_samples_per_second": 35.505,
      "eval_steps_per_second": 0.279,
      "step": 19700
    },
    {
      "epoch": 0.04275,
      "grad_norm": 0.40918728709220886,
      "learning_rate": 1.5649986792710447e-05,
      "loss": 0.1269,
      "step": 19710
    },
    {
      "epoch": 0.043,
      "grad_norm": 0.5099054574966431,
      "learning_rate": 1.5638067695547584e-05,
      "loss": 0.1372,
      "step": 19720
    },
    {
      "epoch": 0.04325,
      "grad_norm": 0.3759796917438507,
      "learning_rate": 1.562614819476508e-05,
      "loss": 0.135,
      "step": 19730
    },
    {
      "epoch": 0.0435,
      "grad_norm": 0.42475512623786926,
      "learning_rate": 1.5614228297902802e-05,
      "loss": 0.1333,
      "step": 19740
    },
    {
      "step": 19750,
      "wer/bud500": 0.05894992253047622
    },
    {
      "step": 19750,
      "wer/private": 0.3212669683257919
    },
    {
      "epoch": 0.04375,
      "grad_norm": 0.4904419481754303,
      "learning_rate": 1.560230801250087e-05,
      "loss": 0.1406,
      "step": 19750
    },
    {
      "epoch": 0.044,
      "grad_norm": 0.38725119829177856,
      "learning_rate": 1.559038734609964e-05,
      "loss": 0.139,
      "step": 19760
    },
    {
      "epoch": 0.04425,
      "grad_norm": 0.5715628862380981,
      "learning_rate": 1.557846630623972e-05,
      "loss": 0.1448,
      "step": 19770
    },
    {
      "epoch": 0.0445,
      "grad_norm": 0.3816949427127838,
      "learning_rate": 1.556654490046195e-05,
      "loss": 0.1225,
      "step": 19780
    },
    {
      "epoch": 0.04475,
      "grad_norm": 0.3837215304374695,
      "learning_rate": 1.5554623136307393e-05,
      "loss": 0.1331,
      "step": 19790
    },
    {
      "step": 19800,
      "wer/bud500": 0.05846756511825065
    },
    {
      "step": 19800,
      "wer/private": 0.3235294117647059
    },
    {
      "epoch": 0.045,
      "grad_norm": 0.47285977005958557,
      "learning_rate": 1.554270102131735e-05,
      "loss": 0.1347,
      "step": 19800
    },
    {
      "epoch": 0.045,
      "eval_loss": 0.0811767652630806,
      "eval_runtime": 206.1208,
      "eval_samples_per_second": 36.386,
      "eval_steps_per_second": 0.286,
      "step": 19800
    },
    {
      "epoch": 0.04525,
      "grad_norm": 0.48670271039009094,
      "learning_rate": 1.5530778563033344e-05,
      "loss": 0.1313,
      "step": 19810
    },
    {
      "epoch": 0.0455,
      "grad_norm": 0.37759721279144287,
      "learning_rate": 1.5518855768997108e-05,
      "loss": 0.1475,
      "step": 19820
    },
    {
      "epoch": 0.04575,
      "grad_norm": 0.47206321358680725,
      "learning_rate": 1.5506932646750594e-05,
      "loss": 0.1522,
      "step": 19830
    },
    {
      "epoch": 0.046,
      "grad_norm": 0.666671633720398,
      "learning_rate": 1.549500920383595e-05,
      "loss": 0.1375,
      "step": 19840
    },
    {
      "step": 19850,
      "wer/bud500": 0.058628350922325836
    },
    {
      "step": 19850,
      "wer/private": 0.3088235294117647
    },
    {
      "epoch": 0.04625,
      "grad_norm": 0.48451465368270874,
      "learning_rate": 1.548308544779554e-05,
      "loss": 0.138,
      "step": 19850
    },
    {
      "epoch": 0.0465,
      "grad_norm": 0.4309198260307312,
      "learning_rate": 1.5471161386171925e-05,
      "loss": 0.1357,
      "step": 19860
    },
    {
      "epoch": 0.04675,
      "grad_norm": 0.4138578772544861,
      "learning_rate": 1.545923702650785e-05,
      "loss": 0.139,
      "step": 19870
    },
    {
      "epoch": 0.047,
      "grad_norm": 0.43407881259918213,
      "learning_rate": 1.5447312376346256e-05,
      "loss": 0.1337,
      "step": 19880
    },
    {
      "epoch": 0.04725,
      "grad_norm": 0.5282942056655884,
      "learning_rate": 1.5435387443230267e-05,
      "loss": 0.134,
      "step": 19890
    },
    {
      "step": 19900,
      "wer/bud500": 0.05848218200953021
    },
    {
      "step": 19900,
      "wer/private": 0.3178733031674208
    },
    {
      "epoch": 0.0475,
      "grad_norm": 0.49542638659477234,
      "learning_rate": 1.5423462234703185e-05,
      "loss": 0.1289,
      "step": 19900
    },
    {
      "epoch": 0.0475,
      "eval_loss": 0.08108063042163849,
      "eval_runtime": 206.1356,
      "eval_samples_per_second": 36.384,
      "eval_steps_per_second": 0.286,
      "step": 19900
    },
    {
      "epoch": 0.04775,
      "grad_norm": 0.4033454656600952,
      "learning_rate": 1.541153675830848e-05,
      "loss": 0.1346,
      "step": 19910
    },
    {
      "epoch": 0.048,
      "grad_norm": 0.3847486674785614,
      "learning_rate": 1.5399611021589807e-05,
      "loss": 0.142,
      "step": 19920
    },
    {
      "epoch": 0.04825,
      "grad_norm": 0.4133510887622833,
      "learning_rate": 1.5387685032090965e-05,
      "loss": 0.1416,
      "step": 19930
    },
    {
      "epoch": 0.0485,
      "grad_norm": 0.44142279028892517,
      "learning_rate": 1.5375758797355937e-05,
      "loss": 0.1347,
      "step": 19940
    },
    {
      "step": 19950,
      "wer/bud500": 0.06139094337416318
    },
    {
      "step": 19950,
      "wer/private": 0.31221719457013575
    },
    {
      "epoch": 0.04875,
      "grad_norm": 0.4858085513114929,
      "learning_rate": 1.536383232492884e-05,
      "loss": 0.1321,
      "step": 19950
    },
    {
      "epoch": 0.049,
      "grad_norm": 0.5346890687942505,
      "learning_rate": 1.5351905622353946e-05,
      "loss": 0.1295,
      "step": 19960
    },
    {
      "epoch": 0.04925,
      "grad_norm": 0.3579656183719635,
      "learning_rate": 1.5339978697175687e-05,
      "loss": 0.1397,
      "step": 19970
    },
    {
      "epoch": 0.0495,
      "grad_norm": 0.43744176626205444,
      "learning_rate": 1.5328051556938616e-05,
      "loss": 0.1482,
      "step": 19980
    },
    {
      "epoch": 0.04975,
      "grad_norm": 0.4535800814628601,
      "learning_rate": 1.5316124209187437e-05,
      "loss": 0.1396,
      "step": 19990
    },
    {
      "step": 20000,
      "wer/bud500": 0.05871605227000322
    },
    {
      "step": 20000,
      "wer/private": 0.3212669683257919
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4841567873954773,
      "learning_rate": 1.5304196661466972e-05,
      "loss": 0.1426,
      "step": 20000
    },
    {
      "epoch": 0.05,
      "eval_loss": 0.08118883520364761,
      "eval_runtime": 205.2142,
      "eval_samples_per_second": 36.547,
      "eval_steps_per_second": 0.288,
      "step": 20000
    },
    {
      "epoch": 0.05025,
      "grad_norm": 0.4382101893424988,
      "learning_rate": 1.5292268921322184e-05,
      "loss": 0.1369,
      "step": 20010
    },
    {
      "epoch": 0.0505,
      "grad_norm": 0.43865659832954407,
      "learning_rate": 1.5280340996298143e-05,
      "loss": 0.1291,
      "step": 20020
    },
    {
      "epoch": 0.05075,
      "grad_norm": 0.39424049854278564,
      "learning_rate": 1.526841289394005e-05,
      "loss": 0.1328,
      "step": 20030
    },
    {
      "epoch": 0.051,
      "grad_norm": 0.41311824321746826,
      "learning_rate": 1.5256484621793207e-05,
      "loss": 0.1352,
      "step": 20040
    },
    {
      "step": 20050,
      "wer/bud500": 0.058569883357207586
    },
    {
      "step": 20050,
      "wer/private": 0.31221719457013575
    },
    {
      "epoch": 0.05125,
      "grad_norm": 0.3508571684360504,
      "learning_rate": 1.5244556187403034e-05,
      "loss": 0.1279,
      "step": 20050
    },
    {
      "epoch": 0.0515,
      "grad_norm": 0.38141384720802307,
      "learning_rate": 1.5232627598315042e-05,
      "loss": 0.1458,
      "step": 20060
    },
    {
      "epoch": 0.05175,
      "grad_norm": 0.6210079789161682,
      "learning_rate": 1.5220698862074847e-05,
      "loss": 0.1518,
      "step": 20070
    },
    {
      "epoch": 0.052,
      "grad_norm": 0.5138088464736938,
      "learning_rate": 1.5208769986228154e-05,
      "loss": 0.1341,
      "step": 20080
    },
    {
      "epoch": 0.05225,
      "grad_norm": 0.477520227432251,
      "learning_rate": 1.5196840978320765e-05,
      "loss": 0.141,
      "step": 20090
    },
    {
      "step": 20100,
      "wer/bud500": 0.058628350922325836
    },
    {
      "step": 20100,
      "wer/private": 0.3167420814479638
    },
    {
      "epoch": 0.0525,
      "grad_norm": 0.4566630423069,
      "learning_rate": 1.5184911845898554e-05,
      "loss": 0.1447,
      "step": 20100
    },
    {
      "epoch": 0.0525,
      "eval_loss": 0.0806565135717392,
      "eval_runtime": 205.948,
      "eval_samples_per_second": 36.417,
      "eval_steps_per_second": 0.286,
      "step": 20100
    },
    {
      "epoch": 0.05275,
      "grad_norm": 0.44816386699676514,
      "learning_rate": 1.517298259650748e-05,
      "loss": 0.1431,
      "step": 20110
    },
    {
      "epoch": 0.053,
      "grad_norm": 0.4072714149951935,
      "learning_rate": 1.5161053237693577e-05,
      "loss": 0.1352,
      "step": 20120
    },
    {
      "epoch": 0.05325,
      "grad_norm": 0.41505110263824463,
      "learning_rate": 1.5149123777002948e-05,
      "loss": 0.1411,
      "step": 20130
    },
    {
      "epoch": 0.0535,
      "grad_norm": 0.5686824917793274,
      "learning_rate": 1.513719422198175e-05,
      "loss": 0.1471,
      "step": 20140
    },
    {
      "step": 20150,
      "wer/bud500": 0.05861373403104628
    },
    {
      "step": 20150,
      "wer/private": 0.3665158371040724
    },
    {
      "epoch": 0.05375,
      "grad_norm": 0.503773033618927,
      "learning_rate": 1.512526458017622e-05,
      "loss": 0.1488,
      "step": 20150
    },
    {
      "epoch": 0.054,
      "grad_norm": 0.41638419032096863,
      "learning_rate": 1.5113334859132631e-05,
      "loss": 0.1382,
      "step": 20160
    },
    {
      "epoch": 0.05425,
      "grad_norm": 0.4233090877532959,
      "learning_rate": 1.5101405066397313e-05,
      "loss": 0.1274,
      "step": 20170
    },
    {
      "epoch": 0.0545,
      "grad_norm": 0.41501516103744507,
      "learning_rate": 1.5089475209516647e-05,
      "loss": 0.1222,
      "step": 20180
    },
    {
      "epoch": 0.05475,
      "grad_norm": 0.5220877528190613,
      "learning_rate": 1.5077545296037047e-05,
      "loss": 0.1341,
      "step": 20190
    },
    {
      "step": 20200,
      "wer/bud500": 0.058511415792089336
    },
    {
      "step": 20200,
      "wer/private": 0.3178733031674208
    },
    {
      "epoch": 0.055,
      "grad_norm": 0.484287828207016,
      "learning_rate": 1.506561533350496e-05,
      "loss": 0.1499,
      "step": 20200
    },
    {
      "epoch": 0.055,
      "eval_loss": 0.08054964244365692,
      "eval_runtime": 205.4569,
      "eval_samples_per_second": 36.504,
      "eval_steps_per_second": 0.287,
      "step": 20200
    },
    {
      "epoch": 0.00025,
      "grad_norm": 0.4735690653324127,
      "learning_rate": 1.505368532946688e-05,
      "loss": 0.1328,
      "step": 20210
    },
    {
      "epoch": 0.0005,
      "grad_norm": 0.4176303744316101,
      "learning_rate": 1.5041755291469306e-05,
      "loss": 0.1492,
      "step": 20220
    },
    {
      "epoch": 0.00075,
      "grad_norm": 0.4556072950363159,
      "learning_rate": 1.5029825227058777e-05,
      "loss": 0.1395,
      "step": 20230
    },
    {
      "epoch": 0.001,
      "grad_norm": 0.3948853611946106,
      "learning_rate": 1.5017895143781834e-05,
      "loss": 0.1302,
      "step": 20240
    },
    {
      "step": 20250,
      "wer/bud500": 0.05894992253047622
    },
    {
      "step": 20250,
      "wer/private": 0.3506787330316742
    },
    {
      "epoch": 0.00125,
      "grad_norm": 0.4224206209182739,
      "learning_rate": 1.5005965049185037e-05,
      "loss": 0.1375,
      "step": 20250
    },
    {
      "epoch": 0.0015,
      "grad_norm": 0.4904647767543793,
      "learning_rate": 1.499403495081496e-05,
      "loss": 0.1356,
      "step": 20260
    },
    {
      "epoch": 0.00175,
      "grad_norm": 0.5301446914672852,
      "learning_rate": 1.4982104856218169e-05,
      "loss": 0.146,
      "step": 20270
    },
    {
      "epoch": 0.002,
      "grad_norm": 0.42878562211990356,
      "learning_rate": 1.4970174772941227e-05,
      "loss": 0.1336,
      "step": 20280
    },
    {
      "epoch": 0.00225,
      "grad_norm": 0.48083165287971497,
      "learning_rate": 1.4958244708530698e-05,
      "loss": 0.1335,
      "step": 20290
    },
    {
      "step": 20300,
      "wer/bud500": 0.05902300698687403
    },
    {
      "step": 20300,
      "wer/private": 0.3257918552036199
    },
    {
      "epoch": 0.0025,
      "grad_norm": 0.37895575165748596,
      "learning_rate": 1.4946314670533127e-05,
      "loss": 0.1453,
      "step": 20300
    },
    {
      "epoch": 0.0025,
      "eval_loss": 0.08078490197658539,
      "eval_runtime": 208.6244,
      "eval_samples_per_second": 35.95,
      "eval_steps_per_second": 0.283,
      "step": 20300
    },
    {
      "epoch": 0.00275,
      "grad_norm": 0.5287708044052124,
      "learning_rate": 1.4934384666495039e-05,
      "loss": 0.1328,
      "step": 20310
    },
    {
      "epoch": 0.003,
      "grad_norm": 0.42260560393333435,
      "learning_rate": 1.4922454703962954e-05,
      "loss": 0.1206,
      "step": 20320
    },
    {
      "epoch": 0.00325,
      "grad_norm": 0.4793568253517151,
      "learning_rate": 1.4910524790483355e-05,
      "loss": 0.147,
      "step": 20330
    },
    {
      "epoch": 0.0035,
      "grad_norm": 0.5242841839790344,
      "learning_rate": 1.4898594933602691e-05,
      "loss": 0.1456,
      "step": 20340
    },
    {
      "step": 20350,
      "wer/bud500": 0.05835062998801415
    },
    {
      "step": 20350,
      "wer/private": 0.3506787330316742
    },
    {
      "epoch": 0.00375,
      "grad_norm": 0.4314616620540619,
      "learning_rate": 1.4886665140867373e-05,
      "loss": 0.1229,
      "step": 20350
    },
    {
      "epoch": 0.004,
      "grad_norm": 0.4550815224647522,
      "learning_rate": 1.4874735419823787e-05,
      "loss": 0.1372,
      "step": 20360
    },
    {
      "epoch": 0.00425,
      "grad_norm": 0.4785703420639038,
      "learning_rate": 1.4862805778018247e-05,
      "loss": 0.138,
      "step": 20370
    },
    {
      "epoch": 0.0045,
      "grad_norm": 0.41661152243614197,
      "learning_rate": 1.4850876222997056e-05,
      "loss": 0.1442,
      "step": 20380
    },
    {
      "epoch": 0.00475,
      "grad_norm": 0.42880386114120483,
      "learning_rate": 1.4838946762306426e-05,
      "loss": 0.1329,
      "step": 20390
    },
    {
      "step": 20400,
      "wer/bud500": 0.05842371444441196
    },
    {
      "step": 20400,
      "wer/private": 0.32805429864253394
    },
    {
      "epoch": 0.005,
      "grad_norm": 0.3878791630268097,
      "learning_rate": 1.4827017403492522e-05,
      "loss": 0.1228,
      "step": 20400
    },
    {
      "epoch": 0.005,
      "eval_loss": 0.08098713308572769,
      "eval_runtime": 208.2518,
      "eval_samples_per_second": 36.014,
      "eval_steps_per_second": 0.283,
      "step": 20400
    },
    {
      "epoch": 0.00525,
      "grad_norm": 0.4739184081554413,
      "learning_rate": 1.4815088154101452e-05,
      "loss": 0.1354,
      "step": 20410
    },
    {
      "epoch": 0.0055,
      "grad_norm": 0.3625882565975189,
      "learning_rate": 1.4803159021679234e-05,
      "loss": 0.135,
      "step": 20420
    },
    {
      "epoch": 0.00575,
      "grad_norm": 0.43561413884162903,
      "learning_rate": 1.4791230013771848e-05,
      "loss": 0.1317,
      "step": 20430
    },
    {
      "epoch": 0.006,
      "grad_norm": 0.46750032901763916,
      "learning_rate": 1.4779301137925153e-05,
      "loss": 0.1578,
      "step": 20440
    },
    {
      "step": 20450,
      "wer/bud500": 0.05855526646592803
    },
    {
      "step": 20450,
      "wer/private": 0.3552036199095023
    },
    {
      "epoch": 0.00625,
      "grad_norm": 0.4352095127105713,
      "learning_rate": 1.4767372401684962e-05,
      "loss": 0.139,
      "step": 20450
    },
    {
      "epoch": 0.0065,
      "grad_norm": 0.4249548316001892,
      "learning_rate": 1.475544381259697e-05,
      "loss": 0.1272,
      "step": 20460
    },
    {
      "epoch": 0.00675,
      "grad_norm": 0.3955714702606201,
      "learning_rate": 1.4743515378206792e-05,
      "loss": 0.1431,
      "step": 20470
    },
    {
      "epoch": 0.007,
      "grad_norm": 0.4936080276966095,
      "learning_rate": 1.4731587106059949e-05,
      "loss": 0.1289,
      "step": 20480
    },
    {
      "epoch": 0.00725,
      "grad_norm": 0.4574969410896301,
      "learning_rate": 1.4719659003701858e-05,
      "loss": 0.127,
      "step": 20490
    },
    {
      "step": 20500,
      "wer/bud500": 0.058321396205455026
    },
    {
      "step": 20500,
      "wer/private": 0.3246606334841629
    },
    {
      "epoch": 0.0075,
      "grad_norm": 0.4786432385444641,
      "learning_rate": 1.4707731078677822e-05,
      "loss": 0.133,
      "step": 20500
    },
    {
      "epoch": 0.0075,
      "eval_loss": 0.08084306865930557,
      "eval_runtime": 208.4512,
      "eval_samples_per_second": 35.98,
      "eval_steps_per_second": 0.283,
      "step": 20500
    },
    {
      "epoch": 0.00775,
      "grad_norm": 0.4435667395591736,
      "learning_rate": 1.4695803338533029e-05,
      "loss": 0.1444,
      "step": 20510
    },
    {
      "epoch": 0.008,
      "grad_norm": 0.4029242992401123,
      "learning_rate": 1.4683875790812569e-05,
      "loss": 0.1249,
      "step": 20520
    },
    {
      "epoch": 0.00825,
      "grad_norm": 0.37356966733932495,
      "learning_rate": 1.4671948443061383e-05,
      "loss": 0.1336,
      "step": 20530
    },
    {
      "epoch": 0.0085,
      "grad_norm": 0.37484389543533325,
      "learning_rate": 1.4660021302824314e-05,
      "loss": 0.1328,
      "step": 20540
    },
    {
      "step": 20550,
      "wer/bud500": 0.058379863770573276
    },
    {
      "step": 20550,
      "wer/private": 0.33031674208144796
    },
    {
      "epoch": 0.00875,
      "grad_norm": 0.38945379853248596,
      "learning_rate": 1.4648094377646055e-05,
      "loss": 0.1431,
      "step": 20550
    },
    {
      "epoch": 0.009,
      "grad_norm": 0.5685266256332397,
      "learning_rate": 1.4636167675071163e-05,
      "loss": 0.1185,
      "step": 20560
    },
    {
      "epoch": 0.00925,
      "grad_norm": 0.6812021732330322,
      "learning_rate": 1.4624241202644066e-05,
      "loss": 0.1343,
      "step": 20570
    },
    {
      "epoch": 0.0095,
      "grad_norm": 0.4063224494457245,
      "learning_rate": 1.4612314967909032e-05,
      "loss": 0.1396,
      "step": 20580
    },
    {
      "epoch": 0.00975,
      "grad_norm": 0.41201213002204895,
      "learning_rate": 1.4600388978410196e-05,
      "loss": 0.139,
      "step": 20590
    },
    {
      "step": 20600,
      "wer/bud500": 0.058438331335691526
    },
    {
      "step": 20600,
      "wer/private": 0.3427601809954751
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.42168930172920227,
      "learning_rate": 1.458846324169152e-05,
      "loss": 0.1307,
      "step": 20600
    },
    {
      "epoch": 0.01,
      "eval_loss": 0.0809495821595192,
      "eval_runtime": 208.9026,
      "eval_samples_per_second": 35.902,
      "eval_steps_per_second": 0.282,
      "step": 20600
    },
    {
      "epoch": 0.01025,
      "grad_norm": 0.5203217267990112,
      "learning_rate": 1.457653776529682e-05,
      "loss": 0.1132,
      "step": 20610
    },
    {
      "epoch": 0.0105,
      "grad_norm": 0.48186194896698,
      "learning_rate": 1.4564612556769737e-05,
      "loss": 0.1339,
      "step": 20620
    },
    {
      "epoch": 0.01075,
      "grad_norm": 0.5104741454124451,
      "learning_rate": 1.4552687623653744e-05,
      "loss": 0.1443,
      "step": 20630
    },
    {
      "epoch": 0.011,
      "grad_norm": 0.435903400182724,
      "learning_rate": 1.4540762973492148e-05,
      "loss": 0.1434,
      "step": 20640
    },
    {
      "step": 20650,
      "wer/bud500": 0.05855526646592803
    },
    {
      "step": 20650,
      "wer/private": 0.3201357466063348
    },
    {
      "epoch": 0.01125,
      "grad_norm": 0.3679642975330353,
      "learning_rate": 1.4528838613828076e-05,
      "loss": 0.1339,
      "step": 20650
    },
    {
      "epoch": 0.0115,
      "grad_norm": 0.4232322573661804,
      "learning_rate": 1.4516914552204461e-05,
      "loss": 0.1257,
      "step": 20660
    },
    {
      "epoch": 0.01175,
      "grad_norm": 0.38164809346199036,
      "learning_rate": 1.4504990796164052e-05,
      "loss": 0.125,
      "step": 20670
    },
    {
      "epoch": 0.012,
      "grad_norm": 0.45484450459480286,
      "learning_rate": 1.4493067353249412e-05,
      "loss": 0.1427,
      "step": 20680
    },
    {
      "epoch": 0.01225,
      "grad_norm": 0.3881857097148895,
      "learning_rate": 1.448114423100289e-05,
      "loss": 0.1355,
      "step": 20690
    },
    {
      "step": 20700,
      "wer/bud500": 0.05877451983512147
    },
    {
      "step": 20700,
      "wer/private": 0.3416289592760181
    },
    {
      "epoch": 0.0125,
      "grad_norm": 0.3819620907306671,
      "learning_rate": 1.4469221436966655e-05,
      "loss": 0.1388,
      "step": 20700
    },
    {
      "epoch": 0.0125,
      "eval_loss": 0.08090405911207199,
      "eval_runtime": 208.6422,
      "eval_samples_per_second": 35.947,
      "eval_steps_per_second": 0.283,
      "step": 20700
    },
    {
      "epoch": 0.01275,
      "grad_norm": 0.31823596358299255,
      "learning_rate": 1.4457298978682651e-05,
      "loss": 0.1349,
      "step": 20710
    },
    {
      "epoch": 0.013,
      "grad_norm": 0.42094552516937256,
      "learning_rate": 1.444537686369261e-05,
      "loss": 0.129,
      "step": 20720
    },
    {
      "epoch": 0.01325,
      "grad_norm": 0.4161683917045593,
      "learning_rate": 1.4433455099538055e-05,
      "loss": 0.1392,
      "step": 20730
    },
    {
      "epoch": 0.0135,
      "grad_norm": 0.4110112190246582,
      "learning_rate": 1.442153369376028e-05,
      "loss": 0.1353,
      "step": 20740
    },
    {
      "step": 20750,
      "wer/bud500": 0.05855526646592803
    },
    {
      "step": 20750,
      "wer/private": 0.3235294117647059
    },
    {
      "epoch": 0.01375,
      "grad_norm": 0.33606892824172974,
      "learning_rate": 1.440961265390036e-05,
      "loss": 0.1226,
      "step": 20750
    },
    {
      "epoch": 0.014,
      "grad_norm": 0.4434927999973297,
      "learning_rate": 1.4397691987499131e-05,
      "loss": 0.1427,
      "step": 20760
    },
    {
      "epoch": 0.01425,
      "grad_norm": 0.4191562235355377,
      "learning_rate": 1.43857717020972e-05,
      "loss": 0.1322,
      "step": 20770
    },
    {
      "epoch": 0.0145,
      "grad_norm": 0.4640214443206787,
      "learning_rate": 1.4373851805234926e-05,
      "loss": 0.1336,
      "step": 20780
    },
    {
      "epoch": 0.01475,
      "grad_norm": 0.484134316444397,
      "learning_rate": 1.4363124236492192e-05,
      "loss": 0.1264,
      "step": 20790
    },
    {
      "step": 20800,
      "wer/bud500": 0.05865758470488496
    },
    {
      "step": 20800,
      "wer/private": 0.3223981900452489
    },
    {
      "epoch": 0.015,
      "grad_norm": 0.4545053541660309,
      "learning_rate": 1.4351205098628077e-05,
      "loss": 0.1313,
      "step": 20800
    },
    {
      "epoch": 0.015,
      "eval_loss": 0.080793596804142,
      "eval_runtime": 208.9151,
      "eval_samples_per_second": 35.9,
      "eval_steps_per_second": 0.282,
      "step": 20800
    },
    {
      "epoch": 0.01525,
      "grad_norm": 0.4277775287628174,
      "learning_rate": 1.4339286371169262e-05,
      "loss": 0.1434,
      "step": 20810
    },
    {
      "epoch": 0.0155,
      "grad_norm": 0.42553144693374634,
      "learning_rate": 1.4327368061655115e-05,
      "loss": 0.1162,
      "step": 20820
    },
    {
      "epoch": 0.01575,
      "grad_norm": 0.4828387498855591,
      "learning_rate": 1.4315450177624763e-05,
      "loss": 0.1316,
      "step": 20830
    },
    {
      "epoch": 0.016,
      "grad_norm": 0.42392536997795105,
      "learning_rate": 1.4303532726617035e-05,
      "loss": 0.1321,
      "step": 20840
    },
    {
      "step": 20850,
      "wer/bud500": 0.058336013096734585
    },
    {
      "step": 20850,
      "wer/private": 0.3246606334841629
    },
    {
      "epoch": 0.01625,
      "grad_norm": 0.4894119203090668,
      "learning_rate": 1.429161571617051e-05,
      "loss": 0.1422,
      "step": 20850
    },
    {
      "epoch": 0.0165,
      "grad_norm": 0.3497093915939331,
      "learning_rate": 1.4279699153823476e-05,
      "loss": 0.1442,
      "step": 20860
    },
    {
      "epoch": 0.01675,
      "grad_norm": 0.43679794669151306,
      "learning_rate": 1.426778304711393e-05,
      "loss": 0.1408,
      "step": 20870
    },
    {
      "epoch": 0.017,
      "grad_norm": 0.4099608063697815,
      "learning_rate": 1.4255867403579605e-05,
      "loss": 0.139,
      "step": 20880
    },
    {
      "epoch": 0.01725,
      "grad_norm": 0.6320242285728455,
      "learning_rate": 1.4243952230757918e-05,
      "loss": 0.1442,
      "step": 20890
    },
    {
      "step": 20900,
      "wer/bud500": 0.05855526646592803
    },
    {
      "step": 20900,
      "wer/private": 0.3156108597285068
    },
    {
      "epoch": 0.0175,
      "grad_norm": 0.4271279573440552,
      "learning_rate": 1.4232037536186e-05,
      "loss": 0.1374,
      "step": 20900
    },
    {
      "epoch": 0.0175,
      "eval_loss": 0.08060385286808014,
      "eval_runtime": 208.6093,
      "eval_samples_per_second": 35.952,
      "eval_steps_per_second": 0.283,
      "step": 20900
    },
    {
      "epoch": 0.01775,
      "grad_norm": 0.38816365599632263,
      "learning_rate": 1.4220123327400673e-05,
      "loss": 0.1287,
      "step": 20910
    },
    {
      "epoch": 0.018,
      "grad_norm": 0.4218291938304901,
      "learning_rate": 1.4208209611938457e-05,
      "loss": 0.1395,
      "step": 20920
    },
    {
      "epoch": 0.01825,
      "grad_norm": 0.4564901888370514,
      "learning_rate": 1.4196296397335552e-05,
      "loss": 0.1271,
      "step": 20930
    },
    {
      "epoch": 0.0185,
      "grad_norm": 0.4759943187236786,
      "learning_rate": 1.418438369112786e-05,
      "loss": 0.1281,
      "step": 20940
    },
    {
      "step": 20950,
      "wer/bud500": 0.05873066916128278
    },
    {
      "step": 20950,
      "wer/private": 0.3269230769230769
    },
    {
      "epoch": 0.01875,
      "grad_norm": 0.42952603101730347,
      "learning_rate": 1.417247150085094e-05,
      "loss": 0.1236,
      "step": 20950
    },
    {
      "epoch": 0.019,
      "grad_norm": 0.4052567183971405,
      "learning_rate": 1.4160559834040032e-05,
      "loss": 0.1262,
      "step": 20960
    },
    {
      "epoch": 0.01925,
      "grad_norm": 0.4394206404685974,
      "learning_rate": 1.4148648698230051e-05,
      "loss": 0.1328,
      "step": 20970
    },
    {
      "epoch": 0.0195,
      "grad_norm": 0.37909069657325745,
      "learning_rate": 1.4136738100955562e-05,
      "loss": 0.1326,
      "step": 20980
    },
    {
      "epoch": 0.01975,
      "grad_norm": 0.4583345353603363,
      "learning_rate": 1.4124828049750811e-05,
      "loss": 0.139,
      "step": 20990
    },
    {
      "step": 21000,
      "wer/bud500": 0.0585260326833689
    },
    {
      "step": 21000,
      "wer/private": 0.3167420814479638
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.39725375175476074,
      "learning_rate": 1.4112918552149678e-05,
      "loss": 0.1328,
      "step": 21000
    },
    {
      "epoch": 0.02,
      "eval_loss": 0.08060719072818756,
      "eval_runtime": 208.5293,
      "eval_samples_per_second": 35.966,
      "eval_steps_per_second": 0.283,
      "step": 21000
    },
    {
      "epoch": 0.02025,
      "grad_norm": 0.36563730239868164,
      "learning_rate": 1.4101009615685704e-05,
      "loss": 0.1501,
      "step": 21010
    },
    {
      "epoch": 0.0205,
      "grad_norm": 0.5140157341957092,
      "learning_rate": 1.4089101247892071e-05,
      "loss": 0.133,
      "step": 21020
    },
    {
      "epoch": 0.02075,
      "grad_norm": 0.48340898752212524,
      "learning_rate": 1.4077193456301596e-05,
      "loss": 0.1396,
      "step": 21030
    },
    {
      "epoch": 0.021,
      "grad_norm": 0.505614697933197,
      "learning_rate": 1.4065286248446748e-05,
      "loss": 0.1367,
      "step": 21040
    },
    {
      "step": 21050,
      "wer/bud500": 0.058145993510100275
    },
    {
      "step": 21050,
      "wer/private": 0.3438914027149321
    },
    {
      "epoch": 0.02125,
      "grad_norm": 0.41343599557876587,
      "learning_rate": 1.4053379631859608e-05,
      "loss": 0.1331,
      "step": 21050
    },
    {
      "epoch": 0.0215,
      "grad_norm": 0.4770137667655945,
      "learning_rate": 1.4041473614071899e-05,
      "loss": 0.139,
      "step": 21060
    },
    {
      "epoch": 0.02175,
      "grad_norm": 0.34870582818984985,
      "learning_rate": 1.4029568202614953e-05,
      "loss": 0.1277,
      "step": 21070
    },
    {
      "epoch": 0.022,
      "grad_norm": 0.43788301944732666,
      "learning_rate": 1.4017663405019722e-05,
      "loss": 0.1386,
      "step": 21080
    },
    {
      "epoch": 0.02225,
      "grad_norm": 0.45594215393066406,
      "learning_rate": 1.4005759228816767e-05,
      "loss": 0.1442,
      "step": 21090
    },
    {
      "step": 21100,
      "wer/bud500": 0.058277545531616334
    },
    {
      "step": 21100,
      "wer/private": 0.3178733031674208
    },
    {
      "epoch": 0.0225,
      "grad_norm": 0.49142593145370483,
      "learning_rate": 1.3993855681536274e-05,
      "loss": 0.1385,
      "step": 21100
    },
    {
      "epoch": 0.0225,
      "eval_loss": 0.08083315938711166,
      "eval_runtime": 210.341,
      "eval_samples_per_second": 35.656,
      "eval_steps_per_second": 0.28,
      "step": 21100
    },
    {
      "epoch": 0.02275,
      "grad_norm": 0.4631271958351135,
      "learning_rate": 1.3981952770708006e-05,
      "loss": 0.1327,
      "step": 21110
    },
    {
      "epoch": 0.023,
      "grad_norm": 0.4107927680015564,
      "learning_rate": 1.3970050503861333e-05,
      "loss": 0.1395,
      "step": 21120
    },
    {
      "epoch": 0.02325,
      "grad_norm": 0.378974974155426,
      "learning_rate": 1.3958148888525228e-05,
      "loss": 0.1393,
      "step": 21130
    },
    {
      "epoch": 0.0235,
      "grad_norm": 0.39639103412628174,
      "learning_rate": 1.3946247932228226e-05,
      "loss": 0.1389,
      "step": 21140
    },
    {
      "step": 21150,
      "wer/bud500": 0.05823369485777765
    },
    {
      "step": 21150,
      "wer/private": 0.3223981900452489
    },
    {
      "epoch": 0.02375,
      "grad_norm": 0.4702996015548706,
      "learning_rate": 1.3934347642498482e-05,
      "loss": 0.1347,
      "step": 21150
    },
    {
      "epoch": 0.024,
      "grad_norm": 0.4024340510368347,
      "learning_rate": 1.3922448026863696e-05,
      "loss": 0.1565,
      "step": 21160
    },
    {
      "epoch": 0.02425,
      "grad_norm": 0.4619556665420532,
      "learning_rate": 1.3910549092851161e-05,
      "loss": 0.1421,
      "step": 21170
    },
    {
      "epoch": 0.0245,
      "grad_norm": 0.439005583524704,
      "learning_rate": 1.389865084798773e-05,
      "loss": 0.1407,
      "step": 21180
    },
    {
      "epoch": 0.02475,
      "grad_norm": 0.45177972316741943,
      "learning_rate": 1.388675329979982e-05,
      "loss": 0.1293,
      "step": 21190
    },
    {
      "step": 21200,
      "wer/bud500": 0.05858450024848715
    },
    {
      "step": 21200,
      "wer/private": 0.332579185520362
    },
    {
      "epoch": 0.025,
      "grad_norm": 0.5782217979431152,
      "learning_rate": 1.3874856455813418e-05,
      "loss": 0.1441,
      "step": 21200
    },
    {
      "epoch": 0.025,
      "eval_loss": 0.08061061054468155,
      "eval_runtime": 208.784,
      "eval_samples_per_second": 35.922,
      "eval_steps_per_second": 0.283,
      "step": 21200
    },
    {
      "epoch": 0.02525,
      "grad_norm": 0.38436663150787354,
      "learning_rate": 1.3862960323554048e-05,
      "loss": 0.1411,
      "step": 21210
    },
    {
      "epoch": 0.0255,
      "grad_norm": 0.4558570384979248,
      "learning_rate": 1.3851064910546803e-05,
      "loss": 0.1455,
      "step": 21220
    },
    {
      "epoch": 0.02575,
      "grad_norm": 0.39615750312805176,
      "learning_rate": 1.3839170224316304e-05,
      "loss": 0.1397,
      "step": 21230
    },
    {
      "epoch": 0.026,
      "grad_norm": 0.5450672507286072,
      "learning_rate": 1.382727627238672e-05,
      "loss": 0.1284,
      "step": 21240
    },
    {
      "step": 21250,
      "wer/bud500": 0.05861373403104628
    },
    {
      "step": 21250,
      "wer/private": 0.3495475113122172
    },
    {
      "epoch": 0.02625,
      "grad_norm": 0.40074285864830017,
      "learning_rate": 1.3815383062281755e-05,
      "loss": 0.1338,
      "step": 21250
    },
    {
      "epoch": 0.0265,
      "grad_norm": 0.4157215654850006,
      "learning_rate": 1.3803490601524654e-05,
      "loss": 0.1318,
      "step": 21260
    },
    {
      "epoch": 0.02675,
      "grad_norm": 0.3559129238128662,
      "learning_rate": 1.3791598897638168e-05,
      "loss": 0.1419,
      "step": 21270
    },
    {
      "epoch": 0.027,
      "grad_norm": 0.4682457447052002,
      "learning_rate": 1.3779707958144578e-05,
      "loss": 0.1279,
      "step": 21280
    },
    {
      "epoch": 0.02725,
      "grad_norm": 0.4950595796108246,
      "learning_rate": 1.376781779056569e-05,
      "loss": 0.1328,
      "step": 21290
    },
    {
      "step": 21300,
      "wer/bud500": 0.05842371444441196
    },
    {
      "step": 21300,
      "wer/private": 0.333710407239819
    },
    {
      "epoch": 0.0275,
      "grad_norm": 0.4133320748806,
      "learning_rate": 1.3755928402422802e-05,
      "loss": 0.1275,
      "step": 21300
    },
    {
      "epoch": 0.0275,
      "eval_loss": 0.08043842017650604,
      "eval_runtime": 208.7103,
      "eval_samples_per_second": 35.935,
      "eval_steps_per_second": 0.283,
      "step": 21300
    },
    {
      "epoch": 0.02775,
      "grad_norm": 0.42530569434165955,
      "learning_rate": 1.3744039801236746e-05,
      "loss": 0.1227,
      "step": 21310
    },
    {
      "epoch": 0.028,
      "grad_norm": 0.49020978808403015,
      "learning_rate": 1.3732151994527833e-05,
      "loss": 0.1424,
      "step": 21320
    },
    {
      "epoch": 0.02825,
      "grad_norm": 0.4836505055427551,
      "learning_rate": 1.3720264989815885e-05,
      "loss": 0.1453,
      "step": 21330
    },
    {
      "epoch": 0.0285,
      "grad_norm": 0.39974245429039,
      "learning_rate": 1.3708378794620206e-05,
      "loss": 0.1306,
      "step": 21340
    },
    {
      "step": 21350,
      "wer/bud500": 0.05811675972754115
    },
    {
      "step": 21350,
      "wer/private": 0.3438914027149321
    },
    {
      "epoch": 0.02875,
      "grad_norm": 0.4202842116355896,
      "learning_rate": 1.369649341645959e-05,
      "loss": 0.1332,
      "step": 21350
    },
    {
      "epoch": 0.029,
      "grad_norm": 0.3903002440929413,
      "learning_rate": 1.3684608862852329e-05,
      "loss": 0.1276,
      "step": 21360
    },
    {
      "epoch": 0.02925,
      "grad_norm": 0.40340888500213623,
      "learning_rate": 1.3672725141316179e-05,
      "loss": 0.137,
      "step": 21370
    },
    {
      "epoch": 0.0295,
      "grad_norm": 0.5738527178764343,
      "learning_rate": 1.366084225936837e-05,
      "loss": 0.1395,
      "step": 21380
    },
    {
      "epoch": 0.02975,
      "grad_norm": 0.4774768054485321,
      "learning_rate": 1.36489602245256e-05,
      "loss": 0.148,
      "step": 21390
    },
    {
      "step": 21400,
      "wer/bud500": 0.05818984418393896
    },
    {
      "step": 21400,
      "wer/private": 0.3438914027149321
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.43514612317085266,
      "learning_rate": 1.3637079044304043e-05,
      "loss": 0.131,
      "step": 21400
    },
    {
      "epoch": 0.03,
      "eval_loss": 0.08060126006603241,
      "eval_runtime": 208.7451,
      "eval_samples_per_second": 35.929,
      "eval_steps_per_second": 0.283,
      "step": 21400
    },
    {
      "epoch": 0.03025,
      "grad_norm": 0.4300558567047119,
      "learning_rate": 1.3625198726219312e-05,
      "loss": 0.1472,
      "step": 21410
    },
    {
      "epoch": 0.0305,
      "grad_norm": 0.5255419611930847,
      "learning_rate": 1.3613319277786504e-05,
      "loss": 0.1464,
      "step": 21420
    },
    {
      "epoch": 0.03075,
      "grad_norm": 0.4649023115634918,
      "learning_rate": 1.3601440706520138e-05,
      "loss": 0.1357,
      "step": 21430
    },
    {
      "epoch": 0.031,
      "grad_norm": 0.4908756613731384,
      "learning_rate": 1.3589563019934187e-05,
      "loss": 0.1363,
      "step": 21440
    },
    {
      "step": 21450,
      "wer/bud500": 0.058394480661852835
    },
    {
      "step": 21450,
      "wer/private": 0.332579185520362
    },
    {
      "epoch": 0.03125,
      "grad_norm": 0.4867362678050995,
      "learning_rate": 1.3577686225542074e-05,
      "loss": 0.1392,
      "step": 21450
    },
    {
      "epoch": 0.0315,
      "grad_norm": 0.596797525882721,
      "learning_rate": 1.3565810330856638e-05,
      "loss": 0.1179,
      "step": 21460
    },
    {
      "epoch": 0.03175,
      "grad_norm": 0.4792632758617401,
      "learning_rate": 1.3553935343390177e-05,
      "loss": 0.1282,
      "step": 21470
    },
    {
      "epoch": 0.032,
      "grad_norm": 0.47515252232551575,
      "learning_rate": 1.3542061270654386e-05,
      "loss": 0.1503,
      "step": 21480
    },
    {
      "epoch": 0.03225,
      "grad_norm": 0.4410640001296997,
      "learning_rate": 1.3530188120160402e-05,
      "loss": 0.1352,
      "step": 21490
    },
    {
      "step": 21500,
      "wer/bud500": 0.05842371444441196
    },
    {
      "step": 21500,
      "wer/private": 0.33597285067873306
    },
    {
      "epoch": 0.0325,
      "grad_norm": 0.5303976535797119,
      "learning_rate": 1.3518315899418767e-05,
      "loss": 0.1339,
      "step": 21500
    },
    {
      "epoch": 0.0325,
      "eval_loss": 0.08069656789302826,
      "eval_runtime": 208.7396,
      "eval_samples_per_second": 35.93,
      "eval_steps_per_second": 0.283,
      "step": 21500
    },
    {
      "epoch": 0.03275,
      "grad_norm": 0.38610222935676575,
      "learning_rate": 1.3506444615939434e-05,
      "loss": 0.1413,
      "step": 21510
    },
    {
      "epoch": 0.033,
      "grad_norm": 0.537661075592041,
      "learning_rate": 1.3494574277231775e-05,
      "loss": 0.133,
      "step": 21520
    },
    {
      "epoch": 0.03325,
      "grad_norm": 0.42553025484085083,
      "learning_rate": 1.348270489080456e-05,
      "loss": 0.1304,
      "step": 21530
    },
    {
      "epoch": 0.0335,
      "grad_norm": 0.4153527617454529,
      "learning_rate": 1.3470836464165947e-05,
      "loss": 0.1273,
      "step": 21540
    },
    {
      "step": 21550,
      "wer/bud500": 0.05801444148858421
    },
    {
      "step": 21550,
      "wer/private": 0.3246606334841629
    },
    {
      "epoch": 0.03375,
      "grad_norm": 0.5190815329551697,
      "learning_rate": 1.3458969004823495e-05,
      "loss": 0.1349,
      "step": 21550
    },
    {
      "epoch": 0.034,
      "grad_norm": 0.6137675046920776,
      "learning_rate": 1.3447102520284154e-05,
      "loss": 0.1448,
      "step": 21560
    },
    {
      "epoch": 0.03425,
      "grad_norm": 0.5140892863273621,
      "learning_rate": 1.3435237018054242e-05,
      "loss": 0.1335,
      "step": 21570
    },
    {
      "epoch": 0.0345,
      "grad_norm": 0.38105693459510803,
      "learning_rate": 1.3423372505639483e-05,
      "loss": 0.1372,
      "step": 21580
    },
    {
      "epoch": 0.03475,
      "grad_norm": 0.4624658226966858,
      "learning_rate": 1.341150899054495e-05,
      "loss": 0.1277,
      "step": 21590
    },
    {
      "step": 21600,
      "wer/bud500": 0.05810214283626158
    },
    {
      "step": 21600,
      "wer/private": 0.3257918552036199
    },
    {
      "epoch": 0.035,
      "grad_norm": 0.44331204891204834,
      "learning_rate": 1.3399646480275091e-05,
      "loss": 0.1348,
      "step": 21600
    },
    {
      "epoch": 0.035,
      "eval_loss": 0.08068391680717468,
      "eval_runtime": 208.2828,
      "eval_samples_per_second": 36.009,
      "eval_steps_per_second": 0.283,
      "step": 21600
    },
    {
      "epoch": 0.03525,
      "grad_norm": 0.41463223099708557,
      "learning_rate": 1.338778498233373e-05,
      "loss": 0.1347,
      "step": 21610
    },
    {
      "epoch": 0.0355,
      "grad_norm": 0.47492143511772156,
      "learning_rate": 1.3375924504224028e-05,
      "loss": 0.1521,
      "step": 21620
    },
    {
      "epoch": 0.03575,
      "grad_norm": 0.42093929648399353,
      "learning_rate": 1.336406505344853e-05,
      "loss": 0.13,
      "step": 21630
    },
    {
      "epoch": 0.036,
      "grad_norm": 0.47681376338005066,
      "learning_rate": 1.3352206637509108e-05,
      "loss": 0.1219,
      "step": 21640
    },
    {
      "step": 21650,
      "wer/bud500": 0.058204461075218525
    },
    {
      "step": 21650,
      "wer/private": 0.31447963800904977
    },
    {
      "epoch": 0.03625,
      "grad_norm": 0.4526898264884949,
      "learning_rate": 1.3340349263906992e-05,
      "loss": 0.1462,
      "step": 21650
    },
    {
      "epoch": 0.0365,
      "grad_norm": 0.562857449054718,
      "learning_rate": 1.332849294014274e-05,
      "loss": 0.1297,
      "step": 21660
    },
    {
      "epoch": 0.03675,
      "grad_norm": 0.3779031038284302,
      "learning_rate": 1.3316637673716257e-05,
      "loss": 0.1346,
      "step": 21670
    },
    {
      "epoch": 0.037,
      "grad_norm": 0.46975019574165344,
      "learning_rate": 1.330478347212678e-05,
      "loss": 0.1292,
      "step": 21680
    },
    {
      "epoch": 0.03725,
      "grad_norm": 0.41434362530708313,
      "learning_rate": 1.3292930342872867e-05,
      "loss": 0.1531,
      "step": 21690
    },
    {
      "step": 21700,
      "wer/bud500": 0.0581752272926594
    },
    {
      "step": 21700,
      "wer/private": 0.3552036199095023
    },
    {
      "epoch": 0.0375,
      "grad_norm": 0.521791398525238,
      "learning_rate": 1.3281078293452402e-05,
      "loss": 0.1414,
      "step": 21700
    },
    {
      "epoch": 0.0375,
      "eval_loss": 0.0807022824883461,
      "eval_runtime": 208.5507,
      "eval_samples_per_second": 35.962,
      "eval_steps_per_second": 0.283,
      "step": 21700
    },
    {
      "epoch": 0.03775,
      "grad_norm": 0.4170856773853302,
      "learning_rate": 1.3269227331362573e-05,
      "loss": 0.1414,
      "step": 21710
    },
    {
      "epoch": 0.038,
      "grad_norm": 0.3776329457759857,
      "learning_rate": 1.3257377464099892e-05,
      "loss": 0.1274,
      "step": 21720
    },
    {
      "epoch": 0.03825,
      "grad_norm": 0.42000487446784973,
      "learning_rate": 1.324552869916019e-05,
      "loss": 0.1469,
      "step": 21730
    },
    {
      "epoch": 0.0385,
      "grad_norm": 0.46194207668304443,
      "learning_rate": 1.323368104403858e-05,
      "loss": 0.1322,
      "step": 21740
    },
    {
      "step": 21750,
      "wer/bud500": 0.058219077966498084
    },
    {
      "step": 21750,
      "wer/private": 0.3438914027149321
    },
    {
      "epoch": 0.03875,
      "grad_norm": 0.5353665947914124,
      "learning_rate": 1.3221834506229477e-05,
      "loss": 0.1318,
      "step": 21750
    },
    {
      "epoch": 0.039,
      "grad_norm": 0.5826659202575684,
      "learning_rate": 1.3209989093226591e-05,
      "loss": 0.1355,
      "step": 21760
    },
    {
      "epoch": 0.03925,
      "grad_norm": 0.5454684495925903,
      "learning_rate": 1.319814481252293e-05,
      "loss": 0.1404,
      "step": 21770
    },
    {
      "epoch": 0.0395,
      "grad_norm": 0.422279953956604,
      "learning_rate": 1.3186301671610768e-05,
      "loss": 0.1406,
      "step": 21780
    },
    {
      "epoch": 0.03975,
      "grad_norm": 0.5206776261329651,
      "learning_rate": 1.3174459677981676e-05,
      "loss": 0.1329,
      "step": 21790
    },
    {
      "step": 21800,
      "wer/bud500": 0.0582921624228959
    },
    {
      "step": 21800,
      "wer/private": 0.34728506787330315
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4780225455760956,
      "learning_rate": 1.316261883912649e-05,
      "loss": 0.1386,
      "step": 21800
    },
    {
      "epoch": 0.04,
      "eval_loss": 0.08041395992040634,
      "eval_runtime": 209.1499,
      "eval_samples_per_second": 35.859,
      "eval_steps_per_second": 0.282,
      "step": 21800
    },
    {
      "epoch": 0.04025,
      "grad_norm": 0.4902006983757019,
      "learning_rate": 1.3150779162535318e-05,
      "loss": 0.1358,
      "step": 21810
    },
    {
      "epoch": 0.0405,
      "grad_norm": 0.47921222448349,
      "learning_rate": 1.3138940655697527e-05,
      "loss": 0.1341,
      "step": 21820
    },
    {
      "epoch": 0.04075,
      "grad_norm": 0.3955264687538147,
      "learning_rate": 1.3127103326101745e-05,
      "loss": 0.1323,
      "step": 21830
    },
    {
      "epoch": 0.041,
      "grad_norm": 0.571271538734436,
      "learning_rate": 1.3115267181235866e-05,
      "loss": 0.1416,
      "step": 21840
    },
    {
      "step": 21850,
      "wer/bud500": 0.05849679890080978
    },
    {
      "step": 21850,
      "wer/private": 0.3246606334841629
    },
    {
      "epoch": 0.04125,
      "grad_norm": 0.47785240411758423,
      "learning_rate": 1.310343222858703e-05,
      "loss": 0.1404,
      "step": 21850
    },
    {
      "epoch": 0.0415,
      "grad_norm": 0.45003196597099304,
      "learning_rate": 1.3091598475641615e-05,
      "loss": 0.151,
      "step": 21860
    },
    {
      "epoch": 0.04175,
      "grad_norm": 0.4243585169315338,
      "learning_rate": 1.3079765929885244e-05,
      "loss": 0.1291,
      "step": 21870
    },
    {
      "epoch": 0.042,
      "grad_norm": 0.42651382088661194,
      "learning_rate": 1.3067934598802773e-05,
      "loss": 0.1278,
      "step": 21880
    },
    {
      "epoch": 0.04225,
      "grad_norm": 0.36783185601234436,
      "learning_rate": 1.3056104489878311e-05,
      "loss": 0.1351,
      "step": 21890
    },
    {
      "step": 21900,
      "wer/bud500": 0.05811675972754115
    },
    {
      "step": 21900,
      "wer/private": 0.3246606334841629
    },
    {
      "epoch": 0.0425,
      "grad_norm": 0.4522739350795746,
      "learning_rate": 1.3044275610595165e-05,
      "loss": 0.1338,
      "step": 21900
    },
    {
      "epoch": 0.0425,
      "eval_loss": 0.08077181875705719,
      "eval_runtime": 208.6614,
      "eval_samples_per_second": 35.943,
      "eval_steps_per_second": 0.283,
      "step": 21900
    },
    {
      "epoch": 0.04275,
      "grad_norm": 0.3738943040370941,
      "learning_rate": 1.3032447968435878e-05,
      "loss": 0.1334,
      "step": 21910
    },
    {
      "epoch": 0.043,
      "grad_norm": 0.4951688051223755,
      "learning_rate": 1.3020621570882213e-05,
      "loss": 0.1372,
      "step": 21920
    },
    {
      "epoch": 0.04325,
      "grad_norm": 0.3746609389781952,
      "learning_rate": 1.3008796425415138e-05,
      "loss": 0.1326,
      "step": 21930
    },
    {
      "epoch": 0.0435,
      "grad_norm": 0.43397584557533264,
      "learning_rate": 1.2996972539514825e-05,
      "loss": 0.1356,
      "step": 21940
    },
    {
      "step": 21950,
      "wer/bud500": 0.05799982459730465
    },
    {
      "step": 21950,
      "wer/private": 0.3178733031674208
    },
    {
      "epoch": 0.04375,
      "grad_norm": 0.4193887412548065,
      "learning_rate": 1.2985149920660672e-05,
      "loss": 0.1344,
      "step": 21950
    },
    {
      "epoch": 0.044,
      "grad_norm": 0.40178778767585754,
      "learning_rate": 1.297332857633125e-05,
      "loss": 0.135,
      "step": 21960
    },
    {
      "epoch": 0.04425,
      "grad_norm": 0.5549290776252747,
      "learning_rate": 1.296150851400434e-05,
      "loss": 0.1402,
      "step": 21970
    },
    {
      "epoch": 0.0445,
      "grad_norm": 0.40938878059387207,
      "learning_rate": 1.2949689741156903e-05,
      "loss": 0.119,
      "step": 21980
    },
    {
      "epoch": 0.04475,
      "grad_norm": 0.42200931906700134,
      "learning_rate": 1.2937872265265081e-05,
      "loss": 0.1356,
      "step": 21990
    },
    {
      "step": 22000,
      "wer/bud500": 0.05818984418393896
    },
    {
      "step": 22000,
      "wer/private": 0.3235294117647059
    },
    {
      "epoch": 0.045,
      "grad_norm": 0.44941237568855286,
      "learning_rate": 1.2926056093804213e-05,
      "loss": 0.142,
      "step": 22000
    },
    {
      "epoch": 0.045,
      "eval_loss": 0.0804426297545433,
      "eval_runtime": 209.0026,
      "eval_samples_per_second": 35.885,
      "eval_steps_per_second": 0.282,
      "step": 22000
    },
    {
      "epoch": 0.04525,
      "grad_norm": 0.5171571373939514,
      "learning_rate": 1.2914241234248801e-05,
      "loss": 0.1357,
      "step": 22010
    },
    {
      "epoch": 0.0455,
      "grad_norm": 0.38318902254104614,
      "learning_rate": 1.2902427694072513e-05,
      "loss": 0.13,
      "step": 22020
    },
    {
      "epoch": 0.04575,
      "grad_norm": 0.49313607811927795,
      "learning_rate": 1.2890615480748187e-05,
      "loss": 0.1555,
      "step": 22030
    },
    {
      "epoch": 0.046,
      "grad_norm": 0.5978066921234131,
      "learning_rate": 1.287880460174782e-05,
      "loss": 0.1437,
      "step": 22040
    },
    {
      "step": 22050,
      "wer/bud500": 0.0584090975531324
    },
    {
      "step": 22050,
      "wer/private": 0.31108597285067874
    },
    {
      "epoch": 0.04625,
      "grad_norm": 0.5281978845596313,
      "learning_rate": 1.286699506454258e-05,
      "loss": 0.1366,
      "step": 22050
    },
    {
      "epoch": 0.0465,
      "grad_norm": 0.48982155323028564,
      "learning_rate": 1.2855186876602764e-05,
      "loss": 0.1394,
      "step": 22060
    },
    {
      "epoch": 0.04675,
      "grad_norm": 0.57245934009552,
      "learning_rate": 1.2843380045397822e-05,
      "loss": 0.1325,
      "step": 22070
    },
    {
      "epoch": 0.047,
      "grad_norm": 0.5290011167526245,
      "learning_rate": 1.2831574578396355e-05,
      "loss": 0.1415,
      "step": 22080
    },
    {
      "epoch": 0.04725,
      "grad_norm": 0.4450446665287018,
      "learning_rate": 1.2819770483066092e-05,
      "loss": 0.139,
      "step": 22090
    },
    {
      "step": 22100,
      "wer/bud500": 0.058336013096734585
    },
    {
      "step": 22100,
      "wer/private": 0.332579185520362
    },
    {
      "epoch": 0.0475,
      "grad_norm": 0.4447004795074463,
      "learning_rate": 1.2807967766873891e-05,
      "loss": 0.1373,
      "step": 22100
    },
    {
      "epoch": 0.0475,
      "eval_loss": 0.08045266568660736,
      "eval_runtime": 208.9192,
      "eval_samples_per_second": 35.899,
      "eval_steps_per_second": 0.282,
      "step": 22100
    },
    {
      "epoch": 0.04775,
      "grad_norm": 0.44983556866645813,
      "learning_rate": 1.2796166437285753e-05,
      "loss": 0.1372,
      "step": 22110
    },
    {
      "epoch": 0.048,
      "grad_norm": 0.5053262710571289,
      "learning_rate": 1.2784366501766788e-05,
      "loss": 0.143,
      "step": 22120
    },
    {
      "epoch": 0.04825,
      "grad_norm": 0.42669835686683655,
      "learning_rate": 1.2772567967781233e-05,
      "loss": 0.1344,
      "step": 22130
    },
    {
      "epoch": 0.0485,
      "grad_norm": 0.5364834666252136,
      "learning_rate": 1.2760770842792429e-05,
      "loss": 0.1497,
      "step": 22140
    },
    {
      "step": 22150,
      "wer/bud500": 0.05849679890080978
    },
    {
      "step": 22150,
      "wer/private": 0.3246606334841629
    },
    {
      "epoch": 0.04875,
      "grad_norm": 0.44937610626220703,
      "learning_rate": 1.2748975134262826e-05,
      "loss": 0.1373,
      "step": 22150
    },
    {
      "epoch": 0.049,
      "grad_norm": 0.5844169855117798,
      "learning_rate": 1.2737180849653992e-05,
      "loss": 0.1319,
      "step": 22160
    },
    {
      "epoch": 0.04925,
      "grad_norm": 0.39763760566711426,
      "learning_rate": 1.2725387996426587e-05,
      "loss": 0.1351,
      "step": 22170
    },
    {
      "epoch": 0.0495,
      "grad_norm": 0.41964396834373474,
      "learning_rate": 1.2713596582040355e-05,
      "loss": 0.137,
      "step": 22180
    },
    {
      "epoch": 0.04975,
      "grad_norm": 0.49435386061668396,
      "learning_rate": 1.2701806613954143e-05,
      "loss": 0.1267,
      "step": 22190
    },
    {
      "step": 22200,
      "wer/bud500": 0.057912123249627266
    },
    {
      "step": 22200,
      "wer/private": 0.3212669683257919
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4697183072566986,
      "learning_rate": 1.2690018099625872e-05,
      "loss": 0.121,
      "step": 22200
    },
    {
      "epoch": 0.05,
      "eval_loss": 0.08057582378387451,
      "eval_runtime": 208.5535,
      "eval_samples_per_second": 35.962,
      "eval_steps_per_second": 0.283,
      "step": 22200
    },
    {
      "epoch": 0.05025,
      "grad_norm": 0.4779813587665558,
      "learning_rate": 1.2678231046512561e-05,
      "loss": 0.1443,
      "step": 22210
    },
    {
      "epoch": 0.0505,
      "grad_norm": 0.5087865591049194,
      "learning_rate": 1.2666445462070292e-05,
      "loss": 0.132,
      "step": 22220
    },
    {
      "epoch": 0.05075,
      "grad_norm": 0.39014527201652527,
      "learning_rate": 1.265466135375421e-05,
      "loss": 0.1292,
      "step": 22230
    },
    {
      "epoch": 0.051,
      "grad_norm": 0.44144168496131897,
      "learning_rate": 1.2642878729018546e-05,
      "loss": 0.1344,
      "step": 22240
    },
    {
      "step": 22250,
      "wer/bud500": 0.05783903879322946
    },
    {
      "step": 22250,
      "wer/private": 0.3190045248868778
    },
    {
      "epoch": 0.05125,
      "grad_norm": 0.3565572202205658,
      "learning_rate": 1.2631097595316577e-05,
      "loss": 0.133,
      "step": 22250
    },
    {
      "epoch": 0.0515,
      "grad_norm": 0.35999754071235657,
      "learning_rate": 1.2619317960100637e-05,
      "loss": 0.1423,
      "step": 22260
    },
    {
      "epoch": 0.05175,
      "grad_norm": 0.5366988182067871,
      "learning_rate": 1.2607539830822127e-05,
      "loss": 0.1486,
      "step": 22270
    },
    {
      "epoch": 0.052,
      "grad_norm": 0.5344743728637695,
      "learning_rate": 1.2595763214931484e-05,
      "loss": 0.1249,
      "step": 22280
    },
    {
      "epoch": 0.05225,
      "grad_norm": 0.45239290595054626,
      "learning_rate": 1.258398811987819e-05,
      "loss": 0.1399,
      "step": 22290
    },
    {
      "step": 22300,
      "wer/bud500": 0.057970590814745517
    },
    {
      "step": 22300,
      "wer/private": 0.3190045248868778
    },
    {
      "epoch": 0.0525,
      "grad_norm": 0.4863013029098511,
      "learning_rate": 1.2572214553110759e-05,
      "loss": 0.1243,
      "step": 22300
    },
    {
      "epoch": 0.0525,
      "eval_loss": 0.08043728023767471,
      "eval_runtime": 210.5926,
      "eval_samples_per_second": 35.614,
      "eval_steps_per_second": 0.28,
      "step": 22300
    },
    {
      "epoch": 0.05275,
      "grad_norm": 0.43263062834739685,
      "learning_rate": 1.2560442522076747e-05,
      "loss": 0.1348,
      "step": 22310
    },
    {
      "epoch": 0.053,
      "grad_norm": 0.43714016675949097,
      "learning_rate": 1.2548672034222734e-05,
      "loss": 0.1315,
      "step": 22320
    },
    {
      "epoch": 0.05325,
      "grad_norm": 0.39578214287757874,
      "learning_rate": 1.253690309699433e-05,
      "loss": 0.143,
      "step": 22330
    },
    {
      "epoch": 0.0535,
      "grad_norm": 0.44618672132492065,
      "learning_rate": 1.2525135717836156e-05,
      "loss": 0.1284,
      "step": 22340
    },
    {
      "step": 22350,
      "wer/bud500": 0.05818984418393896
    },
    {
      "step": 22350,
      "wer/private": 0.3404977375565611
    },
    {
      "epoch": 0.05375,
      "grad_norm": 0.4648401737213135,
      "learning_rate": 1.2513369904191845e-05,
      "loss": 0.1472,
      "step": 22350
    },
    {
      "epoch": 0.054,
      "grad_norm": 0.42934784293174744,
      "learning_rate": 1.250160566350405e-05,
      "loss": 0.1376,
      "step": 22360
    },
    {
      "epoch": 0.05425,
      "grad_norm": 0.4531218111515045,
      "learning_rate": 1.2489843003214427e-05,
      "loss": 0.1261,
      "step": 22370
    },
    {
      "epoch": 0.0545,
      "grad_norm": 0.38979876041412354,
      "learning_rate": 1.2478081930763628e-05,
      "loss": 0.1467,
      "step": 22380
    },
    {
      "epoch": 0.05475,
      "grad_norm": 0.5425548553466797,
      "learning_rate": 1.2466322453591301e-05,
      "loss": 0.1399,
      "step": 22390
    },
    {
      "step": 22400,
      "wer/bud500": 0.058321396205455026
    },
    {
      "step": 22400,
      "wer/private": 0.3178733031674208
    },
    {
      "epoch": 0.055,
      "grad_norm": 0.37027135491371155,
      "learning_rate": 1.2454564579136087e-05,
      "loss": 0.137,
      "step": 22400
    },
    {
      "epoch": 0.055,
      "eval_loss": 0.08025991171598434,
      "eval_runtime": 208.9779,
      "eval_samples_per_second": 35.889,
      "eval_steps_per_second": 0.282,
      "step": 22400
    },
    {
      "epoch": 0.05525,
      "grad_norm": 0.4802870452404022,
      "learning_rate": 1.2442808314835612e-05,
      "loss": 0.1347,
      "step": 22410
    },
    {
      "epoch": 0.0555,
      "grad_norm": 0.4785400927066803,
      "learning_rate": 1.2431053668126477e-05,
      "loss": 0.1525,
      "step": 22420
    },
    {
      "epoch": 0.05575,
      "grad_norm": 0.4222310781478882,
      "learning_rate": 1.2419300646444275e-05,
      "loss": 0.1222,
      "step": 22430
    },
    {
      "epoch": 0.056,
      "grad_norm": 0.4788070321083069,
      "learning_rate": 1.2407549257223564e-05,
      "loss": 0.1387,
      "step": 22440
    },
    {
      "step": 22450,
      "wer/bud500": 0.05792674014090683
    },
    {
      "step": 22450,
      "wer/private": 0.31447963800904977
    },
    {
      "epoch": 0.05625,
      "grad_norm": 0.44015464186668396,
      "learning_rate": 1.2395799507897865e-05,
      "loss": 0.1215,
      "step": 22450
    },
    {
      "epoch": 0.0565,
      "grad_norm": 0.5545837879180908,
      "learning_rate": 1.2384051405899659e-05,
      "loss": 0.1374,
      "step": 22460
    },
    {
      "epoch": 0.05675,
      "grad_norm": 0.4421905279159546,
      "learning_rate": 1.2372304958660398e-05,
      "loss": 0.1394,
      "step": 22470
    },
    {
      "epoch": 0.057,
      "grad_norm": 0.4529169797897339,
      "learning_rate": 1.2360560173610474e-05,
      "loss": 0.1298,
      "step": 22480
    },
    {
      "epoch": 0.05725,
      "grad_norm": 0.44046011567115784,
      "learning_rate": 1.234881705817924e-05,
      "loss": 0.1329,
      "step": 22490
    },
    {
      "step": 22500,
      "wer/bud500": 0.05783903879322946
    },
    {
      "step": 22500,
      "wer/private": 0.3438914027149321
    },
    {
      "epoch": 0.0575,
      "grad_norm": 0.45799720287323,
      "learning_rate": 1.2337075619794984e-05,
      "loss": 0.1323,
      "step": 22500
    },
    {
      "epoch": 0.0575,
      "eval_loss": 0.08036935329437256,
      "eval_runtime": 212.1478,
      "eval_samples_per_second": 35.353,
      "eval_steps_per_second": 0.278,
      "step": 22500
    },
    {
      "epoch": 0.05775,
      "grad_norm": 0.44765958189964294,
      "learning_rate": 1.232533586588493e-05,
      "loss": 0.1388,
      "step": 22510
    },
    {
      "epoch": 0.058,
      "grad_norm": 0.3216801583766937,
      "learning_rate": 1.2313597803875243e-05,
      "loss": 0.1324,
      "step": 22520
    },
    {
      "epoch": 0.05825,
      "grad_norm": 0.39671218395233154,
      "learning_rate": 1.2301861441191024e-05,
      "loss": 0.1392,
      "step": 22530
    },
    {
      "epoch": 0.0585,
      "grad_norm": 0.47658899426460266,
      "learning_rate": 1.2290126785256289e-05,
      "loss": 0.1365,
      "step": 22540
    },
    {
      "step": 22550,
      "wer/bud500": 0.05854064957464846
    },
    {
      "step": 22550,
      "wer/private": 0.3744343891402715
    },
    {
      "epoch": 0.05875,
      "grad_norm": 0.4878094792366028,
      "learning_rate": 1.227839384349397e-05,
      "loss": 0.1408,
      "step": 22550
    },
    {
      "epoch": 0.059,
      "grad_norm": 0.4803479313850403,
      "learning_rate": 1.226666262332593e-05,
      "loss": 0.1357,
      "step": 22560
    },
    {
      "epoch": 0.05925,
      "grad_norm": 0.47628915309906006,
      "learning_rate": 1.2254933132172932e-05,
      "loss": 0.1498,
      "step": 22570
    },
    {
      "epoch": 0.0595,
      "grad_norm": 0.41229256987571716,
      "learning_rate": 1.2243205377454641e-05,
      "loss": 0.1224,
      "step": 22580
    },
    {
      "epoch": 0.05975,
      "grad_norm": 0.4874604344367981,
      "learning_rate": 1.2231479366589638e-05,
      "loss": 0.1215,
      "step": 22590
    },
    {
      "step": 22600,
      "wer/bud500": 0.05846756511825065
    },
    {
      "step": 22600,
      "wer/private": 0.31447963800904977
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.47925692796707153,
      "learning_rate": 1.2219755106995399e-05,
      "loss": 0.1387,
      "step": 22600
    },
    {
      "epoch": 0.06,
      "eval_loss": 0.08029373735189438,
      "eval_runtime": 209.4648,
      "eval_samples_per_second": 35.806,
      "eval_steps_per_second": 0.282,
      "step": 22600
    },
    {
      "epoch": 0.06025,
      "grad_norm": 0.36730387806892395,
      "learning_rate": 1.2208032606088278e-05,
      "loss": 0.1305,
      "step": 22610
    },
    {
      "epoch": 0.0605,
      "grad_norm": 0.44481605291366577,
      "learning_rate": 1.2196311871283521e-05,
      "loss": 0.138,
      "step": 22620
    },
    {
      "epoch": 0.06075,
      "grad_norm": 0.5553949475288391,
      "learning_rate": 1.218459290999527e-05,
      "loss": 0.1398,
      "step": 22630
    },
    {
      "epoch": 0.061,
      "grad_norm": 0.4690137505531311,
      "learning_rate": 1.217287572963653e-05,
      "loss": 0.1338,
      "step": 22640
    },
    {
      "step": 22650,
      "wer/bud500": 0.058379863770573276
    },
    {
      "step": 22650,
      "wer/private": 0.3495475113122172
    },
    {
      "epoch": 0.06125,
      "grad_norm": 0.4549281597137451,
      "learning_rate": 1.2161160337619195e-05,
      "loss": 0.131,
      "step": 22650
    },
    {
      "epoch": 0.0615,
      "grad_norm": 0.4499809443950653,
      "learning_rate": 1.214944674135401e-05,
      "loss": 0.1402,
      "step": 22660
    },
    {
      "epoch": 0.06175,
      "grad_norm": 0.6434133648872375,
      "learning_rate": 1.2137734948250591e-05,
      "loss": 0.1502,
      "step": 22670
    },
    {
      "epoch": 0.062,
      "grad_norm": 0.4208946228027344,
      "learning_rate": 1.2126024965717416e-05,
      "loss": 0.1377,
      "step": 22680
    },
    {
      "epoch": 0.06225,
      "grad_norm": 0.48076140880584717,
      "learning_rate": 1.2114316801161824e-05,
      "loss": 0.1444,
      "step": 22690
    },
    {
      "step": 22700,
      "wer/bud500": 0.058204461075218525
    },
    {
      "step": 22700,
      "wer/private": 0.3167420814479638
    },
    {
      "epoch": 0.0625,
      "grad_norm": 0.3922748863697052,
      "learning_rate": 1.210261046198999e-05,
      "loss": 0.1279,
      "step": 22700
    },
    {
      "epoch": 0.0625,
      "eval_loss": 0.08030859380960464,
      "eval_runtime": 209.8709,
      "eval_samples_per_second": 35.736,
      "eval_steps_per_second": 0.281,
      "step": 22700
    },
    {
      "epoch": 0.06275,
      "grad_norm": 0.440358966588974,
      "learning_rate": 1.209090595560694e-05,
      "loss": 0.1349,
      "step": 22710
    },
    {
      "epoch": 0.063,
      "grad_norm": 0.46384432911872864,
      "learning_rate": 1.2079203289416546e-05,
      "loss": 0.1339,
      "step": 22720
    },
    {
      "epoch": 0.06325,
      "grad_norm": 0.455528199672699,
      "learning_rate": 1.2067502470821508e-05,
      "loss": 0.1469,
      "step": 22730
    },
    {
      "epoch": 0.0635,
      "grad_norm": 0.3993244767189026,
      "learning_rate": 1.2055803507223353e-05,
      "loss": 0.1293,
      "step": 22740
    },
    {
      "step": 22750,
      "wer/bud500": 0.0582921624228959
    },
    {
      "step": 22750,
      "wer/private": 0.35407239819004527
    },
    {
      "epoch": 0.06375,
      "grad_norm": 0.4108346104621887,
      "learning_rate": 1.2044106406022457e-05,
      "loss": 0.1317,
      "step": 22750
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.36253878474235535,
      "learning_rate": 1.2032411174617997e-05,
      "loss": 0.1315,
      "step": 22760
    },
    {
      "epoch": 0.06425,
      "grad_norm": 0.3444151282310486,
      "learning_rate": 1.2020717820407976e-05,
      "loss": 0.1419,
      "step": 22770
    },
    {
      "epoch": 0.0645,
      "grad_norm": 0.45949116349220276,
      "learning_rate": 1.2009026350789197e-05,
      "loss": 0.1391,
      "step": 22780
    },
    {
      "epoch": 0.06475,
      "grad_norm": 0.6481683254241943,
      "learning_rate": 1.1997336773157288e-05,
      "loss": 0.1291,
      "step": 22790
    },
    {
      "step": 22800,
      "wer/bud500": 0.058336013096734585
    },
    {
      "step": 22800,
      "wer/private": 0.31334841628959276
    },
    {
      "epoch": 0.065,
      "grad_norm": 0.5086299180984497,
      "learning_rate": 1.1985649094906679e-05,
      "loss": 0.1385,
      "step": 22800
    },
    {
      "epoch": 0.065,
      "eval_loss": 0.08010102808475494,
      "eval_runtime": 208.9756,
      "eval_samples_per_second": 35.889,
      "eval_steps_per_second": 0.282,
      "step": 22800
    },
    {
      "epoch": 0.00025,
      "grad_norm": 0.5127971172332764,
      "learning_rate": 1.1973963323430584e-05,
      "loss": 0.1313,
      "step": 22810
    },
    {
      "epoch": 0.0005,
      "grad_norm": 0.3555355966091156,
      "learning_rate": 1.196227946612102e-05,
      "loss": 0.1391,
      "step": 22820
    },
    {
      "epoch": 0.00075,
      "grad_norm": 0.5047056674957275,
      "learning_rate": 1.1950597530368798e-05,
      "loss": 0.1379,
      "step": 22830
    },
    {
      "epoch": 0.001,
      "grad_norm": 0.38533857464790344,
      "learning_rate": 1.1938917523563496e-05,
      "loss": 0.1328,
      "step": 22840
    },
    {
      "step": 22850,
      "wer/bud500": 0.05823369485777765
    },
    {
      "step": 22850,
      "wer/private": 0.35180995475113125
    },
    {
      "epoch": 0.00125,
      "grad_norm": 0.4908630847930908,
      "learning_rate": 1.1927239453093499e-05,
      "loss": 0.1383,
      "step": 22850
    },
    {
      "epoch": 0.0015,
      "grad_norm": 0.4087088704109192,
      "learning_rate": 1.1915563326345945e-05,
      "loss": 0.1312,
      "step": 22860
    },
    {
      "epoch": 0.00175,
      "grad_norm": 0.5262326598167419,
      "learning_rate": 1.1903889150706748e-05,
      "loss": 0.136,
      "step": 22870
    },
    {
      "epoch": 0.002,
      "grad_norm": 0.41588783264160156,
      "learning_rate": 1.1892216933560593e-05,
      "loss": 0.129,
      "step": 22880
    },
    {
      "epoch": 0.00225,
      "grad_norm": 0.489716112613678,
      "learning_rate": 1.188054668229092e-05,
      "loss": 0.1421,
      "step": 22890
    },
    {
      "step": 22900,
      "wer/bud500": 0.058379863770573276
    },
    {
      "step": 22900,
      "wer/private": 0.3235294117647059
    },
    {
      "epoch": 0.0025,
      "grad_norm": 0.39555343985557556,
      "learning_rate": 1.1868878404279922e-05,
      "loss": 0.1481,
      "step": 22900
    },
    {
      "epoch": 0.0025,
      "eval_loss": 0.08032044023275375,
      "eval_runtime": 218.2674,
      "eval_samples_per_second": 34.362,
      "eval_steps_per_second": 0.27,
      "step": 22900
    },
    {
      "epoch": 0.00275,
      "grad_norm": 0.46303483843803406,
      "learning_rate": 1.1857212106908558e-05,
      "loss": 0.1278,
      "step": 22910
    },
    {
      "epoch": 0.003,
      "grad_norm": 0.5164175629615784,
      "learning_rate": 1.1845547797556527e-05,
      "loss": 0.1238,
      "step": 22920
    },
    {
      "epoch": 0.00325,
      "grad_norm": 0.463162899017334,
      "learning_rate": 1.1833885483602266e-05,
      "loss": 0.1494,
      "step": 22930
    },
    {
      "epoch": 0.0035,
      "grad_norm": 0.4585305154323578,
      "learning_rate": 1.182222517242295e-05,
      "loss": 0.1328,
      "step": 22940
    },
    {
      "step": 22950,
      "wer/bud500": 0.05823369485777765
    },
    {
      "step": 22950,
      "wer/private": 0.33710407239819007
    },
    {
      "epoch": 0.00375,
      "grad_norm": 0.4794568717479706,
      "learning_rate": 1.1810566871394488e-05,
      "loss": 0.1308,
      "step": 22950
    },
    {
      "epoch": 0.004,
      "grad_norm": 0.4865657389163971,
      "learning_rate": 1.179891058789153e-05,
      "loss": 0.1341,
      "step": 22960
    },
    {
      "epoch": 0.00425,
      "grad_norm": 0.4437868297100067,
      "learning_rate": 1.1787256329287436e-05,
      "loss": 0.1367,
      "step": 22970
    },
    {
      "epoch": 0.0045,
      "grad_norm": 0.38956964015960693,
      "learning_rate": 1.1775604102954279e-05,
      "loss": 0.1363,
      "step": 22980
    },
    {
      "epoch": 0.00475,
      "grad_norm": 0.45599254965782166,
      "learning_rate": 1.1763953916262869e-05,
      "loss": 0.143,
      "step": 22990
    },
    {
      "step": 23000,
      "wer/bud500": 0.05807290905370246
    },
    {
      "step": 23000,
      "wer/private": 0.3608597285067873
    },
    {
      "epoch": 0.005,
      "grad_norm": 0.4812139570713043,
      "learning_rate": 1.17523057765827e-05,
      "loss": 0.1432,
      "step": 23000
    },
    {
      "epoch": 0.005,
      "eval_loss": 0.0805276557803154,
      "eval_runtime": 218.0729,
      "eval_samples_per_second": 34.392,
      "eval_steps_per_second": 0.271,
      "step": 23000
    },
    {
      "epoch": 0.00525,
      "grad_norm": 0.4844738841056824,
      "learning_rate": 1.1740659691281995e-05,
      "loss": 0.1395,
      "step": 23010
    },
    {
      "epoch": 0.0055,
      "grad_norm": 0.34966179728507996,
      "learning_rate": 1.172901566772766e-05,
      "loss": 0.128,
      "step": 23020
    },
    {
      "epoch": 0.00575,
      "grad_norm": 0.4914129078388214,
      "learning_rate": 1.1717373713285303e-05,
      "loss": 0.1344,
      "step": 23030
    },
    {
      "epoch": 0.006,
      "grad_norm": 0.486214280128479,
      "learning_rate": 1.1705733835319228e-05,
      "loss": 0.1397,
      "step": 23040
    },
    {
      "step": 23050,
      "wer/bud500": 0.057663636097874706
    },
    {
      "step": 23050,
      "wer/private": 0.3257918552036199
    },
    {
      "epoch": 0.00625,
      "grad_norm": 0.43292737007141113,
      "learning_rate": 1.1694096041192416e-05,
      "loss": 0.1337,
      "step": 23050
    },
    {
      "epoch": 0.0065,
      "grad_norm": 0.42713287472724915,
      "learning_rate": 1.1682460338266532e-05,
      "loss": 0.1267,
      "step": 23060
    },
    {
      "epoch": 0.00675,
      "grad_norm": 0.39781469106674194,
      "learning_rate": 1.1670826733901927e-05,
      "loss": 0.1504,
      "step": 23070
    },
    {
      "epoch": 0.007,
      "grad_norm": 0.4557563066482544,
      "learning_rate": 1.1659195235457619e-05,
      "loss": 0.1305,
      "step": 23080
    },
    {
      "epoch": 0.00725,
      "grad_norm": 0.4869898557662964,
      "learning_rate": 1.164756585029129e-05,
      "loss": 0.1332,
      "step": 23090
    },
    {
      "step": 23100,
      "wer/bud500": 0.057736720554272515
    },
    {
      "step": 23100,
      "wer/private": 0.3246606334841629
    },
    {
      "epoch": 0.0075,
      "grad_norm": 0.49392884969711304,
      "learning_rate": 1.1635938585759284e-05,
      "loss": 0.1286,
      "step": 23100
    },
    {
      "epoch": 0.0075,
      "eval_loss": 0.08025232702493668,
      "eval_runtime": 218.3761,
      "eval_samples_per_second": 34.344,
      "eval_steps_per_second": 0.27,
      "step": 23100
    },
    {
      "epoch": 0.00775,
      "grad_norm": 0.45402881503105164,
      "learning_rate": 1.162431344921661e-05,
      "loss": 0.1375,
      "step": 23110
    },
    {
      "epoch": 0.008,
      "grad_norm": 0.4116882085800171,
      "learning_rate": 1.1612690448016938e-05,
      "loss": 0.1215,
      "step": 23120
    },
    {
      "epoch": 0.00825,
      "grad_norm": 0.5628342032432556,
      "learning_rate": 1.1601069589512573e-05,
      "loss": 0.1356,
      "step": 23130
    },
    {
      "epoch": 0.0085,
      "grad_norm": 0.38691794872283936,
      "learning_rate": 1.1589450881054462e-05,
      "loss": 0.1369,
      "step": 23140
    },
    {
      "step": 23150,
      "wer/bud500": 0.05801444148858421
    },
    {
      "step": 23150,
      "wer/private": 0.32805429864253394
    },
    {
      "epoch": 0.00875,
      "grad_norm": 0.5695813298225403,
      "learning_rate": 1.157783432999221e-05,
      "loss": 0.148,
      "step": 23150
    },
    {
      "epoch": 0.009,
      "grad_norm": 0.4915000796318054,
      "learning_rate": 1.1566219943674036e-05,
      "loss": 0.1257,
      "step": 23160
    },
    {
      "epoch": 0.00925,
      "grad_norm": 0.48089635372161865,
      "learning_rate": 1.1554607729446814e-05,
      "loss": 0.1389,
      "step": 23170
    },
    {
      "epoch": 0.0095,
      "grad_norm": 0.3943610191345215,
      "learning_rate": 1.1542997694656023e-05,
      "loss": 0.1392,
      "step": 23180
    },
    {
      "epoch": 0.00975,
      "grad_norm": 0.3871561288833618,
      "learning_rate": 1.1531389846645768e-05,
      "loss": 0.1315,
      "step": 23190
    },
    {
      "step": 23200,
      "wer/bud500": 0.0581752272926594
    },
    {
      "step": 23200,
      "wer/private": 0.334841628959276
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.44551175832748413,
      "learning_rate": 1.151978419275878e-05,
      "loss": 0.1301,
      "step": 23200
    },
    {
      "epoch": 0.01,
      "eval_loss": 0.08045461773872375,
      "eval_runtime": 217.7985,
      "eval_samples_per_second": 34.436,
      "eval_steps_per_second": 0.271,
      "step": 23200
    },
    {
      "epoch": 0.01025,
      "grad_norm": 0.4957370460033417,
      "learning_rate": 1.1508180740336393e-05,
      "loss": 0.1238,
      "step": 23210
    },
    {
      "epoch": 0.0105,
      "grad_norm": 0.5313831567764282,
      "learning_rate": 1.1496579496718547e-05,
      "loss": 0.138,
      "step": 23220
    },
    {
      "epoch": 0.01075,
      "grad_norm": 0.5383021831512451,
      "learning_rate": 1.1484980469243794e-05,
      "loss": 0.1539,
      "step": 23230
    },
    {
      "epoch": 0.011,
      "grad_norm": 0.40071216225624084,
      "learning_rate": 1.1473383665249281e-05,
      "loss": 0.1404,
      "step": 23240
    },
    {
      "step": 23250,
      "wer/bud500": 0.058029058379863774
    },
    {
      "step": 23250,
      "wer/private": 0.3235294117647059
    },
    {
      "epoch": 0.01125,
      "grad_norm": 0.41593143343925476,
      "learning_rate": 1.1461789092070746e-05,
      "loss": 0.1432,
      "step": 23250
    },
    {
      "epoch": 0.0115,
      "grad_norm": 0.4621095657348633,
      "learning_rate": 1.145019675704251e-05,
      "loss": 0.1325,
      "step": 23260
    },
    {
      "epoch": 0.01175,
      "grad_norm": 0.4259403347969055,
      "learning_rate": 1.1438606667497486e-05,
      "loss": 0.1275,
      "step": 23270
    },
    {
      "epoch": 0.012,
      "grad_norm": 0.39950037002563477,
      "learning_rate": 1.1427018830767175e-05,
      "loss": 0.1341,
      "step": 23280
    },
    {
      "epoch": 0.01225,
      "grad_norm": 0.43545618653297424,
      "learning_rate": 1.1415433254181636e-05,
      "loss": 0.1469,
      "step": 23290
    },
    {
      "step": 23300,
      "wer/bud500": 0.05804367527114333
    },
    {
      "step": 23300,
      "wer/private": 0.3201357466063348
    },
    {
      "epoch": 0.0125,
      "grad_norm": 0.4557788372039795,
      "learning_rate": 1.1403849945069504e-05,
      "loss": 0.1363,
      "step": 23300
    },
    {
      "epoch": 0.0125,
      "eval_loss": 0.08026730269193649,
      "eval_runtime": 219.2062,
      "eval_samples_per_second": 34.214,
      "eval_steps_per_second": 0.269,
      "step": 23300
    },
    {
      "epoch": 0.01275,
      "grad_norm": 0.3500601649284363,
      "learning_rate": 1.1392268910757985e-05,
      "loss": 0.1374,
      "step": 23310
    },
    {
      "epoch": 0.013,
      "grad_norm": 0.43243902921676636,
      "learning_rate": 1.1380690158572835e-05,
      "loss": 0.1312,
      "step": 23320
    },
    {
      "epoch": 0.01325,
      "grad_norm": 0.41129910945892334,
      "learning_rate": 1.1369113695838386e-05,
      "loss": 0.14,
      "step": 23330
    },
    {
      "epoch": 0.0135,
      "grad_norm": 0.417011022567749,
      "learning_rate": 1.13575395298775e-05,
      "loss": 0.1235,
      "step": 23340
    },
    {
      "step": 23350,
      "wer/bud500": 0.057970590814745517
    },
    {
      "step": 23350,
      "wer/private": 0.3246606334841629
    },
    {
      "epoch": 0.01375,
      "grad_norm": 0.35297754406929016,
      "learning_rate": 1.13459676680116e-05,
      "loss": 0.1421,
      "step": 23350
    },
    {
      "epoch": 0.014,
      "grad_norm": 0.4667081832885742,
      "learning_rate": 1.1334398117560645e-05,
      "loss": 0.1355,
      "step": 23360
    },
    {
      "epoch": 0.01425,
      "grad_norm": 0.3935386836528778,
      "learning_rate": 1.1322830885843133e-05,
      "loss": 0.1246,
      "step": 23370
    },
    {
      "epoch": 0.0145,
      "grad_norm": 0.43014657497406006,
      "learning_rate": 1.1311265980176097e-05,
      "loss": 0.133,
      "step": 23380
    },
    {
      "epoch": 0.01475,
      "grad_norm": 0.5393518805503845,
      "learning_rate": 1.1299703407875097e-05,
      "loss": 0.1227,
      "step": 23390
    },
    {
      "step": 23400,
      "wer/bud500": 0.058262928640336775
    },
    {
      "step": 23400,
      "wer/private": 0.3223981900452489
    },
    {
      "epoch": 0.015,
      "grad_norm": 0.45907196402549744,
      "learning_rate": 1.1288143176254223e-05,
      "loss": 0.139,
      "step": 23400
    },
    {
      "epoch": 0.015,
      "eval_loss": 0.08012033253908157,
      "eval_runtime": 218.7588,
      "eval_samples_per_second": 34.284,
      "eval_steps_per_second": 0.27,
      "step": 23400
    },
    {
      "epoch": 0.01525,
      "grad_norm": 0.44100096821784973,
      "learning_rate": 1.1276585292626075e-05,
      "loss": 0.1541,
      "step": 23410
    },
    {
      "epoch": 0.0155,
      "grad_norm": 0.39252543449401855,
      "learning_rate": 1.126502976430177e-05,
      "loss": 0.1201,
      "step": 23420
    },
    {
      "epoch": 0.01575,
      "grad_norm": 0.5619999170303345,
      "learning_rate": 1.1253476598590936e-05,
      "loss": 0.1277,
      "step": 23430
    },
    {
      "epoch": 0.016,
      "grad_norm": 0.408823698759079,
      "learning_rate": 1.1241925802801715e-05,
      "loss": 0.1296,
      "step": 23440
    },
    {
      "step": 23450,
      "wer/bud500": 0.05798520770602508
    },
    {
      "step": 23450,
      "wer/private": 0.3212669683257919
    },
    {
      "epoch": 0.01625,
      "grad_norm": 0.5178585052490234,
      "learning_rate": 1.1230377384240744e-05,
      "loss": 0.1463,
      "step": 23450
    },
    {
      "epoch": 0.0165,
      "grad_norm": 0.40803512930870056,
      "learning_rate": 1.1218831350213141e-05,
      "loss": 0.1347,
      "step": 23460
    },
    {
      "epoch": 0.01675,
      "grad_norm": 0.40015408396720886,
      "learning_rate": 1.1207287708022541e-05,
      "loss": 0.1292,
      "step": 23470
    },
    {
      "epoch": 0.017,
      "grad_norm": 0.4303175210952759,
      "learning_rate": 1.1195746464971045e-05,
      "loss": 0.1325,
      "step": 23480
    },
    {
      "epoch": 0.01725,
      "grad_norm": 0.6017554402351379,
      "learning_rate": 1.1184207628359257e-05,
      "loss": 0.1452,
      "step": 23490
    },
    {
      "step": 23500,
      "wer/bud500": 0.057912123249627266
    },
    {
      "step": 23500,
      "wer/private": 0.3178733031674208
    },
    {
      "epoch": 0.0175,
      "grad_norm": 0.461232990026474,
      "learning_rate": 1.1172671205486237e-05,
      "loss": 0.1289,
      "step": 23500
    },
    {
      "epoch": 0.0175,
      "eval_loss": 0.07986216247081757,
      "eval_runtime": 218.8152,
      "eval_samples_per_second": 34.275,
      "eval_steps_per_second": 0.27,
      "step": 23500
    },
    {
      "epoch": 0.01775,
      "grad_norm": 0.4639190137386322,
      "learning_rate": 1.1161137203649538e-05,
      "loss": 0.1296,
      "step": 23510
    },
    {
      "epoch": 0.018,
      "grad_norm": 0.49598419666290283,
      "learning_rate": 1.1149605630145166e-05,
      "loss": 0.1244,
      "step": 23520
    },
    {
      "epoch": 0.01825,
      "grad_norm": 0.46445780992507935,
      "learning_rate": 1.1138076492267594e-05,
      "loss": 0.1372,
      "step": 23530
    },
    {
      "epoch": 0.0185,
      "grad_norm": 0.5134653449058533,
      "learning_rate": 1.1126549797309767e-05,
      "loss": 0.1367,
      "step": 23540
    },
    {
      "step": 23550,
      "wer/bud500": 0.058087525944982024
    },
    {
      "step": 23550,
      "wer/private": 0.3235294117647059
    },
    {
      "epoch": 0.01875,
      "grad_norm": 0.4678299129009247,
      "learning_rate": 1.1115025552563068e-05,
      "loss": 0.1358,
      "step": 23550
    },
    {
      "epoch": 0.019,
      "grad_norm": 0.42279160022735596,
      "learning_rate": 1.110350376531734e-05,
      "loss": 0.1236,
      "step": 23560
    },
    {
      "epoch": 0.01925,
      "grad_norm": 0.4466579556465149,
      "learning_rate": 1.109198444286087e-05,
      "loss": 0.1431,
      "step": 23570
    },
    {
      "epoch": 0.0195,
      "grad_norm": 0.4992883503437042,
      "learning_rate": 1.1080467592480376e-05,
      "loss": 0.1301,
      "step": 23580
    },
    {
      "epoch": 0.01975,
      "grad_norm": 0.44159725308418274,
      "learning_rate": 1.1068953221461025e-05,
      "loss": 0.1271,
      "step": 23590
    },
    {
      "step": 23600,
      "wer/bud500": 0.05782442190194989
    },
    {
      "step": 23600,
      "wer/private": 0.31334841628959276
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.43093276023864746,
      "learning_rate": 1.1057441337086418e-05,
      "loss": 0.1233,
      "step": 23600
    },
    {
      "epoch": 0.02,
      "eval_loss": 0.07984434068202972,
      "eval_runtime": 218.1028,
      "eval_samples_per_second": 34.387,
      "eval_steps_per_second": 0.271,
      "step": 23600
    },
    {
      "epoch": 0.02025,
      "grad_norm": 0.39468854665756226,
      "learning_rate": 1.1045931946638574e-05,
      "loss": 0.1439,
      "step": 23610
    },
    {
      "epoch": 0.0205,
      "grad_norm": 0.5079989433288574,
      "learning_rate": 1.103442505739793e-05,
      "loss": 0.1244,
      "step": 23620
    },
    {
      "epoch": 0.02075,
      "grad_norm": 0.572655439376831,
      "learning_rate": 1.1022920676643356e-05,
      "loss": 0.1313,
      "step": 23630
    },
    {
      "epoch": 0.021,
      "grad_norm": 0.4802888333797455,
      "learning_rate": 1.1011418811652114e-05,
      "loss": 0.1539,
      "step": 23640
    },
    {
      "step": 23650,
      "wer/bud500": 0.05804367527114333
    },
    {
      "step": 23650,
      "wer/private": 0.3235294117647059
    },
    {
      "epoch": 0.02125,
      "grad_norm": 0.34026503562927246,
      "learning_rate": 1.0999919469699903e-05,
      "loss": 0.1274,
      "step": 23650
    },
    {
      "epoch": 0.0215,
      "grad_norm": 0.4670257568359375,
      "learning_rate": 1.0988422658060803e-05,
      "loss": 0.1483,
      "step": 23660
    },
    {
      "epoch": 0.02175,
      "grad_norm": 0.3674069344997406,
      "learning_rate": 1.0976928384007301e-05,
      "loss": 0.1306,
      "step": 23670
    },
    {
      "epoch": 0.022,
      "grad_norm": 0.43358102440834045,
      "learning_rate": 1.0965436654810282e-05,
      "loss": 0.1287,
      "step": 23680
    },
    {
      "epoch": 0.02225,
      "grad_norm": 0.4920121729373932,
      "learning_rate": 1.0953947477739009e-05,
      "loss": 0.1378,
      "step": 23690
    },
    {
      "step": 23700,
      "wer/bud500": 0.057795188119390765
    },
    {
      "step": 23700,
      "wer/private": 0.3178733031674208
    },
    {
      "epoch": 0.0225,
      "grad_norm": 0.49301472306251526,
      "learning_rate": 1.0942460860061147e-05,
      "loss": 0.132,
      "step": 23700
    },
    {
      "epoch": 0.0225,
      "eval_loss": 0.0797923281788826,
      "eval_runtime": 218.0708,
      "eval_samples_per_second": 34.392,
      "eval_steps_per_second": 0.271,
      "step": 23700
    },
    {
      "epoch": 0.02275,
      "grad_norm": 0.42450305819511414,
      "learning_rate": 1.0930976809042739e-05,
      "loss": 0.1311,
      "step": 23710
    },
    {
      "epoch": 0.023,
      "grad_norm": 0.36652326583862305,
      "learning_rate": 1.0919495331948193e-05,
      "loss": 0.1286,
      "step": 23720
    },
    {
      "epoch": 0.02325,
      "grad_norm": 0.4013921320438385,
      "learning_rate": 1.0908016436040293e-05,
      "loss": 0.1377,
      "step": 23730
    },
    {
      "epoch": 0.0235,
      "grad_norm": 0.3951074481010437,
      "learning_rate": 1.0896540128580202e-05,
      "loss": 0.1316,
      "step": 23740
    },
    {
      "step": 23750,
      "wer/bud500": 0.05775133744555208
    },
    {
      "step": 23750,
      "wer/private": 0.3223981900452489
    },
    {
      "epoch": 0.02375,
      "grad_norm": 0.4766060709953308,
      "learning_rate": 1.0885066416827424e-05,
      "loss": 0.1421,
      "step": 23750
    },
    {
      "epoch": 0.024,
      "grad_norm": 0.4620357155799866,
      "learning_rate": 1.0873595308039849e-05,
      "loss": 0.1505,
      "step": 23760
    },
    {
      "epoch": 0.02425,
      "grad_norm": 0.39732906222343445,
      "learning_rate": 1.0862126809473697e-05,
      "loss": 0.1407,
      "step": 23770
    },
    {
      "epoch": 0.0245,
      "grad_norm": 0.4544658064842224,
      "learning_rate": 1.0850660928383541e-05,
      "loss": 0.1231,
      "step": 23780
    },
    {
      "epoch": 0.02475,
      "grad_norm": 0.6498977541923523,
      "learning_rate": 1.0839197672022313e-05,
      "loss": 0.1233,
      "step": 23790
    },
    {
      "step": 23800,
      "wer/bud500": 0.05770748677171339
    },
    {
      "step": 23800,
      "wer/private": 0.3167420814479638
    },
    {
      "epoch": 0.025,
      "grad_norm": 0.5231620073318481,
      "learning_rate": 1.0827737047641259e-05,
      "loss": 0.132,
      "step": 23800
    },
    {
      "epoch": 0.025,
      "eval_loss": 0.07995224744081497,
      "eval_runtime": 218.8089,
      "eval_samples_per_second": 34.276,
      "eval_steps_per_second": 0.27,
      "step": 23800
    },
    {
      "epoch": 0.02525,
      "grad_norm": 0.4223066568374634,
      "learning_rate": 1.081627906248999e-05,
      "loss": 0.1397,
      "step": 23810
    },
    {
      "epoch": 0.0255,
      "grad_norm": 0.4382164180278778,
      "learning_rate": 1.0804823723816426e-05,
      "loss": 0.1377,
      "step": 23820
    },
    {
      "epoch": 0.02575,
      "grad_norm": 0.39657023549079895,
      "learning_rate": 1.0793371038866821e-05,
      "loss": 0.1317,
      "step": 23830
    },
    {
      "epoch": 0.026,
      "grad_norm": 0.5390052199363708,
      "learning_rate": 1.078192101488575e-05,
      "loss": 0.117,
      "step": 23840
    },
    {
      "step": 23850,
      "wer/bud500": 0.05798520770602508
    },
    {
      "step": 23850,
      "wer/private": 0.3223981900452489
    },
    {
      "epoch": 0.02625,
      "grad_norm": 0.41869544982910156,
      "learning_rate": 1.0770473659116095e-05,
      "loss": 0.1337,
      "step": 23850
    },
    {
      "epoch": 0.0265,
      "grad_norm": 0.4356766939163208,
      "learning_rate": 1.0759028978799068e-05,
      "loss": 0.1349,
      "step": 23860
    },
    {
      "epoch": 0.02675,
      "grad_norm": 0.4022098481655121,
      "learning_rate": 1.0747586981174179e-05,
      "loss": 0.1283,
      "step": 23870
    },
    {
      "epoch": 0.027,
      "grad_norm": 0.4472741484642029,
      "learning_rate": 1.073614767347924e-05,
      "loss": 0.1359,
      "step": 23880
    },
    {
      "epoch": 0.02725,
      "grad_norm": 0.46608638763427734,
      "learning_rate": 1.0724711062950358e-05,
      "loss": 0.1358,
      "step": 23890
    },
    {
      "step": 23900,
      "wer/bud500": 0.058145993510100275
    },
    {
      "step": 23900,
      "wer/private": 0.3246606334841629
    },
    {
      "epoch": 0.0275,
      "grad_norm": 0.37060776352882385,
      "learning_rate": 1.0713277156821948e-05,
      "loss": 0.1262,
      "step": 23900
    },
    {
      "epoch": 0.0275,
      "eval_loss": 0.08001236617565155,
      "eval_runtime": 218.0937,
      "eval_samples_per_second": 34.389,
      "eval_steps_per_second": 0.271,
      "step": 23900
    },
    {
      "epoch": 0.02775,
      "grad_norm": 0.45523175597190857,
      "learning_rate": 1.0701845962326694e-05,
      "loss": 0.1254,
      "step": 23910
    },
    {
      "epoch": 0.028,
      "grad_norm": 0.4512215852737427,
      "learning_rate": 1.0690417486695585e-05,
      "loss": 0.1343,
      "step": 23920
    },
    {
      "epoch": 0.02825,
      "grad_norm": 0.5000376105308533,
      "learning_rate": 1.0678991737157879e-05,
      "loss": 0.1362,
      "step": 23930
    },
    {
      "epoch": 0.0285,
      "grad_norm": 0.40734803676605225,
      "learning_rate": 1.0667568720941109e-05,
      "loss": 0.1349,
      "step": 23940
    },
    {
      "step": 23950,
      "wer/bud500": 0.05775133744555208
    },
    {
      "step": 23950,
      "wer/private": 0.3246606334841629
    },
    {
      "epoch": 0.02875,
      "grad_norm": 0.5101925730705261,
      "learning_rate": 1.0656148445271083e-05,
      "loss": 0.1363,
      "step": 23950
    },
    {
      "epoch": 0.029,
      "grad_norm": 0.38316479325294495,
      "learning_rate": 1.0644730917371868e-05,
      "loss": 0.1241,
      "step": 23960
    },
    {
      "epoch": 0.02925,
      "grad_norm": 0.40160104632377625,
      "learning_rate": 1.0633316144465812e-05,
      "loss": 0.1338,
      "step": 23970
    },
    {
      "epoch": 0.0295,
      "grad_norm": 0.5209485292434692,
      "learning_rate": 1.0621904133773492e-05,
      "loss": 0.1385,
      "step": 23980
    },
    {
      "epoch": 0.02975,
      "grad_norm": 0.5159090161323547,
      "learning_rate": 1.0610494892513764e-05,
      "loss": 0.1437,
      "step": 23990
    },
    {
      "step": 24000,
      "wer/bud500": 0.05799982459730465
    },
    {
      "step": 24000,
      "wer/private": 0.35294117647058826
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4274889826774597,
      "learning_rate": 1.0599088427903718e-05,
      "loss": 0.137,
      "step": 24000
    },
    {
      "epoch": 0.03,
      "eval_loss": 0.07997291535139084,
      "eval_runtime": 218.2043,
      "eval_samples_per_second": 34.371,
      "eval_steps_per_second": 0.27,
      "step": 24000
    },
    {
      "epoch": 0.03025,
      "grad_norm": 0.4979729652404785,
      "learning_rate": 1.0587684747158684e-05,
      "loss": 0.1382,
      "step": 24010
    },
    {
      "epoch": 0.0305,
      "grad_norm": 0.4689334034919739,
      "learning_rate": 1.0576283857492246e-05,
      "loss": 0.1328,
      "step": 24020
    },
    {
      "epoch": 0.03075,
      "grad_norm": 0.4690973460674286,
      "learning_rate": 1.0564885766116212e-05,
      "loss": 0.1358,
      "step": 24030
    },
    {
      "epoch": 0.031,
      "grad_norm": 0.5039046406745911,
      "learning_rate": 1.055349048024062e-05,
      "loss": 0.1347,
      "step": 24040
    },
    {
      "step": 24050,
      "wer/bud500": 0.057722103662992956
    },
    {
      "step": 24050,
      "wer/private": 0.34728506787330315
    },
    {
      "epoch": 0.03125,
      "grad_norm": 0.6458234786987305,
      "learning_rate": 1.0542098007073735e-05,
      "loss": 0.1365,
      "step": 24050
    },
    {
      "epoch": 0.0315,
      "grad_norm": 0.5447601675987244,
      "learning_rate": 1.0530708353822045e-05,
      "loss": 0.1244,
      "step": 24060
    },
    {
      "epoch": 0.03175,
      "grad_norm": 0.4555150270462036,
      "learning_rate": 1.0519321527690246e-05,
      "loss": 0.1325,
      "step": 24070
    },
    {
      "epoch": 0.032,
      "grad_norm": 0.494295209646225,
      "learning_rate": 1.0507937535881262e-05,
      "loss": 0.1415,
      "step": 24080
    },
    {
      "epoch": 0.03225,
      "grad_norm": 0.38561365008354187,
      "learning_rate": 1.0496556385596208e-05,
      "loss": 0.1381,
      "step": 24090
    },
    {
      "step": 24100,
      "wer/bud500": 0.05776595433683164
    },
    {
      "step": 24100,
      "wer/private": 0.332579185520362
    },
    {
      "epoch": 0.0325,
      "grad_norm": 0.480351060628891,
      "learning_rate": 1.0485178084034407e-05,
      "loss": 0.13,
      "step": 24100
    },
    {
      "epoch": 0.0325,
      "eval_loss": 0.0800442025065422,
      "eval_runtime": 218.8593,
      "eval_samples_per_second": 34.269,
      "eval_steps_per_second": 0.27,
      "step": 24100
    },
    {
      "epoch": 0.03275,
      "grad_norm": 0.41374677419662476,
      "learning_rate": 1.047380263839338e-05,
      "loss": 0.1353,
      "step": 24110
    },
    {
      "epoch": 0.033,
      "grad_norm": 0.6033815145492554,
      "learning_rate": 1.0462430055868843e-05,
      "loss": 0.1412,
      "step": 24120
    },
    {
      "epoch": 0.03325,
      "grad_norm": 0.4502563178539276,
      "learning_rate": 1.0451060343654705e-05,
      "loss": 0.1347,
      "step": 24130
    },
    {
      "epoch": 0.0335,
      "grad_norm": 0.4505102038383484,
      "learning_rate": 1.0439693508943047e-05,
      "loss": 0.1252,
      "step": 24140
    },
    {
      "step": 24150,
      "wer/bud500": 0.057970590814745517
    },
    {
      "step": 24150,
      "wer/private": 0.33144796380090497
    },
    {
      "epoch": 0.03375,
      "grad_norm": 0.43869349360466003,
      "learning_rate": 1.042832955892414e-05,
      "loss": 0.1281,
      "step": 24150
    },
    {
      "epoch": 0.034,
      "grad_norm": 0.7578946352005005,
      "learning_rate": 1.0416968500786432e-05,
      "loss": 0.1415,
      "step": 24160
    },
    {
      "epoch": 0.03425,
      "grad_norm": 0.5338166356086731,
      "learning_rate": 1.0405610341716521e-05,
      "loss": 0.1401,
      "step": 24170
    },
    {
      "epoch": 0.0345,
      "grad_norm": 0.3756924569606781,
      "learning_rate": 1.0394255088899203e-05,
      "loss": 0.1242,
      "step": 24180
    },
    {
      "epoch": 0.03475,
      "grad_norm": 0.5428204536437988,
      "learning_rate": 1.0382902749517418e-05,
      "loss": 0.1347,
      "step": 24190
    },
    {
      "step": 24200,
      "wer/bud500": 0.058029058379863774
    },
    {
      "step": 24200,
      "wer/private": 0.36312217194570134
    },
    {
      "epoch": 0.035,
      "grad_norm": 0.47341665625572205,
      "learning_rate": 1.037155333075226e-05,
      "loss": 0.1465,
      "step": 24200
    },
    {
      "epoch": 0.035,
      "eval_loss": 0.0800667256116867,
      "eval_runtime": 218.4933,
      "eval_samples_per_second": 34.326,
      "eval_steps_per_second": 0.27,
      "step": 24200
    },
    {
      "epoch": 0.03525,
      "grad_norm": 0.4261589050292969,
      "learning_rate": 1.036020683978298e-05,
      "loss": 0.1443,
      "step": 24210
    },
    {
      "epoch": 0.0355,
      "grad_norm": 0.4725422263145447,
      "learning_rate": 1.0348863283786978e-05,
      "loss": 0.1443,
      "step": 24220
    },
    {
      "epoch": 0.03575,
      "grad_norm": 0.5129701495170593,
      "learning_rate": 1.0337522669939794e-05,
      "loss": 0.147,
      "step": 24230
    },
    {
      "epoch": 0.036,
      "grad_norm": 0.478888601064682,
      "learning_rate": 1.0326185005415119e-05,
      "loss": 0.1307,
      "step": 24240
    },
    {
      "step": 24250,
      "wer/bud500": 0.0582921624228959
    },
    {
      "step": 24250,
      "wer/private": 0.33597285067873306
    },
    {
      "epoch": 0.03625,
      "grad_norm": 0.4665571451187134,
      "learning_rate": 1.0314850297384759e-05,
      "loss": 0.1344,
      "step": 24250
    },
    {
      "epoch": 0.0365,
      "grad_norm": 0.6128502488136292,
      "learning_rate": 1.0303518553018668e-05,
      "loss": 0.1464,
      "step": 24260
    },
    {
      "epoch": 0.03675,
      "grad_norm": 0.37259742617607117,
      "learning_rate": 1.0292189779484912e-05,
      "loss": 0.1505,
      "step": 24270
    },
    {
      "epoch": 0.037,
      "grad_norm": 0.41063880920410156,
      "learning_rate": 1.0280863983949674e-05,
      "loss": 0.1209,
      "step": 24280
    },
    {
      "epoch": 0.03725,
      "grad_norm": 0.5209460258483887,
      "learning_rate": 1.0269541173577282e-05,
      "loss": 0.1402,
      "step": 24290
    },
    {
      "step": 24300,
      "wer/bud500": 0.05783903879322946
    },
    {
      "step": 24300,
      "wer/private": 0.3190045248868778
    },
    {
      "epoch": 0.0375,
      "grad_norm": 0.6229617595672607,
      "learning_rate": 1.0258221355530138e-05,
      "loss": 0.1511,
      "step": 24300
    },
    {
      "epoch": 0.0375,
      "eval_loss": 0.07990626990795135,
      "eval_runtime": 217.6918,
      "eval_samples_per_second": 34.452,
      "eval_steps_per_second": 0.271,
      "step": 24300
    },
    {
      "epoch": 0.03775,
      "grad_norm": 0.3399032652378082,
      "learning_rate": 1.0246904536968783e-05,
      "loss": 0.1381,
      "step": 24310
    },
    {
      "epoch": 0.038,
      "grad_norm": 0.4635818898677826,
      "learning_rate": 1.0235590725051836e-05,
      "loss": 0.1382,
      "step": 24320
    },
    {
      "epoch": 0.03825,
      "grad_norm": 0.4050939977169037,
      "learning_rate": 1.0224279926936024e-05,
      "loss": 0.1362,
      "step": 24330
    },
    {
      "epoch": 0.0385,
      "grad_norm": 0.503463089466095,
      "learning_rate": 1.0212972149776174e-05,
      "loss": 0.1245,
      "step": 24340
    },
    {
      "step": 24350,
      "wer/bud500": 0.057561317858917764
    },
    {
      "step": 24350,
      "wer/private": 0.34841628959276016
    },
    {
      "epoch": 0.03875,
      "grad_norm": 0.44255295395851135,
      "learning_rate": 1.0201667400725198e-05,
      "loss": 0.1363,
      "step": 24350
    },
    {
      "epoch": 0.039,
      "grad_norm": 0.42206820845603943,
      "learning_rate": 1.0190365686934087e-05,
      "loss": 0.1321,
      "step": 24360
    },
    {
      "epoch": 0.03925,
      "grad_norm": 0.5500184297561646,
      "learning_rate": 1.0179067015551911e-05,
      "loss": 0.1467,
      "step": 24370
    },
    {
      "epoch": 0.0395,
      "grad_norm": 0.4289875626564026,
      "learning_rate": 1.0167771393725829e-05,
      "loss": 0.1414,
      "step": 24380
    },
    {
      "epoch": 0.03975,
      "grad_norm": 0.455838143825531,
      "learning_rate": 1.0156478828601053e-05,
      "loss": 0.1376,
      "step": 24390
    },
    {
      "step": 24400,
      "wer/bud500": 0.05776595433683164
    },
    {
      "step": 24400,
      "wer/private": 0.36538461538461536
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.45463883876800537,
      "learning_rate": 1.0145189327320879e-05,
      "loss": 0.1435,
      "step": 24400
    },
    {
      "epoch": 0.04,
      "eval_loss": 0.08032965660095215,
      "eval_runtime": 218.3054,
      "eval_samples_per_second": 34.356,
      "eval_steps_per_second": 0.27,
      "step": 24400
    },
    {
      "epoch": 0.04025,
      "grad_norm": 0.4405596852302551,
      "learning_rate": 1.0133902897026653e-05,
      "loss": 0.1339,
      "step": 24410
    },
    {
      "epoch": 0.0405,
      "grad_norm": 0.3937590420246124,
      "learning_rate": 1.0122619544857784e-05,
      "loss": 0.1291,
      "step": 24420
    },
    {
      "epoch": 0.04075,
      "grad_norm": 0.3251100182533264,
      "learning_rate": 1.0111339277951728e-05,
      "loss": 0.123,
      "step": 24430
    },
    {
      "epoch": 0.041,
      "grad_norm": 0.6184497475624084,
      "learning_rate": 1.0100062103443991e-05,
      "loss": 0.1333,
      "step": 24440
    },
    {
      "step": 24450,
      "wer/bud500": 0.057561317858917764
    },
    {
      "step": 24450,
      "wer/private": 0.36538461538461536
    },
    {
      "epoch": 0.04125,
      "grad_norm": 0.4410824179649353,
      "learning_rate": 1.0088788028468137e-05,
      "loss": 0.1493,
      "step": 24450
    },
    {
      "epoch": 0.0415,
      "grad_norm": 0.45839864015579224,
      "learning_rate": 1.0077517060155744e-05,
      "loss": 0.1312,
      "step": 24460
    },
    {
      "epoch": 0.04175,
      "grad_norm": 0.5010154843330383,
      "learning_rate": 1.0066249205636446e-05,
      "loss": 0.1438,
      "step": 24470
    },
    {
      "epoch": 0.042,
      "grad_norm": 0.4214656949043274,
      "learning_rate": 1.0054984472037898e-05,
      "loss": 0.1314,
      "step": 24480
    },
    {
      "epoch": 0.04225,
      "grad_norm": 0.4324755370616913,
      "learning_rate": 1.0043722866485774e-05,
      "loss": 0.1426,
      "step": 24490
    },
    {
      "step": 24500,
      "wer/bud500": 0.05811675972754115
    },
    {
      "step": 24500,
      "wer/private": 0.3427601809954751
    },
    {
      "epoch": 0.0425,
      "grad_norm": 0.43525558710098267,
      "learning_rate": 1.003246439610379e-05,
      "loss": 0.1362,
      "step": 24500
    },
    {
      "epoch": 0.0425,
      "eval_loss": 0.08024869114160538,
      "eval_runtime": 218.134,
      "eval_samples_per_second": 34.383,
      "eval_steps_per_second": 0.27,
      "step": 24500
    },
    {
      "epoch": 0.04275,
      "grad_norm": 0.36240631341934204,
      "learning_rate": 1.0021209068013664e-05,
      "loss": 0.1242,
      "step": 24510
    },
    {
      "epoch": 0.043,
      "grad_norm": 0.4408787190914154,
      "learning_rate": 1.0009956889335125e-05,
      "loss": 0.1285,
      "step": 24520
    },
    {
      "epoch": 0.04325,
      "grad_norm": 0.444065660238266,
      "learning_rate": 9.998707867185913e-06,
      "loss": 0.1267,
      "step": 24530
    },
    {
      "epoch": 0.0435,
      "grad_norm": 0.3810713589191437,
      "learning_rate": 9.987462008681774e-06,
      "loss": 0.1509,
      "step": 24540
    },
    {
      "step": 24550,
      "wer/bud500": 0.05775133744555208
    },
    {
      "step": 24550,
      "wer/private": 0.3235294117647059
    },
    {
      "epoch": 0.04375,
      "grad_norm": 0.4641880691051483,
      "learning_rate": 9.976219320936447e-06,
      "loss": 0.1387,
      "step": 24550
    },
    {
      "epoch": 0.044,
      "grad_norm": 0.3882165253162384,
      "learning_rate": 9.964979811061675e-06,
      "loss": 0.1339,
      "step": 24560
    },
    {
      "epoch": 0.04425,
      "grad_norm": 0.6531166434288025,
      "learning_rate": 9.953743486167181e-06,
      "loss": 0.1494,
      "step": 24570
    },
    {
      "epoch": 0.0445,
      "grad_norm": 0.40130674839019775,
      "learning_rate": 9.94251035336068e-06,
      "loss": 0.1232,
      "step": 24580
    },
    {
      "epoch": 0.04475,
      "grad_norm": 0.440785676240921,
      "learning_rate": 9.931280419747861e-06,
      "loss": 0.1327,
      "step": 24590
    },
    {
      "step": 24600,
      "wer/bud500": 0.05769286988043383
    },
    {
      "step": 24600,
      "wer/private": 0.3212669683257919
    },
    {
      "epoch": 0.045,
      "grad_norm": 0.4176221191883087,
      "learning_rate": 9.92005369243239e-06,
      "loss": 0.134,
      "step": 24600
    },
    {
      "epoch": 0.045,
      "eval_loss": 0.07977019995450974,
      "eval_runtime": 217.7895,
      "eval_samples_per_second": 34.437,
      "eval_steps_per_second": 0.271,
      "step": 24600
    },
    {
      "epoch": 0.04525,
      "grad_norm": 0.4369887113571167,
      "learning_rate": 9.90883017851592e-06,
      "loss": 0.1441,
      "step": 24610
    },
    {
      "epoch": 0.0455,
      "grad_norm": 0.4660239815711975,
      "learning_rate": 9.897609885098043e-06,
      "loss": 0.1502,
      "step": 24620
    },
    {
      "epoch": 0.04575,
      "grad_norm": 0.5165203213691711,
      "learning_rate": 9.886392819276346e-06,
      "loss": 0.1523,
      "step": 24630
    },
    {
      "epoch": 0.046,
      "grad_norm": 0.47239065170288086,
      "learning_rate": 9.875178988146349e-06,
      "loss": 0.1314,
      "step": 24640
    },
    {
      "step": 24650,
      "wer/bud500": 0.05769286988043383
    },
    {
      "step": 24650,
      "wer/private": 0.3167420814479638
    },
    {
      "epoch": 0.04625,
      "grad_norm": 0.5154359340667725,
      "learning_rate": 9.863968398801531e-06,
      "loss": 0.1389,
      "step": 24650
    },
    {
      "epoch": 0.0465,
      "grad_norm": 0.5099509954452515,
      "learning_rate": 9.852761058333334e-06,
      "loss": 0.1206,
      "step": 24660
    },
    {
      "epoch": 0.04675,
      "grad_norm": 0.4198753833770752,
      "learning_rate": 9.841556973831135e-06,
      "loss": 0.1328,
      "step": 24670
    },
    {
      "epoch": 0.047,
      "grad_norm": 0.38613128662109375,
      "learning_rate": 9.830356152382247e-06,
      "loss": 0.1317,
      "step": 24680
    },
    {
      "epoch": 0.04725,
      "grad_norm": 0.4665658175945282,
      "learning_rate": 9.819158601071924e-06,
      "loss": 0.1368,
      "step": 24690
    },
    {
      "step": 24700,
      "wer/bud500": 0.05745899961996083
    },
    {
      "step": 24700,
      "wer/private": 0.3223981900452489
    },
    {
      "epoch": 0.0475,
      "grad_norm": 0.4367527663707733,
      "learning_rate": 9.807964326983356e-06,
      "loss": 0.1354,
      "step": 24700
    },
    {
      "epoch": 0.0475,
      "eval_loss": 0.07973858714103699,
      "eval_runtime": 217.8642,
      "eval_samples_per_second": 34.425,
      "eval_steps_per_second": 0.271,
      "step": 24700
    },
    {
      "epoch": 0.04775,
      "grad_norm": 0.4428870379924774,
      "learning_rate": 9.796773337197643e-06,
      "loss": 0.1328,
      "step": 24710
    },
    {
      "epoch": 0.048,
      "grad_norm": 0.41527292132377625,
      "learning_rate": 9.785585638793835e-06,
      "loss": 0.1339,
      "step": 24720
    },
    {
      "epoch": 0.04825,
      "grad_norm": 0.45067980885505676,
      "learning_rate": 9.774401238848875e-06,
      "loss": 0.1356,
      "step": 24730
    },
    {
      "epoch": 0.0485,
      "grad_norm": 0.45044657588005066,
      "learning_rate": 9.763220144437633e-06,
      "loss": 0.1437,
      "step": 24740
    },
    {
      "step": 24750,
      "wer/bud500": 0.057561317858917764
    },
    {
      "step": 24750,
      "wer/private": 0.34728506787330315
    },
    {
      "epoch": 0.04875,
      "grad_norm": 0.43579861521720886,
      "learning_rate": 9.752042362632883e-06,
      "loss": 0.1327,
      "step": 24750
    },
    {
      "epoch": 0.049,
      "grad_norm": 0.4904939532279968,
      "learning_rate": 9.7408679005053e-06,
      "loss": 0.1464,
      "step": 24760
    },
    {
      "epoch": 0.04925,
      "grad_norm": 0.4732567071914673,
      "learning_rate": 9.72969676512347e-06,
      "loss": 0.1469,
      "step": 24770
    },
    {
      "epoch": 0.0495,
      "grad_norm": 0.4474281072616577,
      "learning_rate": 9.718528963553871e-06,
      "loss": 0.153,
      "step": 24780
    },
    {
      "epoch": 0.04975,
      "grad_norm": 0.46680790185928345,
      "learning_rate": 9.707364502860861e-06,
      "loss": 0.1307,
      "step": 24790
    },
    {
      "step": 24800,
      "wer/bud500": 0.05726898003332651
    },
    {
      "step": 24800,
      "wer/private": 0.33031674208144796
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.46794819831848145,
      "learning_rate": 9.697319350523633e-06,
      "loss": 0.1214,
      "step": 24800
    },
    {
      "epoch": 0.05,
      "eval_loss": 0.08002421259880066,
      "eval_runtime": 217.6535,
      "eval_samples_per_second": 34.458,
      "eval_steps_per_second": 0.271,
      "step": 24800
    },
    {
      "epoch": 0.05025,
      "grad_norm": 0.4123814105987549,
      "learning_rate": 9.686161256950908e-06,
      "loss": 0.1467,
      "step": 24810
    },
    {
      "epoch": 0.0505,
      "grad_norm": 0.44597169756889343,
      "learning_rate": 9.67500652472947e-06,
      "loss": 0.132,
      "step": 24820
    },
    {
      "epoch": 0.05075,
      "grad_norm": 0.37890124320983887,
      "learning_rate": 9.663855160915422e-06,
      "loss": 0.127,
      "step": 24830
    },
    {
      "epoch": 0.051,
      "grad_norm": 0.4251139163970947,
      "learning_rate": 9.652707172562725e-06,
      "loss": 0.1384,
      "step": 24840
    },
    {
      "step": 24850,
      "wer/bud500": 0.057546700967638205
    },
    {
      "step": 24850,
      "wer/private": 0.32918552036199095
    },
    {
      "epoch": 0.05125,
      "grad_norm": 0.30717676877975464,
      "learning_rate": 9.641562566723223e-06,
      "loss": 0.1265,
      "step": 24850
    },
    {
      "epoch": 0.0515,
      "grad_norm": 0.3758811354637146,
      "learning_rate": 9.6304213504466e-06,
      "loss": 0.1409,
      "step": 24860
    },
    {
      "epoch": 0.05175,
      "grad_norm": 0.7031657099723816,
      "learning_rate": 9.619283530780414e-06,
      "loss": 0.1363,
      "step": 24870
    },
    {
      "epoch": 0.052,
      "grad_norm": 0.47873613238334656,
      "learning_rate": 9.608149114770064e-06,
      "loss": 0.1283,
      "step": 24880
    },
    {
      "epoch": 0.05225,
      "grad_norm": 0.7336510419845581,
      "learning_rate": 9.597018109458785e-06,
      "loss": 0.1478,
      "step": 24890
    },
    {
      "step": 24900,
      "wer/bud500": 0.05763440231531558
    },
    {
      "step": 24900,
      "wer/private": 0.33144796380090497
    },
    {
      "epoch": 0.0525,
      "grad_norm": 0.40480172634124756,
      "learning_rate": 9.585890521887685e-06,
      "loss": 0.145,
      "step": 24900
    },
    {
      "epoch": 0.0525,
      "eval_loss": 0.07988425344228745,
      "eval_runtime": 217.35,
      "eval_samples_per_second": 34.507,
      "eval_steps_per_second": 0.271,
      "step": 24900
    },
    {
      "epoch": 0.05275,
      "grad_norm": 0.4990176260471344,
      "learning_rate": 9.574766359095685e-06,
      "loss": 0.1288,
      "step": 24910
    },
    {
      "epoch": 0.053,
      "grad_norm": 0.46521034836769104,
      "learning_rate": 9.56364562811955e-06,
      "loss": 0.1331,
      "step": 24920
    },
    {
      "epoch": 0.05325,
      "grad_norm": 0.4701693058013916,
      "learning_rate": 9.552528335993866e-06,
      "loss": 0.1455,
      "step": 24930
    },
    {
      "epoch": 0.0535,
      "grad_norm": 0.5419484972953796,
      "learning_rate": 9.541414489751053e-06,
      "loss": 0.1366,
      "step": 24940
    },
    {
      "step": 24950,
      "wer/bud500": 0.05763440231531558
    },
    {
      "step": 24950,
      "wer/private": 0.35407239819004527
    },
    {
      "epoch": 0.05375,
      "grad_norm": 0.406127005815506,
      "learning_rate": 9.530304096421342e-06,
      "loss": 0.1338,
      "step": 24950
    },
    {
      "epoch": 0.054,
      "grad_norm": 0.4131230115890503,
      "learning_rate": 9.519197163032794e-06,
      "loss": 0.1432,
      "step": 24960
    },
    {
      "epoch": 0.05425,
      "grad_norm": 0.4514503479003906,
      "learning_rate": 9.508093696611269e-06,
      "loss": 0.1338,
      "step": 24970
    },
    {
      "epoch": 0.0545,
      "grad_norm": 0.37097811698913574,
      "learning_rate": 9.49699370418043e-06,
      "loss": 0.1296,
      "step": 24980
    },
    {
      "epoch": 0.05475,
      "grad_norm": 0.536445677280426,
      "learning_rate": 9.485897192761758e-06,
      "loss": 0.1258,
      "step": 24990
    },
    {
      "step": 25000,
      "wer/bud500": 0.057736720554272515
    },
    {
      "step": 25000,
      "wer/private": 0.3167420814479638
    },
    {
      "epoch": 0.055,
      "grad_norm": 0.4694626033306122,
      "learning_rate": 9.474804169374516e-06,
      "loss": 0.1402,
      "step": 25000
    },
    {
      "epoch": 0.055,
      "eval_loss": 0.07970419526100159,
      "eval_runtime": 218.2459,
      "eval_samples_per_second": 34.365,
      "eval_steps_per_second": 0.27,
      "step": 25000
    },
    {
      "epoch": 0.05525,
      "grad_norm": 0.5274871587753296,
      "learning_rate": 9.463714641035782e-06,
      "loss": 0.1536,
      "step": 25010
    },
    {
      "epoch": 0.0555,
      "grad_norm": 0.5063234567642212,
      "learning_rate": 9.452628614760396e-06,
      "loss": 0.1523,
      "step": 25020
    },
    {
      "epoch": 0.05575,
      "grad_norm": 0.48328956961631775,
      "learning_rate": 9.441546097561003e-06,
      "loss": 0.1373,
      "step": 25030
    },
    {
      "epoch": 0.056,
      "grad_norm": 0.41717329621315,
      "learning_rate": 9.430467096448022e-06,
      "loss": 0.1268,
      "step": 25040
    },
    {
      "step": 25050,
      "wer/bud500": 0.05769286988043383
    },
    {
      "step": 25050,
      "wer/private": 0.3190045248868778
    },
    {
      "epoch": 0.05625,
      "grad_norm": 0.47809842228889465,
      "learning_rate": 9.419391618429636e-06,
      "loss": 0.1317,
      "step": 25050
    },
    {
      "epoch": 0.0565,
      "grad_norm": 0.4750567376613617,
      "learning_rate": 9.408319670511825e-06,
      "loss": 0.1392,
      "step": 25060
    },
    {
      "epoch": 0.05675,
      "grad_norm": 0.45645907521247864,
      "learning_rate": 9.397251259698318e-06,
      "loss": 0.1362,
      "step": 25070
    },
    {
      "epoch": 0.057,
      "grad_norm": 0.4005890190601349,
      "learning_rate": 9.38618639299061e-06,
      "loss": 0.1248,
      "step": 25080
    },
    {
      "epoch": 0.05725,
      "grad_norm": 0.5088812708854675,
      "learning_rate": 9.37512507738795e-06,
      "loss": 0.133,
      "step": 25090
    },
    {
      "step": 25100,
      "wer/bud500": 0.05795597392346596
    },
    {
      "step": 25100,
      "wer/private": 0.32805429864253394
    },
    {
      "epoch": 0.0575,
      "grad_norm": 0.4318104088306427,
      "learning_rate": 9.364067319887353e-06,
      "loss": 0.1389,
      "step": 25100
    },
    {
      "epoch": 0.0575,
      "eval_loss": 0.07988666743040085,
      "eval_runtime": 217.5277,
      "eval_samples_per_second": 34.478,
      "eval_steps_per_second": 0.271,
      "step": 25100
    },
    {
      "epoch": 0.05775,
      "grad_norm": 0.4884992241859436,
      "learning_rate": 9.353013127483562e-06,
      "loss": 0.136,
      "step": 25110
    },
    {
      "epoch": 0.058,
      "grad_norm": 0.3670910894870758,
      "learning_rate": 9.341962507169094e-06,
      "loss": 0.1273,
      "step": 25120
    },
    {
      "epoch": 0.05825,
      "grad_norm": 0.42268383502960205,
      "learning_rate": 9.330915465934183e-06,
      "loss": 0.1295,
      "step": 25130
    },
    {
      "epoch": 0.0585,
      "grad_norm": 0.47186774015426636,
      "learning_rate": 9.319872010766804e-06,
      "loss": 0.142,
      "step": 25140
    },
    {
      "step": 25150,
      "wer/bud500": 0.05804367527114333
    },
    {
      "step": 25150,
      "wer/private": 0.3563348416289593
    },
    {
      "epoch": 0.05875,
      "grad_norm": 0.9310616850852966,
      "learning_rate": 9.308832148652675e-06,
      "loss": 0.1324,
      "step": 25150
    },
    {
      "epoch": 0.059,
      "grad_norm": 0.47738000750541687,
      "learning_rate": 9.297795886575219e-06,
      "loss": 0.1338,
      "step": 25160
    },
    {
      "epoch": 0.05925,
      "grad_norm": 0.4427933692932129,
      "learning_rate": 9.286763231515608e-06,
      "loss": 0.1452,
      "step": 25170
    },
    {
      "epoch": 0.0595,
      "grad_norm": 0.45953863859176636,
      "learning_rate": 9.275734190452712e-06,
      "loss": 0.1323,
      "step": 25180
    },
    {
      "epoch": 0.05975,
      "grad_norm": 0.5786973237991333,
      "learning_rate": 9.264708770363128e-06,
      "loss": 0.1346,
      "step": 25190
    },
    {
      "step": 25200,
      "wer/bud500": 0.05775133744555208
    },
    {
      "step": 25200,
      "wer/private": 0.3088235294117647
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5045645833015442,
      "learning_rate": 9.253686978221154e-06,
      "loss": 0.1403,
      "step": 25200
    },
    {
      "epoch": 0.06,
      "eval_loss": 0.07984466850757599,
      "eval_runtime": 217.6119,
      "eval_samples_per_second": 34.465,
      "eval_steps_per_second": 0.271,
      "step": 25200
    },
    {
      "epoch": 0.00025,
      "grad_norm": 0.6108300089836121,
      "learning_rate": 9.24377047295099e-06,
      "loss": 0.1318,
      "step": 25210
    },
    {
      "epoch": 0.0005,
      "grad_norm": 0.42211949825286865,
      "learning_rate": 9.232755593115446e-06,
      "loss": 0.1395,
      "step": 25220
    },
    {
      "epoch": 0.00075,
      "grad_norm": 0.4658767879009247,
      "learning_rate": 9.221744361439993e-06,
      "loss": 0.1327,
      "step": 25230
    },
    {
      "epoch": 0.001,
      "grad_norm": 0.41071388125419617,
      "learning_rate": 9.21073678488995e-06,
      "loss": 0.1234,
      "step": 25240
    },
    {
      "step": 25250,
      "wer/bud500": 0.058219077966498084
    },
    {
      "step": 25250,
      "wer/private": 0.3167420814479638
    },
    {
      "epoch": 0.00125,
      "grad_norm": 0.44971728324890137,
      "learning_rate": 9.19973287042834e-06,
      "loss": 0.1361,
      "step": 25250
    },
    {
      "epoch": 0.0015,
      "grad_norm": 0.43973153829574585,
      "learning_rate": 9.18873262501585e-06,
      "loss": 0.1373,
      "step": 25260
    },
    {
      "epoch": 0.00175,
      "grad_norm": 0.4492590129375458,
      "learning_rate": 9.17773605561087e-06,
      "loss": 0.1324,
      "step": 25270
    },
    {
      "epoch": 0.002,
      "grad_norm": 0.4327513873577118,
      "learning_rate": 9.166743169169436e-06,
      "loss": 0.1211,
      "step": 25280
    },
    {
      "epoch": 0.00225,
      "grad_norm": 0.4688761830329895,
      "learning_rate": 9.155753972645271e-06,
      "loss": 0.1319,
      "step": 25290
    },
    {
      "step": 25300,
      "wer/bud500": 0.057722103662992956
    },
    {
      "step": 25300,
      "wer/private": 0.3178733031674208
    },
    {
      "epoch": 0.0025,
      "grad_norm": 0.4591512680053711,
      "learning_rate": 9.144768472989774e-06,
      "loss": 0.1284,
      "step": 25300
    },
    {
      "epoch": 0.0025,
      "eval_loss": 0.07997091859579086,
      "eval_runtime": 212.7749,
      "eval_samples_per_second": 35.249,
      "eval_steps_per_second": 0.277,
      "step": 25300
    },
    {
      "epoch": 0.00275,
      "grad_norm": 0.4218871593475342,
      "learning_rate": 9.133786677151981e-06,
      "loss": 0.1372,
      "step": 25310
    },
    {
      "epoch": 0.003,
      "grad_norm": 0.4645003080368042,
      "learning_rate": 9.122808592078605e-06,
      "loss": 0.1373,
      "step": 25320
    },
    {
      "epoch": 0.00325,
      "grad_norm": 0.4457542300224304,
      "learning_rate": 9.111834224714003e-06,
      "loss": 0.1489,
      "step": 25330
    },
    {
      "epoch": 0.0035,
      "grad_norm": 0.4419167637825012,
      "learning_rate": 9.100863582000177e-06,
      "loss": 0.1296,
      "step": 25340
    },
    {
      "step": 25350,
      "wer/bud500": 0.058145993510100275
    },
    {
      "step": 25350,
      "wer/private": 0.34841628959276016
    },
    {
      "epoch": 0.00375,
      "grad_norm": 0.48494046926498413,
      "learning_rate": 9.089896670876779e-06,
      "loss": 0.1385,
      "step": 25350
    },
    {
      "epoch": 0.004,
      "grad_norm": 0.3856954276561737,
      "learning_rate": 9.078933498281108e-06,
      "loss": 0.1447,
      "step": 25360
    },
    {
      "epoch": 0.00425,
      "grad_norm": 0.4415406584739685,
      "learning_rate": 9.067974071148078e-06,
      "loss": 0.1396,
      "step": 25370
    },
    {
      "epoch": 0.0045,
      "grad_norm": 0.5471413135528564,
      "learning_rate": 9.057018396410251e-06,
      "loss": 0.1402,
      "step": 25380
    },
    {
      "epoch": 0.00475,
      "grad_norm": 0.46031489968299866,
      "learning_rate": 9.046066480997808e-06,
      "loss": 0.13,
      "step": 25390
    },
    {
      "step": 25400,
      "wer/bud500": 0.05751746718507908
    },
    {
      "step": 25400,
      "wer/private": 0.3246606334841629
    },
    {
      "epoch": 0.005,
      "grad_norm": 0.4517821669578552,
      "learning_rate": 9.035118331838549e-06,
      "loss": 0.1262,
      "step": 25400
    },
    {
      "epoch": 0.005,
      "eval_loss": 0.08002220839262009,
      "eval_runtime": 213.0594,
      "eval_samples_per_second": 35.201,
      "eval_steps_per_second": 0.277,
      "step": 25400
    },
    {
      "epoch": 0.00525,
      "grad_norm": 0.4265686869621277,
      "learning_rate": 9.024173955857904e-06,
      "loss": 0.1338,
      "step": 25410
    },
    {
      "epoch": 0.0055,
      "grad_norm": 0.4872467517852783,
      "learning_rate": 9.013233359978902e-06,
      "loss": 0.1274,
      "step": 25420
    },
    {
      "epoch": 0.00575,
      "grad_norm": 0.5445760488510132,
      "learning_rate": 9.00229655112219e-06,
      "loss": 0.1535,
      "step": 25430
    },
    {
      "epoch": 0.006,
      "grad_norm": 0.47282874584198,
      "learning_rate": 8.991363536206017e-06,
      "loss": 0.139,
      "step": 25440
    },
    {
      "step": 25450,
      "wer/bud500": 0.057488233402519955
    },
    {
      "step": 25450,
      "wer/private": 0.333710407239819
    },
    {
      "epoch": 0.00625,
      "grad_norm": 0.4560311436653137,
      "learning_rate": 8.980434322146224e-06,
      "loss": 0.1345,
      "step": 25450
    },
    {
      "epoch": 0.0065,
      "grad_norm": 0.382946640253067,
      "learning_rate": 8.969508915856268e-06,
      "loss": 0.1411,
      "step": 25460
    },
    {
      "epoch": 0.00675,
      "grad_norm": 0.451288640499115,
      "learning_rate": 8.958587324247172e-06,
      "loss": 0.1378,
      "step": 25470
    },
    {
      "epoch": 0.007,
      "grad_norm": 0.5346744060516357,
      "learning_rate": 8.94766955422757e-06,
      "loss": 0.1182,
      "step": 25480
    },
    {
      "epoch": 0.00725,
      "grad_norm": 0.4642161428928375,
      "learning_rate": 8.936755612703662e-06,
      "loss": 0.1362,
      "step": 25490
    },
    {
      "step": 25500,
      "wer/bud500": 0.05741514894612214
    },
    {
      "step": 25500,
      "wer/private": 0.3190045248868778
    },
    {
      "epoch": 0.0075,
      "grad_norm": 0.42381495237350464,
      "learning_rate": 8.925845506579226e-06,
      "loss": 0.1312,
      "step": 25500
    },
    {
      "epoch": 0.0075,
      "eval_loss": 0.0796634703874588,
      "eval_runtime": 212.6905,
      "eval_samples_per_second": 35.263,
      "eval_steps_per_second": 0.277,
      "step": 25500
    },
    {
      "epoch": 0.00775,
      "grad_norm": 0.418434739112854,
      "learning_rate": 8.914939242755621e-06,
      "loss": 0.1344,
      "step": 25510
    },
    {
      "epoch": 0.008,
      "grad_norm": 0.37714850902557373,
      "learning_rate": 8.904036828131783e-06,
      "loss": 0.125,
      "step": 25520
    },
    {
      "epoch": 0.00825,
      "grad_norm": 0.4441158175468445,
      "learning_rate": 8.893138269604196e-06,
      "loss": 0.1329,
      "step": 25530
    },
    {
      "epoch": 0.0085,
      "grad_norm": 0.4395298659801483,
      "learning_rate": 8.882243574066912e-06,
      "loss": 0.1328,
      "step": 25540
    },
    {
      "step": 25550,
      "wer/bud500": 0.05753208407635864
    },
    {
      "step": 25550,
      "wer/private": 0.32805429864253394
    },
    {
      "epoch": 0.00875,
      "grad_norm": 0.40818873047828674,
      "learning_rate": 8.871352748411546e-06,
      "loss": 0.1436,
      "step": 25550
    },
    {
      "epoch": 0.009,
      "grad_norm": 0.52653568983078,
      "learning_rate": 8.860465799527247e-06,
      "loss": 0.1232,
      "step": 25560
    },
    {
      "epoch": 0.00925,
      "grad_norm": 0.5861178040504456,
      "learning_rate": 8.84958273430074e-06,
      "loss": 0.1312,
      "step": 25570
    },
    {
      "epoch": 0.0095,
      "grad_norm": 0.4531668722629547,
      "learning_rate": 8.838703559616264e-06,
      "loss": 0.1408,
      "step": 25580
    },
    {
      "epoch": 0.00975,
      "grad_norm": 0.5086602568626404,
      "learning_rate": 8.827828282355618e-06,
      "loss": 0.1279,
      "step": 25590
    },
    {
      "step": 25600,
      "wer/bud500": 0.05763440231531558
    },
    {
      "step": 25600,
      "wer/private": 0.32805429864253394
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.42262402176856995,
      "learning_rate": 8.816956909398125e-06,
      "loss": 0.131,
      "step": 25600
    },
    {
      "epoch": 0.01,
      "eval_loss": 0.0797356367111206,
      "eval_runtime": 212.6139,
      "eval_samples_per_second": 35.275,
      "eval_steps_per_second": 0.277,
      "step": 25600
    },
    {
      "epoch": 0.01025,
      "grad_norm": 0.5970605611801147,
      "learning_rate": 8.806089447620636e-06,
      "loss": 0.1305,
      "step": 25610
    },
    {
      "epoch": 0.0105,
      "grad_norm": 0.39690735936164856,
      "learning_rate": 8.795225903897542e-06,
      "loss": 0.1283,
      "step": 25620
    },
    {
      "epoch": 0.01075,
      "grad_norm": 0.5653819441795349,
      "learning_rate": 8.784366285100738e-06,
      "loss": 0.146,
      "step": 25630
    },
    {
      "epoch": 0.011,
      "grad_norm": 0.4377295970916748,
      "learning_rate": 8.773510598099653e-06,
      "loss": 0.1412,
      "step": 25640
    },
    {
      "step": 25650,
      "wer/bud500": 0.05770748677171339
    },
    {
      "step": 25650,
      "wer/private": 0.31447963800904977
    },
    {
      "epoch": 0.01125,
      "grad_norm": 0.37085777521133423,
      "learning_rate": 8.762658849761215e-06,
      "loss": 0.1253,
      "step": 25650
    },
    {
      "epoch": 0.0115,
      "grad_norm": 0.3849344849586487,
      "learning_rate": 8.751811046949866e-06,
      "loss": 0.1273,
      "step": 25660
    },
    {
      "epoch": 0.01175,
      "grad_norm": 0.4250243306159973,
      "learning_rate": 8.740967196527549e-06,
      "loss": 0.1328,
      "step": 25670
    },
    {
      "epoch": 0.012,
      "grad_norm": 0.45960137248039246,
      "learning_rate": 8.730127305353714e-06,
      "loss": 0.1433,
      "step": 25680
    },
    {
      "epoch": 0.01225,
      "grad_norm": 0.3630601763725281,
      "learning_rate": 8.71929138028531e-06,
      "loss": 0.1295,
      "step": 25690
    },
    {
      "step": 25700,
      "wer/bud500": 0.057722103662992956
    },
    {
      "step": 25700,
      "wer/private": 0.3495475113122172
    },
    {
      "epoch": 0.0125,
      "grad_norm": 0.7294626832008362,
      "learning_rate": 8.708459428176762e-06,
      "loss": 0.1422,
      "step": 25700
    },
    {
      "epoch": 0.0125,
      "eval_loss": 0.07985949516296387,
      "eval_runtime": 212.7247,
      "eval_samples_per_second": 35.257,
      "eval_steps_per_second": 0.277,
      "step": 25700
    },
    {
      "epoch": 0.01275,
      "grad_norm": 0.36884376406669617,
      "learning_rate": 8.697631455879989e-06,
      "loss": 0.1414,
      "step": 25710
    },
    {
      "epoch": 0.013,
      "grad_norm": 0.45023903250694275,
      "learning_rate": 8.686807470244392e-06,
      "loss": 0.1317,
      "step": 25720
    },
    {
      "epoch": 0.01325,
      "grad_norm": 0.39537596702575684,
      "learning_rate": 8.675987478116857e-06,
      "loss": 0.1387,
      "step": 25730
    },
    {
      "epoch": 0.0135,
      "grad_norm": 0.4477872848510742,
      "learning_rate": 8.665171486341738e-06,
      "loss": 0.1358,
      "step": 25740
    },
    {
      "step": 25750,
      "wer/bud500": 0.05770748677171339
    },
    {
      "step": 25750,
      "wer/private": 0.33597285067873306
    },
    {
      "epoch": 0.01375,
      "grad_norm": 0.3439471125602722,
      "learning_rate": 8.654359501760853e-06,
      "loss": 0.1293,
      "step": 25750
    },
    {
      "epoch": 0.014,
      "grad_norm": 0.5097633600234985,
      "learning_rate": 8.64355153121349e-06,
      "loss": 0.145,
      "step": 25760
    },
    {
      "epoch": 0.01425,
      "grad_norm": 0.41657570004463196,
      "learning_rate": 8.632747581536402e-06,
      "loss": 0.1365,
      "step": 25770
    },
    {
      "epoch": 0.0145,
      "grad_norm": 0.4814733564853668,
      "learning_rate": 8.621947659563804e-06,
      "loss": 0.1381,
      "step": 25780
    },
    {
      "epoch": 0.01475,
      "grad_norm": 0.5480992197990417,
      "learning_rate": 8.611151772127344e-06,
      "loss": 0.1235,
      "step": 25790
    },
    {
      "step": 25800,
      "wer/bud500": 0.057546700967638205
    },
    {
      "step": 25800,
      "wer/private": 0.33144796380090497
    },
    {
      "epoch": 0.015,
      "grad_norm": 0.4757215976715088,
      "learning_rate": 8.600359926056132e-06,
      "loss": 0.137,
      "step": 25800
    },
    {
      "epoch": 0.015,
      "eval_loss": 0.07962778955698013,
      "eval_runtime": 211.9032,
      "eval_samples_per_second": 35.394,
      "eval_steps_per_second": 0.278,
      "step": 25800
    },
    {
      "epoch": 0.01525,
      "grad_norm": 0.46337273716926575,
      "learning_rate": 8.589572128176715e-06,
      "loss": 0.1431,
      "step": 25810
    },
    {
      "epoch": 0.0155,
      "grad_norm": 0.47570618987083435,
      "learning_rate": 8.578788385313084e-06,
      "loss": 0.1338,
      "step": 25820
    },
    {
      "epoch": 0.01575,
      "grad_norm": 0.48096606135368347,
      "learning_rate": 8.56800870428666e-06,
      "loss": 0.1278,
      "step": 25830
    },
    {
      "epoch": 0.016,
      "grad_norm": 0.4750673472881317,
      "learning_rate": 8.557233091916299e-06,
      "loss": 0.1212,
      "step": 25840
    },
    {
      "step": 25850,
      "wer/bud500": 0.05735668138100389
    },
    {
      "step": 25850,
      "wer/private": 0.33710407239819007
    },
    {
      "epoch": 0.01625,
      "grad_norm": 0.5625931024551392,
      "learning_rate": 8.54646155501829e-06,
      "loss": 0.1374,
      "step": 25850
    },
    {
      "epoch": 0.0165,
      "grad_norm": 0.3951307237148285,
      "learning_rate": 8.53569410040633e-06,
      "loss": 0.1457,
      "step": 25860
    },
    {
      "epoch": 0.01675,
      "grad_norm": 0.3996937572956085,
      "learning_rate": 8.524930734891542e-06,
      "loss": 0.1348,
      "step": 25870
    },
    {
      "epoch": 0.017,
      "grad_norm": 0.41892680525779724,
      "learning_rate": 8.514171465282451e-06,
      "loss": 0.1267,
      "step": 25880
    },
    {
      "epoch": 0.01725,
      "grad_norm": 0.5531443357467651,
      "learning_rate": 8.503416298385012e-06,
      "loss": 0.146,
      "step": 25890
    },
    {
      "step": 25900,
      "wer/bud500": 0.05776595433683164
    },
    {
      "step": 25900,
      "wer/private": 0.3235294117647059
    },
    {
      "epoch": 0.0175,
      "grad_norm": 0.4567256569862366,
      "learning_rate": 8.492665241002568e-06,
      "loss": 0.1271,
      "step": 25900
    },
    {
      "epoch": 0.0175,
      "eval_loss": 0.07964920997619629,
      "eval_runtime": 212.8698,
      "eval_samples_per_second": 35.233,
      "eval_steps_per_second": 0.277,
      "step": 25900
    },
    {
      "epoch": 0.01775,
      "grad_norm": 0.44554203748703003,
      "learning_rate": 8.481918299935871e-06,
      "loss": 0.1273,
      "step": 25910
    },
    {
      "epoch": 0.018,
      "grad_norm": 0.4373629689216614,
      "learning_rate": 8.471175481983054e-06,
      "loss": 0.1353,
      "step": 25920
    },
    {
      "epoch": 0.01825,
      "grad_norm": 0.474618136882782,
      "learning_rate": 8.460436793939661e-06,
      "loss": 0.1486,
      "step": 25930
    },
    {
      "epoch": 0.0185,
      "grad_norm": 0.5737735033035278,
      "learning_rate": 8.449702242598624e-06,
      "loss": 0.1274,
      "step": 25940
    },
    {
      "step": 25950,
      "wer/bud500": 0.057795188119390765
    },
    {
      "step": 25950,
      "wer/private": 0.3608597285067873
    },
    {
      "epoch": 0.01875,
      "grad_norm": 0.45301398634910583,
      "learning_rate": 8.438971834750243e-06,
      "loss": 0.1254,
      "step": 25950
    },
    {
      "epoch": 0.019,
      "grad_norm": 0.4008309245109558,
      "learning_rate": 8.428245577182204e-06,
      "loss": 0.1276,
      "step": 25960
    },
    {
      "epoch": 0.01925,
      "grad_norm": 0.4512021243572235,
      "learning_rate": 8.41752347667957e-06,
      "loss": 0.1354,
      "step": 25970
    },
    {
      "epoch": 0.0195,
      "grad_norm": 0.3782994747161865,
      "learning_rate": 8.406805540024767e-06,
      "loss": 0.139,
      "step": 25980
    },
    {
      "epoch": 0.01975,
      "grad_norm": 0.38615116477012634,
      "learning_rate": 8.396091773997594e-06,
      "loss": 0.1227,
      "step": 25990
    },
    {
      "step": 26000,
      "wer/bud500": 0.05744438272868126
    },
    {
      "step": 26000,
      "wer/private": 0.34841628959276016
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4204004406929016,
      "learning_rate": 8.38538218537521e-06,
      "loss": 0.125,
      "step": 26000
    },
    {
      "epoch": 0.02,
      "eval_loss": 0.07975896447896957,
      "eval_runtime": 212.7277,
      "eval_samples_per_second": 35.256,
      "eval_steps_per_second": 0.277,
      "step": 26000
    },
    {
      "epoch": 0.02025,
      "grad_norm": 0.41369307041168213,
      "learning_rate": 8.37467678093214e-06,
      "loss": 0.1351,
      "step": 26010
    },
    {
      "epoch": 0.0205,
      "grad_norm": 0.4460512399673462,
      "learning_rate": 8.36397556744025e-06,
      "loss": 0.1286,
      "step": 26020
    },
    {
      "epoch": 0.02075,
      "grad_norm": 0.4453524053096771,
      "learning_rate": 8.353278551668754e-06,
      "loss": 0.1473,
      "step": 26030
    },
    {
      "epoch": 0.021,
      "grad_norm": 0.4815795421600342,
      "learning_rate": 8.342585740384214e-06,
      "loss": 0.1482,
      "step": 26040
    },
    {
      "step": 26050,
      "wer/bud500": 0.057619785424036014
    },
    {
      "step": 26050,
      "wer/private": 0.3608597285067873
    },
    {
      "epoch": 0.02125,
      "grad_norm": 0.4042860269546509,
      "learning_rate": 8.331897140350545e-06,
      "loss": 0.1338,
      "step": 26050
    },
    {
      "epoch": 0.0215,
      "grad_norm": 0.46764281392097473,
      "learning_rate": 8.32121275832898e-06,
      "loss": 0.1476,
      "step": 26060
    },
    {
      "epoch": 0.02175,
      "grad_norm": 0.513999342918396,
      "learning_rate": 8.310532601078085e-06,
      "loss": 0.1351,
      "step": 26070
    },
    {
      "epoch": 0.022,
      "grad_norm": 0.49177131056785583,
      "learning_rate": 8.299856675353775e-06,
      "loss": 0.1422,
      "step": 26080
    },
    {
      "epoch": 0.02225,
      "grad_norm": 0.4462093114852905,
      "learning_rate": 8.289184987909254e-06,
      "loss": 0.1388,
      "step": 26090
    },
    {
      "step": 26100,
      "wer/bud500": 0.05738591516356301
    },
    {
      "step": 26100,
      "wer/private": 0.332579185520362
    },
    {
      "epoch": 0.0225,
      "grad_norm": 0.5086433291435242,
      "learning_rate": 8.27851754549508e-06,
      "loss": 0.127,
      "step": 26100
    },
    {
      "epoch": 0.0225,
      "eval_loss": 0.07953333109617233,
      "eval_runtime": 212.6153,
      "eval_samples_per_second": 35.275,
      "eval_steps_per_second": 0.277,
      "step": 26100
    },
    {
      "epoch": 0.02275,
      "grad_norm": 0.5000511407852173,
      "learning_rate": 8.267854354859103e-06,
      "loss": 0.1382,
      "step": 26110
    },
    {
      "epoch": 0.023,
      "grad_norm": 0.42520421743392944,
      "learning_rate": 8.257195422746491e-06,
      "loss": 0.1225,
      "step": 26120
    },
    {
      "epoch": 0.02325,
      "grad_norm": 0.44608184695243835,
      "learning_rate": 8.246540755899714e-06,
      "loss": 0.1374,
      "step": 26130
    },
    {
      "epoch": 0.0235,
      "grad_norm": 0.4292583167552948,
      "learning_rate": 8.235890361058552e-06,
      "loss": 0.1382,
      "step": 26140
    },
    {
      "step": 26150,
      "wer/bud500": 0.057722103662992956
    },
    {
      "step": 26150,
      "wer/private": 0.333710407239819
    },
    {
      "epoch": 0.02375,
      "grad_norm": 0.4636536240577698,
      "learning_rate": 8.225244244960067e-06,
      "loss": 0.1395,
      "step": 26150
    },
    {
      "epoch": 0.024,
      "grad_norm": 0.4172745645046234,
      "learning_rate": 8.214602414338634e-06,
      "loss": 0.1359,
      "step": 26160
    },
    {
      "epoch": 0.02425,
      "grad_norm": 0.5417258143424988,
      "learning_rate": 8.203964875925913e-06,
      "loss": 0.1351,
      "step": 26170
    },
    {
      "epoch": 0.0245,
      "grad_norm": 0.45793160796165466,
      "learning_rate": 8.193331636450841e-06,
      "loss": 0.13,
      "step": 26180
    },
    {
      "epoch": 0.02475,
      "grad_norm": 0.548617422580719,
      "learning_rate": 8.182702702639635e-06,
      "loss": 0.1244,
      "step": 26190
    },
    {
      "step": 26200,
      "wer/bud500": 0.057122811120530886
    },
    {
      "step": 26200,
      "wer/private": 0.3212669683257919
    },
    {
      "epoch": 0.025,
      "grad_norm": 0.4340725541114807,
      "learning_rate": 8.172078081215788e-06,
      "loss": 0.1411,
      "step": 26200
    },
    {
      "epoch": 0.025,
      "eval_loss": 0.07944425195455551,
      "eval_runtime": 212.6494,
      "eval_samples_per_second": 35.269,
      "eval_steps_per_second": 0.277,
      "step": 26200
    },
    {
      "epoch": 0.02525,
      "grad_norm": 0.40727606415748596,
      "learning_rate": 8.16145777890008e-06,
      "loss": 0.136,
      "step": 26210
    },
    {
      "epoch": 0.0255,
      "grad_norm": 0.5111942887306213,
      "learning_rate": 8.150841802410547e-06,
      "loss": 0.1576,
      "step": 26220
    },
    {
      "epoch": 0.02575,
      "grad_norm": 0.4093770384788513,
      "learning_rate": 8.140230158462479e-06,
      "loss": 0.1273,
      "step": 26230
    },
    {
      "epoch": 0.026,
      "grad_norm": 0.46570250391960144,
      "learning_rate": 8.12962285376845e-06,
      "loss": 0.1153,
      "step": 26240
    },
    {
      "step": 26250,
      "wer/bud500": 0.057722103662992956
    },
    {
      "step": 26250,
      "wer/private": 0.36199095022624433
    },
    {
      "epoch": 0.02625,
      "grad_norm": 0.3989983797073364,
      "learning_rate": 8.119019895038262e-06,
      "loss": 0.1555,
      "step": 26250
    },
    {
      "epoch": 0.0265,
      "grad_norm": 0.49522140622138977,
      "learning_rate": 8.108421288978998e-06,
      "loss": 0.128,
      "step": 26260
    },
    {
      "epoch": 0.02675,
      "grad_norm": 0.39187896251678467,
      "learning_rate": 8.09782704229496e-06,
      "loss": 0.1354,
      "step": 26270
    },
    {
      "epoch": 0.027,
      "grad_norm": 0.45287150144577026,
      "learning_rate": 8.087237161687704e-06,
      "loss": 0.1321,
      "step": 26280
    },
    {
      "epoch": 0.02725,
      "grad_norm": 0.43050000071525574,
      "learning_rate": 8.076651653856026e-06,
      "loss": 0.1324,
      "step": 26290
    },
    {
      "step": 26300,
      "wer/bud500": 0.05744438272868126
    },
    {
      "step": 26300,
      "wer/private": 0.3246606334841629
    },
    {
      "epoch": 0.0275,
      "grad_norm": 0.4213606119155884,
      "learning_rate": 8.06607052549595e-06,
      "loss": 0.1353,
      "step": 26300
    },
    {
      "epoch": 0.0275,
      "eval_loss": 0.07937993109226227,
      "eval_runtime": 212.8819,
      "eval_samples_per_second": 35.231,
      "eval_steps_per_second": 0.277,
      "step": 26300
    },
    {
      "epoch": 0.02775,
      "grad_norm": 0.38021185994148254,
      "learning_rate": 8.055493783300733e-06,
      "loss": 0.1214,
      "step": 26310
    },
    {
      "epoch": 0.028,
      "grad_norm": 0.5240647792816162,
      "learning_rate": 8.04492143396086e-06,
      "loss": 0.1394,
      "step": 26320
    },
    {
      "epoch": 0.02825,
      "grad_norm": 0.39205440878868103,
      "learning_rate": 8.03435348416404e-06,
      "loss": 0.138,
      "step": 26330
    },
    {
      "epoch": 0.0285,
      "grad_norm": 0.4045579135417938,
      "learning_rate": 8.02378994059519e-06,
      "loss": 0.1306,
      "step": 26340
    },
    {
      "step": 26350,
      "wer/bud500": 0.05753208407635864
    },
    {
      "step": 26350,
      "wer/private": 0.3212669683257919
    },
    {
      "epoch": 0.02875,
      "grad_norm": 0.4960302412509918,
      "learning_rate": 8.013230809936438e-06,
      "loss": 0.131,
      "step": 26350
    },
    {
      "epoch": 0.029,
      "grad_norm": 0.42425915598869324,
      "learning_rate": 8.00267609886713e-06,
      "loss": 0.1254,
      "step": 26360
    },
    {
      "epoch": 0.02925,
      "grad_norm": 0.4507928192615509,
      "learning_rate": 7.992125814063817e-06,
      "loss": 0.1282,
      "step": 26370
    },
    {
      "epoch": 0.0295,
      "grad_norm": 0.5712404251098633,
      "learning_rate": 7.981579962200242e-06,
      "loss": 0.1458,
      "step": 26380
    },
    {
      "epoch": 0.02975,
      "grad_norm": 0.44761964678764343,
      "learning_rate": 7.971038549947343e-06,
      "loss": 0.1298,
      "step": 26390
    },
    {
      "step": 26400,
      "wer/bud500": 0.05759055164147689
    },
    {
      "step": 26400,
      "wer/private": 0.3235294117647059
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6422490477561951,
      "learning_rate": 7.960501583973263e-06,
      "loss": 0.1415,
      "step": 26400
    },
    {
      "epoch": 0.03,
      "eval_loss": 0.07949903607368469,
      "eval_runtime": 212.7452,
      "eval_samples_per_second": 35.253,
      "eval_steps_per_second": 0.277,
      "step": 26400
    },
    {
      "epoch": 0.03025,
      "grad_norm": 0.4910530745983124,
      "learning_rate": 7.949969070943313e-06,
      "loss": 0.1422,
      "step": 26410
    },
    {
      "epoch": 0.0305,
      "grad_norm": 0.475044846534729,
      "learning_rate": 7.939441017520012e-06,
      "loss": 0.1327,
      "step": 26420
    },
    {
      "epoch": 0.03075,
      "grad_norm": 0.4934964179992676,
      "learning_rate": 7.928917430363034e-06,
      "loss": 0.134,
      "step": 26430
    },
    {
      "epoch": 0.031,
      "grad_norm": 0.5098968744277954,
      "learning_rate": 7.91839831612924e-06,
      "loss": 0.1383,
      "step": 26440
    },
    {
      "step": 26450,
      "wer/bud500": 0.05735668138100389
    },
    {
      "step": 26450,
      "wer/private": 0.3235294117647059
    },
    {
      "epoch": 0.03125,
      "grad_norm": 0.5026066303253174,
      "learning_rate": 7.90788368147266e-06,
      "loss": 0.1354,
      "step": 26450
    },
    {
      "epoch": 0.0315,
      "grad_norm": 0.4916967749595642,
      "learning_rate": 7.89737353304448e-06,
      "loss": 0.1285,
      "step": 26460
    },
    {
      "epoch": 0.03175,
      "grad_norm": 0.4594789743423462,
      "learning_rate": 7.886867877493072e-06,
      "loss": 0.134,
      "step": 26470
    },
    {
      "epoch": 0.032,
      "grad_norm": 0.43429309129714966,
      "learning_rate": 7.876366721463943e-06,
      "loss": 0.1369,
      "step": 26480
    },
    {
      "epoch": 0.03225,
      "grad_norm": 0.5081804394721985,
      "learning_rate": 7.865870071599768e-06,
      "loss": 0.1346,
      "step": 26490
    },
    {
      "step": 26500,
      "wer/bud500": 0.057561317858917764
    },
    {
      "step": 26500,
      "wer/private": 0.33031674208144796
    },
    {
      "epoch": 0.0325,
      "grad_norm": 0.6020846366882324,
      "learning_rate": 7.855377934540365e-06,
      "loss": 0.1468,
      "step": 26500
    },
    {
      "epoch": 0.0325,
      "eval_loss": 0.07966909557580948,
      "eval_runtime": 213.1942,
      "eval_samples_per_second": 35.179,
      "eval_steps_per_second": 0.277,
      "step": 26500
    },
    {
      "epoch": 0.03275,
      "grad_norm": 0.45504632592201233,
      "learning_rate": 7.844890316922696e-06,
      "loss": 0.1426,
      "step": 26510
    },
    {
      "epoch": 0.033,
      "grad_norm": 0.6111499667167664,
      "learning_rate": 7.834407225380863e-06,
      "loss": 0.1372,
      "step": 26520
    },
    {
      "epoch": 0.03325,
      "grad_norm": 0.4262707531452179,
      "learning_rate": 7.823928666546116e-06,
      "loss": 0.1347,
      "step": 26530
    },
    {
      "epoch": 0.0335,
      "grad_norm": 0.42054033279418945,
      "learning_rate": 7.813454647046828e-06,
      "loss": 0.1523,
      "step": 26540
    },
    {
      "step": 26550,
      "wer/bud500": 0.05769286988043383
    },
    {
      "step": 26550,
      "wer/private": 0.3235294117647059
    },
    {
      "epoch": 0.03375,
      "grad_norm": 0.4256799519062042,
      "learning_rate": 7.802985173508496e-06,
      "loss": 0.1256,
      "step": 26550
    },
    {
      "epoch": 0.034,
      "grad_norm": 0.6180881261825562,
      "learning_rate": 7.79252025255376e-06,
      "loss": 0.1369,
      "step": 26560
    },
    {
      "epoch": 0.03425,
      "grad_norm": 0.47374629974365234,
      "learning_rate": 7.782059890802356e-06,
      "loss": 0.1391,
      "step": 26570
    },
    {
      "epoch": 0.0345,
      "grad_norm": 0.40870189666748047,
      "learning_rate": 7.771604094871159e-06,
      "loss": 0.1302,
      "step": 26580
    },
    {
      "epoch": 0.03475,
      "grad_norm": 0.4635171592235565,
      "learning_rate": 7.761152871374143e-06,
      "loss": 0.1335,
      "step": 26590
    },
    {
      "step": 26600,
      "wer/bud500": 0.057371298272283454
    },
    {
      "step": 26600,
      "wer/private": 0.33597285067873306
    },
    {
      "epoch": 0.035,
      "grad_norm": 0.4389703869819641,
      "learning_rate": 7.750706226922388e-06,
      "loss": 0.138,
      "step": 26600
    },
    {
      "epoch": 0.035,
      "eval_loss": 0.07960046082735062,
      "eval_runtime": 212.9147,
      "eval_samples_per_second": 35.225,
      "eval_steps_per_second": 0.277,
      "step": 26600
    },
    {
      "epoch": 0.03525,
      "grad_norm": 0.5221630930900574,
      "learning_rate": 7.740264168124086e-06,
      "loss": 0.1534,
      "step": 26610
    },
    {
      "epoch": 0.0355,
      "grad_norm": 0.4643514156341553,
      "learning_rate": 7.729826701584513e-06,
      "loss": 0.1482,
      "step": 26620
    },
    {
      "epoch": 0.03575,
      "grad_norm": 0.49936947226524353,
      "learning_rate": 7.719393833906064e-06,
      "loss": 0.145,
      "step": 26630
    },
    {
      "epoch": 0.036,
      "grad_norm": 0.5246626734733582,
      "learning_rate": 7.708965571688202e-06,
      "loss": 0.1326,
      "step": 26640
    },
    {
      "step": 26650,
      "wer/bud500": 0.057502850293799514
    },
    {
      "step": 26650,
      "wer/private": 0.3257918552036199
    },
    {
      "epoch": 0.03625,
      "grad_norm": 0.43970203399658203,
      "learning_rate": 7.698541921527494e-06,
      "loss": 0.1272,
      "step": 26650
    },
    {
      "epoch": 0.0365,
      "grad_norm": 0.6085073947906494,
      "learning_rate": 7.68812289001758e-06,
      "loss": 0.1478,
      "step": 26660
    },
    {
      "epoch": 0.03675,
      "grad_norm": 0.37207695841789246,
      "learning_rate": 7.67770848374918e-06,
      "loss": 0.1393,
      "step": 26670
    },
    {
      "epoch": 0.037,
      "grad_norm": 0.41246896982192993,
      "learning_rate": 7.667298709310079e-06,
      "loss": 0.1238,
      "step": 26680
    },
    {
      "epoch": 0.03725,
      "grad_norm": 0.40861406922340393,
      "learning_rate": 7.656893573285155e-06,
      "loss": 0.1465,
      "step": 26690
    },
    {
      "step": 26700,
      "wer/bud500": 0.05744438272868126
    },
    {
      "step": 26700,
      "wer/private": 0.3257918552036199
    },
    {
      "epoch": 0.0375,
      "grad_norm": 0.5857117176055908,
      "learning_rate": 7.646493082256333e-06,
      "loss": 0.1395,
      "step": 26700
    },
    {
      "epoch": 0.0375,
      "eval_loss": 0.0794760063290596,
      "eval_runtime": 212.5781,
      "eval_samples_per_second": 35.281,
      "eval_steps_per_second": 0.278,
      "step": 26700
    },
    {
      "epoch": 0.03775,
      "grad_norm": 0.4306372404098511,
      "learning_rate": 7.636097242802602e-06,
      "loss": 0.1399,
      "step": 26710
    },
    {
      "epoch": 0.038,
      "grad_norm": 0.46091240644454956,
      "learning_rate": 7.625706061500019e-06,
      "loss": 0.1338,
      "step": 26720
    },
    {
      "epoch": 0.03825,
      "grad_norm": 0.40878233313560486,
      "learning_rate": 7.615319544921681e-06,
      "loss": 0.1307,
      "step": 26730
    },
    {
      "epoch": 0.0385,
      "grad_norm": 0.43902987241744995,
      "learning_rate": 7.604937699637746e-06,
      "loss": 0.1305,
      "step": 26740
    },
    {
      "step": 26750,
      "wer/bud500": 0.05776595433683164
    },
    {
      "step": 26750,
      "wer/private": 0.33031674208144796
    },
    {
      "epoch": 0.03875,
      "grad_norm": 0.4191119372844696,
      "learning_rate": 7.59456053221541e-06,
      "loss": 0.1308,
      "step": 26750
    },
    {
      "epoch": 0.039,
      "grad_norm": 0.469213604927063,
      "learning_rate": 7.584188049218911e-06,
      "loss": 0.1269,
      "step": 26760
    },
    {
      "epoch": 0.03925,
      "grad_norm": 0.6413355469703674,
      "learning_rate": 7.573820257209522e-06,
      "loss": 0.1427,
      "step": 26770
    },
    {
      "epoch": 0.0395,
      "grad_norm": 0.4512421488761902,
      "learning_rate": 7.563457162745548e-06,
      "loss": 0.1515,
      "step": 26780
    },
    {
      "epoch": 0.03975,
      "grad_norm": 0.5882096290588379,
      "learning_rate": 7.5530987723823345e-06,
      "loss": 0.1324,
      "step": 26790
    },
    {
      "step": 26800,
      "wer/bud500": 0.05704972666413307
    },
    {
      "step": 26800,
      "wer/private": 0.32805429864253394
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.41218703985214233,
      "learning_rate": 7.5437802484771735e-06,
      "loss": 0.1325,
      "step": 26800
    },
    {
      "epoch": 0.04,
      "eval_loss": 0.07952237129211426,
      "eval_runtime": 212.5906,
      "eval_samples_per_second": 35.279,
      "eval_steps_per_second": 0.278,
      "step": 26800
    },
    {
      "epoch": 0.04025,
      "grad_norm": 0.48930296301841736,
      "learning_rate": 7.533430813954684e-06,
      "loss": 0.1313,
      "step": 26810
    },
    {
      "epoch": 0.0405,
      "grad_norm": 0.47499966621398926,
      "learning_rate": 7.523086102526589e-06,
      "loss": 0.144,
      "step": 26820
    },
    {
      "epoch": 0.04075,
      "grad_norm": 0.4053453207015991,
      "learning_rate": 7.51274612073659e-06,
      "loss": 0.1308,
      "step": 26830
    },
    {
      "epoch": 0.041,
      "grad_norm": 0.4636670649051666,
      "learning_rate": 7.502410875125408e-06,
      "loss": 0.1474,
      "step": 26840
    },
    {
      "step": 26850,
      "wer/bud500": 0.05741514894612214
    },
    {
      "step": 26850,
      "wer/private": 0.32805429864253394
    },
    {
      "epoch": 0.04125,
      "grad_norm": 0.43858590722084045,
      "learning_rate": 7.492080372230758e-06,
      "loss": 0.1451,
      "step": 26850
    },
    {
      "epoch": 0.0415,
      "grad_norm": 0.4603339731693268,
      "learning_rate": 7.481754618587363e-06,
      "loss": 0.1352,
      "step": 26860
    },
    {
      "epoch": 0.04175,
      "grad_norm": 0.5168349146842957,
      "learning_rate": 7.471433620726932e-06,
      "loss": 0.1355,
      "step": 26870
    },
    {
      "epoch": 0.042,
      "grad_norm": 0.44016319513320923,
      "learning_rate": 7.461117385178179e-06,
      "loss": 0.1299,
      "step": 26880
    },
    {
      "epoch": 0.04225,
      "grad_norm": 0.38120684027671814,
      "learning_rate": 7.450805918466806e-06,
      "loss": 0.151,
      "step": 26890
    },
    {
      "step": 26900,
      "wer/bud500": 0.05792674014090683
    },
    {
      "step": 26900,
      "wer/private": 0.3257918552036199
    },
    {
      "epoch": 0.0425,
      "grad_norm": 0.4649944007396698,
      "learning_rate": 7.440499227115484e-06,
      "loss": 0.1262,
      "step": 26900
    },
    {
      "epoch": 0.0425,
      "eval_loss": 0.07968080788850784,
      "eval_runtime": 212.7284,
      "eval_samples_per_second": 35.256,
      "eval_steps_per_second": 0.277,
      "step": 26900
    },
    {
      "epoch": 0.04275,
      "grad_norm": 0.36325088143348694,
      "learning_rate": 7.43019731764387e-06,
      "loss": 0.1409,
      "step": 26910
    },
    {
      "epoch": 0.043,
      "grad_norm": 0.5439354181289673,
      "learning_rate": 7.419900196568593e-06,
      "loss": 0.1281,
      "step": 26920
    },
    {
      "epoch": 0.04325,
      "grad_norm": 0.4584779143333435,
      "learning_rate": 7.409607870403268e-06,
      "loss": 0.1285,
      "step": 26930
    },
    {
      "epoch": 0.0435,
      "grad_norm": 0.4415988624095917,
      "learning_rate": 7.3993203456584614e-06,
      "loss": 0.133,
      "step": 26940
    },
    {
      "step": 26950,
      "wer/bud500": 0.057678252989154265
    },
    {
      "step": 26950,
      "wer/private": 0.32805429864253394
    },
    {
      "epoch": 0.04375,
      "grad_norm": 0.47696733474731445,
      "learning_rate": 7.389037628841705e-06,
      "loss": 0.1328,
      "step": 26950
    },
    {
      "epoch": 0.044,
      "grad_norm": 0.4216054081916809,
      "learning_rate": 7.378759726457486e-06,
      "loss": 0.1316,
      "step": 26960
    },
    {
      "epoch": 0.04425,
      "grad_norm": 0.5003562569618225,
      "learning_rate": 7.368486645007256e-06,
      "loss": 0.1457,
      "step": 26970
    },
    {
      "epoch": 0.0445,
      "grad_norm": 0.3475305140018463,
      "learning_rate": 7.358218390989422e-06,
      "loss": 0.1145,
      "step": 26980
    },
    {
      "epoch": 0.04475,
      "grad_norm": 0.41294074058532715,
      "learning_rate": 7.3479549708993175e-06,
      "loss": 0.1285,
      "step": 26990
    },
    {
      "step": 27000,
      "wer/bud500": 0.05759055164147689
    },
    {
      "step": 27000,
      "wer/private": 0.3178733031674208
    },
    {
      "epoch": 0.045,
      "grad_norm": 0.5188778638839722,
      "learning_rate": 7.3376963912292285e-06,
      "loss": 0.1408,
      "step": 27000
    },
    {
      "epoch": 0.045,
      "eval_loss": 0.07937299460172653,
      "eval_runtime": 212.71,
      "eval_samples_per_second": 35.259,
      "eval_steps_per_second": 0.277,
      "step": 27000
    },
    {
      "epoch": 0.04525,
      "grad_norm": 0.40330570936203003,
      "learning_rate": 7.327442658468381e-06,
      "loss": 0.1214,
      "step": 27010
    },
    {
      "epoch": 0.0455,
      "grad_norm": 0.38144996762275696,
      "learning_rate": 7.317193779102929e-06,
      "loss": 0.1368,
      "step": 27020
    },
    {
      "epoch": 0.04575,
      "grad_norm": 0.49704456329345703,
      "learning_rate": 7.306949759615968e-06,
      "loss": 0.1425,
      "step": 27030
    },
    {
      "epoch": 0.046,
      "grad_norm": 0.6220762729644775,
      "learning_rate": 7.296710606487502e-06,
      "loss": 0.1403,
      "step": 27040
    },
    {
      "step": 27050,
      "wer/bud500": 0.05764901920659514
    },
    {
      "step": 27050,
      "wer/private": 0.3190045248868778
    },
    {
      "epoch": 0.04625,
      "grad_norm": 0.7902734279632568,
      "learning_rate": 7.286476326194479e-06,
      "loss": 0.1371,
      "step": 27050
    },
    {
      "epoch": 0.0465,
      "grad_norm": 0.45144933462142944,
      "learning_rate": 7.276246925210745e-06,
      "loss": 0.1291,
      "step": 27060
    },
    {
      "epoch": 0.04675,
      "grad_norm": 0.39220619201660156,
      "learning_rate": 7.266022410007066e-06,
      "loss": 0.1412,
      "step": 27070
    },
    {
      "epoch": 0.047,
      "grad_norm": 0.4162227213382721,
      "learning_rate": 7.255802787051114e-06,
      "loss": 0.1195,
      "step": 27080
    },
    {
      "epoch": 0.04725,
      "grad_norm": 0.49635055661201477,
      "learning_rate": 7.245588062807481e-06,
      "loss": 0.1348,
      "step": 27090
    },
    {
      "step": 27100,
      "wer/bud500": 0.05740053205484258
    },
    {
      "step": 27100,
      "wer/private": 0.32805429864253394
    },
    {
      "epoch": 0.0475,
      "grad_norm": 0.4604434370994568,
      "learning_rate": 7.235378243737642e-06,
      "loss": 0.1342,
      "step": 27100
    },
    {
      "epoch": 0.0475,
      "eval_loss": 0.07962352782487869,
      "eval_runtime": 212.7764,
      "eval_samples_per_second": 35.248,
      "eval_steps_per_second": 0.277,
      "step": 27100
    },
    {
      "epoch": 0.04775,
      "grad_norm": 0.44192883372306824,
      "learning_rate": 7.225173336299976e-06,
      "loss": 0.1367,
      "step": 27110
    },
    {
      "epoch": 0.048,
      "grad_norm": 0.42357513308525085,
      "learning_rate": 7.214973346949761e-06,
      "loss": 0.1418,
      "step": 27120
    },
    {
      "epoch": 0.04825,
      "grad_norm": 0.4549313187599182,
      "learning_rate": 7.204778282139152e-06,
      "loss": 0.1419,
      "step": 27130
    },
    {
      "epoch": 0.0485,
      "grad_norm": 0.4646044075489044,
      "learning_rate": 7.194588148317204e-06,
      "loss": 0.1422,
      "step": 27140
    },
    {
      "step": 27150,
      "wer/bud500": 0.057736720554272515
    },
    {
      "step": 27150,
      "wer/private": 0.3190045248868778
    },
    {
      "epoch": 0.04875,
      "grad_norm": 0.46845558285713196,
      "learning_rate": 7.1844029519298435e-06,
      "loss": 0.1315,
      "step": 27150
    },
    {
      "epoch": 0.049,
      "grad_norm": 0.5217839479446411,
      "learning_rate": 7.174222699419869e-06,
      "loss": 0.1333,
      "step": 27160
    },
    {
      "epoch": 0.04925,
      "grad_norm": 0.4073249101638794,
      "learning_rate": 7.16404739722696e-06,
      "loss": 0.1331,
      "step": 27170
    },
    {
      "epoch": 0.0495,
      "grad_norm": 0.39272773265838623,
      "learning_rate": 7.153877051787659e-06,
      "loss": 0.1381,
      "step": 27180
    },
    {
      "epoch": 0.04975,
      "grad_norm": 0.4386388659477234,
      "learning_rate": 7.143711669535382e-06,
      "loss": 0.1354,
      "step": 27190
    },
    {
      "step": 27200,
      "wer/bud500": 0.057561317858917764
    },
    {
      "step": 27200,
      "wer/private": 0.3427601809954751
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4323474168777466,
      "learning_rate": 7.133551256900393e-06,
      "loss": 0.136,
      "step": 27200
    },
    {
      "epoch": 0.05,
      "eval_loss": 0.0795222595334053,
      "eval_runtime": 212.3419,
      "eval_samples_per_second": 35.32,
      "eval_steps_per_second": 0.278,
      "step": 27200
    },
    {
      "epoch": 0.05025,
      "grad_norm": 0.45243164896965027,
      "learning_rate": 7.123395820309827e-06,
      "loss": 0.1437,
      "step": 27210
    },
    {
      "epoch": 0.0505,
      "grad_norm": 0.4254259467124939,
      "learning_rate": 7.1132453661876605e-06,
      "loss": 0.1296,
      "step": 27220
    },
    {
      "epoch": 0.05075,
      "grad_norm": 0.42732372879981995,
      "learning_rate": 7.1030999009547195e-06,
      "loss": 0.1255,
      "step": 27230
    },
    {
      "epoch": 0.051,
      "grad_norm": 0.42716535925865173,
      "learning_rate": 7.092959431028669e-06,
      "loss": 0.1305,
      "step": 27240
    },
    {
      "step": 27250,
      "wer/bud500": 0.05747361651124039
    },
    {
      "step": 27250,
      "wer/private": 0.3223981900452489
    },
    {
      "epoch": 0.05125,
      "grad_norm": 0.3503124415874481,
      "learning_rate": 7.082823962824033e-06,
      "loss": 0.1374,
      "step": 27250
    },
    {
      "epoch": 0.0515,
      "grad_norm": 0.3975242078304291,
      "learning_rate": 7.0726935027521555e-06,
      "loss": 0.1384,
      "step": 27260
    },
    {
      "epoch": 0.05175,
      "grad_norm": 0.585981011390686,
      "learning_rate": 7.062568057221209e-06,
      "loss": 0.146,
      "step": 27270
    },
    {
      "epoch": 0.052,
      "grad_norm": 0.5144988298416138,
      "learning_rate": 7.052447632636213e-06,
      "loss": 0.113,
      "step": 27280
    },
    {
      "epoch": 0.05225,
      "grad_norm": 0.5144842267036438,
      "learning_rate": 7.042332235398986e-06,
      "loss": 0.1396,
      "step": 27290
    },
    {
      "step": 27300,
      "wer/bud500": 0.05738591516356301
    },
    {
      "step": 27300,
      "wer/private": 0.3552036199095023
    },
    {
      "epoch": 0.0525,
      "grad_norm": 0.42440658807754517,
      "learning_rate": 7.032221871908196e-06,
      "loss": 0.1372,
      "step": 27300
    },
    {
      "epoch": 0.0525,
      "eval_loss": 0.0792868509888649,
      "eval_runtime": 212.6337,
      "eval_samples_per_second": 35.272,
      "eval_steps_per_second": 0.277,
      "step": 27300
    },
    {
      "epoch": 0.05275,
      "grad_norm": 0.5397705435752869,
      "learning_rate": 7.022116548559301e-06,
      "loss": 0.1262,
      "step": 27310
    },
    {
      "epoch": 0.053,
      "grad_norm": 0.4116136431694031,
      "learning_rate": 7.01201627174458e-06,
      "loss": 0.1376,
      "step": 27320
    },
    {
      "epoch": 0.05325,
      "grad_norm": 0.46801090240478516,
      "learning_rate": 7.0019210478531244e-06,
      "loss": 0.1538,
      "step": 27330
    },
    {
      "epoch": 0.0535,
      "grad_norm": 0.5040599703788757,
      "learning_rate": 6.991830883270816e-06,
      "loss": 0.1295,
      "step": 27340
    },
    {
      "step": 27350,
      "wer/bud500": 0.05751746718507908
    },
    {
      "step": 27350,
      "wer/private": 0.33710407239819007
    },
    {
      "epoch": 0.05375,
      "grad_norm": 0.41456660628318787,
      "learning_rate": 6.9817457843803556e-06,
      "loss": 0.1375,
      "step": 27350
    },
    {
      "epoch": 0.054,
      "grad_norm": 0.3864995837211609,
      "learning_rate": 6.97166575756122e-06,
      "loss": 0.1341,
      "step": 27360
    },
    {
      "epoch": 0.05425,
      "grad_norm": 0.47106289863586426,
      "learning_rate": 6.961590809189699e-06,
      "loss": 0.1406,
      "step": 27370
    },
    {
      "epoch": 0.0545,
      "grad_norm": 0.397011935710907,
      "learning_rate": 6.951520945638849e-06,
      "loss": 0.1331,
      "step": 27380
    },
    {
      "epoch": 0.05475,
      "grad_norm": 0.4965446889400482,
      "learning_rate": 6.941456173278521e-06,
      "loss": 0.1342,
      "step": 27390
    },
    {
      "step": 27400,
      "wer/bud500": 0.05747361651124039
    },
    {
      "step": 27400,
      "wer/private": 0.3427601809954751
    },
    {
      "epoch": 0.055,
      "grad_norm": 0.42372816801071167,
      "learning_rate": 6.931396498475337e-06,
      "loss": 0.1464,
      "step": 27400
    },
    {
      "epoch": 0.055,
      "eval_loss": 0.07933554798364639,
      "eval_runtime": 212.8164,
      "eval_samples_per_second": 35.242,
      "eval_steps_per_second": 0.277,
      "step": 27400
    },
    {
      "epoch": 0.05525,
      "grad_norm": 0.4422611892223358,
      "learning_rate": 6.921341927592711e-06,
      "loss": 0.1352,
      "step": 27410
    },
    {
      "epoch": 0.0555,
      "grad_norm": 0.6586596369743347,
      "learning_rate": 6.911292466990814e-06,
      "loss": 0.1407,
      "step": 27420
    },
    {
      "epoch": 0.05575,
      "grad_norm": 0.4407634735107422,
      "learning_rate": 6.901248123026581e-06,
      "loss": 0.1294,
      "step": 27430
    },
    {
      "epoch": 0.056,
      "grad_norm": 0.48452961444854736,
      "learning_rate": 6.891208902053733e-06,
      "loss": 0.1347,
      "step": 27440
    },
    {
      "step": 27450,
      "wer/bud500": 0.057488233402519955
    },
    {
      "step": 27450,
      "wer/private": 0.35407239819004527
    },
    {
      "epoch": 0.05625,
      "grad_norm": 0.43972131609916687,
      "learning_rate": 6.881174810422719e-06,
      "loss": 0.1234,
      "step": 27450
    },
    {
      "epoch": 0.0565,
      "grad_norm": 0.47903865575790405,
      "learning_rate": 6.871145854480774e-06,
      "loss": 0.1388,
      "step": 27460
    },
    {
      "epoch": 0.05675,
      "grad_norm": 0.5045515894889832,
      "learning_rate": 6.861122040571862e-06,
      "loss": 0.1305,
      "step": 27470
    },
    {
      "epoch": 0.057,
      "grad_norm": 0.37371933460235596,
      "learning_rate": 6.851103375036706e-06,
      "loss": 0.1301,
      "step": 27480
    },
    {
      "epoch": 0.05725,
      "grad_norm": 0.4374805688858032,
      "learning_rate": 6.8410898642127655e-06,
      "loss": 0.1202,
      "step": 27490
    },
    {
      "step": 27500,
      "wer/bud500": 0.05740053205484258
    },
    {
      "step": 27500,
      "wer/private": 0.3506787330316742
    },
    {
      "epoch": 0.0575,
      "grad_norm": 0.41327688097953796,
      "learning_rate": 6.831081514434238e-06,
      "loss": 0.1268,
      "step": 27500
    },
    {
      "epoch": 0.0575,
      "eval_loss": 0.07947184145450592,
      "eval_runtime": 212.9643,
      "eval_samples_per_second": 35.217,
      "eval_steps_per_second": 0.277,
      "step": 27500
    },
    {
      "epoch": 0.05775,
      "grad_norm": 0.40107420086860657,
      "learning_rate": 6.821078332032071e-06,
      "loss": 0.129,
      "step": 27510
    },
    {
      "epoch": 0.058,
      "grad_norm": 0.370329350233078,
      "learning_rate": 6.811080323333924e-06,
      "loss": 0.1317,
      "step": 27520
    },
    {
      "epoch": 0.05825,
      "grad_norm": 0.4233074188232422,
      "learning_rate": 6.801087494664201e-06,
      "loss": 0.1284,
      "step": 27530
    },
    {
      "epoch": 0.0585,
      "grad_norm": 0.42756763100624084,
      "learning_rate": 6.7910998523440165e-06,
      "loss": 0.1438,
      "step": 27540
    },
    {
      "step": 27550,
      "wer/bud500": 0.057195895576928696
    },
    {
      "step": 27550,
      "wer/private": 0.35180995475113125
    },
    {
      "epoch": 0.05875,
      "grad_norm": 0.6989392042160034,
      "learning_rate": 6.7811174026912115e-06,
      "loss": 0.1254,
      "step": 27550
    },
    {
      "epoch": 0.059,
      "grad_norm": 0.4705774188041687,
      "learning_rate": 6.77114015202033e-06,
      "loss": 0.1327,
      "step": 27560
    },
    {
      "epoch": 0.05925,
      "grad_norm": 0.5155231952667236,
      "learning_rate": 6.761168106642651e-06,
      "loss": 0.142,
      "step": 27570
    },
    {
      "epoch": 0.0595,
      "grad_norm": 0.45575597882270813,
      "learning_rate": 6.75120127286614e-06,
      "loss": 0.1228,
      "step": 27580
    },
    {
      "epoch": 0.05975,
      "grad_norm": 0.5197528004646301,
      "learning_rate": 6.741239656995466e-06,
      "loss": 0.1405,
      "step": 27590
    },
    {
      "step": 27600,
      "wer/bud500": 0.05726898003332651
    },
    {
      "step": 27600,
      "wer/private": 0.3438914027149321
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4683881998062134,
      "learning_rate": 6.731283265332019e-06,
      "loss": 0.1342,
      "step": 27600
    },
    {
      "epoch": 0.06,
      "eval_loss": 0.07936444878578186,
      "eval_runtime": 214.248,
      "eval_samples_per_second": 35.006,
      "eval_steps_per_second": 0.275,
      "step": 27600
    }
  ],
  "logging_steps": 10,
  "max_steps": 40000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 9223372036854775807,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.1753119602376704e+20,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
